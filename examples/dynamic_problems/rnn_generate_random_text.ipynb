{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example uses a simple RNN to learn the probability distribution of a text and tries to match it by generating similar examples using character-based encoding. The network is trained to predict the character that follows a sequence of a certain length and then uses this network to generate random sequences. \n",
    "\n",
    "This example is from \"Deep Learning with Keras\" by Antonio Gulli and Sujit Pal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Adapted from lstm_text_generation.py in keras/examples\n",
    "from __future__ import print_function\n",
    "from keras.layers.recurrent import SimpleRNN\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text from input...\n"
     ]
    }
   ],
   "source": [
    "INPUT_FILE = \"alice_in_wonderland.txt\"\n",
    "\n",
    "# extract the input as a stream of characters\n",
    "print(\"Extracting text from input...\")\n",
    "fin = open(INPUT_FILE, 'rb')\n",
    "lines = []\n",
    "for line in fin:\n",
    "    line = line.strip().lower()\n",
    "    line = line.decode(\"ascii\", \"ignore\")\n",
    "    if len(line) == 0:\n",
    "        continue\n",
    "    lines.append(line)\n",
    "fin.close()\n",
    "text = \" \".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating lookup tables\n",
    "# Here chars is the number of features in our character \"vocabulary\"\n",
    "chars = set([c for c in text])\n",
    "nb_chars = len(chars)\n",
    "char2index = dict((c, i) for i, c in enumerate(chars))\n",
    "index2char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating input and label text...\n"
     ]
    }
   ],
   "source": [
    "# create inputs and labels from the text. We do this by stepping\n",
    "# through the text ${step} character at a time, and extracting a \n",
    "# sequence of size ${seqlen} and the next output char. For example,\n",
    "# assuming an input text \"The sky was falling\", we would get the \n",
    "# following sequence of input_chars and label_chars (first 5 only)\n",
    "#   The sky wa -> s\n",
    "#   he sky was ->  \n",
    "#   e sky was  -> f\n",
    "#    sky was f -> a\n",
    "#   sky was fa -> l\n",
    "print(\"Creating input and label text...\")\n",
    "SEQLEN = 10\n",
    "STEP = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing input and label text...\n"
     ]
    }
   ],
   "source": [
    "input_chars = []\n",
    "label_chars = []\n",
    "for i in range(0, len(text) - SEQLEN, STEP):\n",
    "    input_chars.append(text[i:i + SEQLEN])\n",
    "    label_chars.append(text[i + SEQLEN])\n",
    "\n",
    "# vectorize the input and label chars\n",
    "# Each row of the input is represented by seqlen characters, each \n",
    "# represented as a 1-hot encoding of size len(char). There are \n",
    "# len(input_chars) such rows, so shape(X) is (len(input_chars),\n",
    "# seqlen, nb_chars).\n",
    "# Each row of output is a single character, also represented as a\n",
    "# dense encoding of size len(char). Hence shape(y) is (len(input_chars),\n",
    "# nb_chars).\n",
    "print(\"Vectorizing input and label text...\")\n",
    "X = np.zeros((len(input_chars), SEQLEN, nb_chars), dtype=np.bool)\n",
    "y = np.zeros((len(input_chars), nb_chars), dtype=np.bool)\n",
    "for i, input_char in enumerate(input_chars):\n",
    "    for j, ch in enumerate(input_char):\n",
    "        X[i, j, char2index[ch]] = 1\n",
    "    y[i, char2index[label_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Iteration #: 0\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 4s 30us/step - loss: 2.3533\n",
      "Generating from seed:  `what fun\n",
      " `what fune sa the so the sale the she said the wast the sale the she said the wast the sale the she said the \n",
      "==================================================\n",
      "Iteration #: 1\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 4s 28us/step - loss: 2.0263\n",
      "Generating from seed: e was to g\n",
      "e was to ghe there sarded and the wast of the wast of the wast of the wast of the wast of the wast of the wast\n",
      "==================================================\n",
      "Iteration #: 2\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 4s 29us/step - loss: 1.9200\n",
      "Generating from seed: back to my\n",
      "back to myous to the she she she she she she she she she she she she she she she she she she she she she she s\n",
      "==================================================\n",
      "Iteration #: 3\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 4s 28us/step - loss: 1.8428\n",
      "Generating from seed: silent. th\n",
      "silent. the doon the doon the doon the doon the doon the doon the doon the doon the doon the doon the doon the\n",
      "==================================================\n",
      "Iteration #: 4\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 4s 28us/step - loss: 1.7792\n",
      "Generating from seed: into its f\n",
      "into its for the little she say the gat the latter the little she say the gat the latter the little she say th\n",
      "==================================================\n",
      "Iteration #: 5\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 4s 29us/step - loss: 1.7248\n",
      "Generating from seed: ortant,' a\n",
      "ortant,' alice said the dore the pook the dore the pook the dore the pook the dore the pook the dore the pook \n",
      "==================================================\n",
      "Iteration #: 6\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 4s 28us/step - loss: 1.6776\n",
      "Generating from seed: ou first f\n",
      "ou first for a little she was she had not the rabbit with the groping to the dore the rabbit with the groping \n",
      "==================================================\n",
      "Iteration #: 7\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 4s 29us/step - loss: 1.6377\n",
      "Generating from seed: n!' she ex\n",
      "n!' she expeat in a looked and a little said the more to the more to the more to the more to the more to the m\n",
      "==================================================\n",
      "Iteration #: 8\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 4s 29us/step - loss: 1.6027\n",
      "Generating from seed: arked. `oh\n",
      "arked. `oh meated the cat the marse of the satter with a sand with a tont of the little said the gat her had h\n",
      "==================================================\n",
      "Iteration #: 9\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 4s 30us/step - loss: 1.5726\n",
      "Generating from seed: d take the\n",
      "d take the round rearing the round rearing the round rearing the round rearing the round rearing the round rea\n",
      "==================================================\n",
      "Iteration #: 10\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 5s 31us/step - loss: 1.5473\n",
      "Generating from seed: e waters o\n",
      "e waters of the gryphon alice, and when the gryphon alice, and when the gryphon alice, and when the gryphon al\n",
      "==================================================\n",
      "Iteration #: 11\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 5s 32us/step - loss: 1.5235\n",
      "Generating from seed: your pocke\n",
      "your pocked all the caterpillar. `when i she cat the caterpillar. `when i she cat the caterpillar. `when i she\n",
      "==================================================\n",
      "Iteration #: 12\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 5s 32us/step - loss: 1.5040\n",
      "Generating from seed: er days. t\n",
      "er days. the door of the door of the door of the door of the door of the door of the door of the door of the d\n",
      "==================================================\n",
      "Iteration #: 13\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 5s 32us/step - loss: 1.4865\n",
      "Generating from seed: bout the r\n",
      "bout the round at the mouse to go not the mouse to go not the mouse to go not the mouse to go not the mouse to\n",
      "==================================================\n",
      "Iteration #: 14\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 5s 32us/step - loss: 1.4699\n",
      "Generating from seed: ppen, that\n",
      "ppen, that she could not the think yourse fere it was the caterpillar the caterpillar the caterpillar the cate\n",
      "==================================================\n",
      "Iteration #: 15\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 5s 32us/step - loss: 1.4567\n",
      "Generating from seed: ut for ser\n",
      "ut for seret in the mouse down the gryphon it would be of the more the mouse down the gryphon it would be of t\n",
      "==================================================\n",
      "Iteration #: 16\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 5s 33us/step - loss: 1.4426\n",
      "Generating from seed: ; `there's\n",
      "; `there's no the could not the was the caterpillar the could not the was the caterpillar the could not the wa\n",
      "==================================================\n",
      "Iteration #: 17\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 5s 33us/step - loss: 1.4315\n",
      "Generating from seed: xiously ab\n",
      "xiously about the dormouse the door and the duchess to the dormouse the door and the duchess to the dormouse t\n",
      "==================================================\n",
      "Iteration #: 18\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 5s 33us/step - loss: 1.4200\n",
      "Generating from seed:  the fall \n",
      " the fall a little she was not the mouse to get in a little she was not the mouse to get in a little she was n\n",
      "==================================================\n",
      "Iteration #: 19\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 5s 33us/step - loss: 1.4108\n",
      "Generating from seed: y teeth, s\n",
      "y teeth, so she was a little with the mock turtle was she had not like the more the serpen what i should she s\n",
      "==================================================\n",
      "Iteration #: 20\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 5s 32us/step - loss: 1.4004\n",
      "Generating from seed: be at scho\n",
      "be at schorsed the gryphon in a minute or the time the right the court, and then i should be offer the mock tu\n",
      "==================================================\n",
      "Iteration #: 21\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 5s 33us/step - loss: 1.3918\n",
      "Generating from seed: they--you'\n",
      "they--you're to alice was to as the thing to herself, `i had she said to the door of course, and the time to g\n",
      "==================================================\n",
      "Iteration #: 22\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 5s 31us/step - loss: 1.3835\n",
      "Generating from seed:  it's hard\n",
      " it's hard at the thing to the door, and then they was a little thing to the door, and then they was a little \n",
      "==================================================\n",
      "Iteration #: 23\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 4s 31us/step - loss: 1.3770\n",
      "Generating from seed:  capital o\n",
      " capital on the sate poor little shought they were got to be seeped to the king and began things to her foon t\n",
      "==================================================\n",
      "Iteration #: 24\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 5s 32us/step - loss: 1.3696\n",
      "Generating from seed: it here, l\n",
      "it here, like the door of the said to like the door of the said to like the door of the said to like the door \n"
     ]
    }
   ],
   "source": [
    "# Build the model. We use a single RNN with a fully connected layer\n",
    "# to compute the most likely predicted output char\n",
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 128\n",
    "NUM_ITERATIONS = 25\n",
    "NUM_EPOCHS_PER_ITERATION = 1\n",
    "NUM_PREDS_PER_EPOCH = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(HIDDEN_SIZE, return_sequences=False,\n",
    "                    input_shape=(SEQLEN, nb_chars),\n",
    "                    unroll=True))\n",
    "model.add(Dense(nb_chars))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")\n",
    "\n",
    "# We train the model in batches and test output generated at each step\n",
    "for iteration in range(NUM_ITERATIONS):\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Iteration #: %d\" % (iteration))\n",
    "    model.fit(X, y, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS_PER_ITERATION)\n",
    "    \n",
    "    # testing model\n",
    "    # randomly choose a row from input_chars, then use it to \n",
    "    # generate text from model for next 100 chars\n",
    "    test_idx = np.random.randint(len(input_chars))\n",
    "    test_chars = input_chars[test_idx]\n",
    "    print(\"Generating from seed: %s\" % (test_chars))\n",
    "    print(test_chars, end=\"\")\n",
    "    for i in range(NUM_PREDS_PER_EPOCH):\n",
    "        Xtest = np.zeros((1, SEQLEN, nb_chars))\n",
    "        for i, ch in enumerate(test_chars):\n",
    "            Xtest[0, i, char2index[ch]] = 1\n",
    "        pred = model.predict(Xtest, verbose=0)[0]\n",
    "        ypred = index2char[np.argmax(pred)]\n",
    "        print(ypred, end=\"\")\n",
    "        # move forward with test_chars + ypred\n",
    "        test_chars = test_chars[1:] + ypred\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
