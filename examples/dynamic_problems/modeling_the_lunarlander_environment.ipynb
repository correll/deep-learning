{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Modeling the LunarLander Environment**\n",
    "### CSCI 7000: Applied Deep Learning (Homework 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To run this notebook, you need OpenAI Gym. You can replicate my environment with the following `environment.yml` file for Anaconda.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "name: lunarlander-modeling\n",
    "channels:\n",
    "  - conda-forge\n",
    "dependencies:\n",
    "  - python=3.7.*\n",
    "  - tensorflow-gpu=2.1.*\n",
    "  - numpy=1.18.*\n",
    "  - scipy=1.4.*\n",
    "  - nb_conda_kernels\n",
    "  - pip\n",
    "  - pip:\n",
    "    - gym[box2d]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The motivation behind this work is to explore a couple of ways to \"model\" the OpenAI Gym [LunarLander](https://gym.openai.com/envs/LunarLander-v2/) environment. The observations in this environment consist of 8 values associated with the lander:**\n",
    " - ***x* position,**\n",
    " - ***y* position,**\n",
    " - ***x* velocity,**\n",
    " - ***y* velocity,**\n",
    " - **angle,**\n",
    " - **angular velocity,**\n",
    " - **boolean variable indicating whether its left leg is in contact with the ground,**\n",
    " - **boolean variable indicating whether its right leg is in contact with the ground.**\n",
    " \n",
    "**Specifically, I'm interested in finding out if we can predict with some accuracy the next state of the lander *despite* not knowing what the intervening action is. This might seem nonsensical at first glance: if we don't know what action is going to be taken, how are we going to know the next state?**\n",
    "\n",
    "**However, I suspect that a given state might contain enough information to make a decent prediction of the next state. While the actions taken might change the lander's velocities, they only do so incrementally. For instance, if the lander has a large negative *y* velocity at a given timestep, its *y* position will decrease significantly by the next timestep regardless of what action was taken.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alright, let's get started. First, we import some libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, we generate 100,000 episodes' worth of data from the LunarLander environment. Every action is taken randomly.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joewie/anaconda3/envs/environment-modeling/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed: 0\n",
      "Completed: 5000\n",
      "Completed: 10000\n",
      "Completed: 15000\n",
      "Completed: 20000\n",
      "Completed: 25000\n",
      "Completed: 30000\n",
      "Completed: 35000\n",
      "Completed: 40000\n",
      "Completed: 45000\n",
      "Completed: 50000\n",
      "Completed: 55000\n",
      "Completed: 60000\n",
      "Completed: 65000\n",
      "Completed: 70000\n",
      "Completed: 75000\n",
      "Completed: 80000\n",
      "Completed: 85000\n",
      "Completed: 90000\n",
      "Completed: 95000\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('LunarLander-v2')\n",
    "\n",
    "env.seed(42)\n",
    "\n",
    "episode_count = 100000\n",
    "reward = 0\n",
    "done = False\n",
    "\n",
    "data = []\n",
    "\n",
    "for i in range(episode_count):\n",
    "    episode_obs = []\n",
    "    ob = env.reset()\n",
    "    episode_obs.append(ob)\n",
    "    while True:\n",
    "        action = env.action_space.sample()\n",
    "        ob, reward, done, _ = env.step(action)\n",
    "        episode_obs.append(ob)\n",
    "        if done:\n",
    "            data.append(np.array(episode_obs))\n",
    "            if i % 5000 == 0:\n",
    "                print(\"Completed:\", i)\n",
    "            break\n",
    "            \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, we create training and test data from the generated data. I'm taking a naive approach to this, and just creating sequences of 10 observations. The idea is that, given 9 observations in a row, we will try to predict the 10th observation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 10\n",
    "STATE_DIM = env.observation_space.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fixed_seq_data(data):\n",
    "    fixed_seq_data = []\n",
    "    for episode in data:\n",
    "        for i in range(len(episode) - MAX_SEQ_LEN):\n",
    "            fixed_seq_data.append(episode[i:(i + MAX_SEQ_LEN)])\n",
    "\n",
    "    return np.array(fixed_seq_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = generate_fixed_seq_data(data[:80000])\n",
    "test_data = generate_fixed_seq_data(data[80000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_data[:, :-1], train_data[:, -1]\n",
    "X_test, y_test = test_data[:, :-1], test_data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (6702422, 9, 8)\n",
      "y_train: (6702422, 8)\n",
      "X_test: (1672840, 9, 8)\n",
      "y_test: (1672840, 8)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print(\"y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's define and train a simple LSTM model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = tf.keras.Sequential()\n",
    "lstm_model.add(layers.LSTM(128, input_shape=X_train.shape[-2:]))\n",
    "lstm_model.add(layers.Dense(8))\n",
    "\n",
    "lstm_model.compile(loss='mse',\n",
    "                   optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "                   metrics=['mae', 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 128)               70144     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 1032      \n",
      "=================================================================\n",
      "Total params: 71,176\n",
      "Trainable params: 71,176\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5361937 samples, validate on 1340485 samples\n",
      "Epoch 1/10\n",
      "5361937/5361937 [==============================] - 91s 17us/sample - loss: 0.0060 - mae: 0.0194 - mse: 0.0060 - val_loss: 0.0047 - val_mae: 0.0159 - val_mse: 0.0047\n",
      "Epoch 2/10\n",
      "5361937/5361937 [==============================] - 90s 17us/sample - loss: 0.0044 - mae: 0.0152 - mse: 0.0044 - val_loss: 0.0043 - val_mae: 0.0155 - val_mse: 0.0043\n",
      "Epoch 3/10\n",
      "5361937/5361937 [==============================] - 90s 17us/sample - loss: 0.0042 - mae: 0.0144 - mse: 0.0042 - val_loss: 0.0042 - val_mae: 0.0141 - val_mse: 0.0042\n",
      "Epoch 4/10\n",
      "5361937/5361937 [==============================] - 90s 17us/sample - loss: 0.0040 - mae: 0.0140 - mse: 0.0040 - val_loss: 0.0040 - val_mae: 0.0142 - val_mse: 0.0040\n",
      "Epoch 5/10\n",
      "5361937/5361937 [==============================] - 90s 17us/sample - loss: 0.0039 - mae: 0.0137 - mse: 0.0039 - val_loss: 0.0039 - val_mae: 0.0134 - val_mse: 0.0039\n",
      "Epoch 6/10\n",
      "5361937/5361937 [==============================] - 90s 17us/sample - loss: 0.0038 - mae: 0.0135 - mse: 0.0038 - val_loss: 0.0038 - val_mae: 0.0132 - val_mse: 0.0038\n",
      "Epoch 7/10\n",
      "5361937/5361937 [==============================] - 90s 17us/sample - loss: 0.0038 - mae: 0.0133 - mse: 0.0038 - val_loss: 0.0038 - val_mae: 0.0130 - val_mse: 0.0038\n",
      "Epoch 8/10\n",
      "5361937/5361937 [==============================] - 90s 17us/sample - loss: 0.0037 - mae: 0.0132 - mse: 0.0037 - val_loss: 0.0038 - val_mae: 0.0133 - val_mse: 0.0038\n",
      "Epoch 9/10\n",
      "5361937/5361937 [==============================] - 90s 17us/sample - loss: 0.0037 - mae: 0.0131 - mse: 0.0037 - val_loss: 0.0038 - val_mae: 0.0134 - val_mse: 0.0038\n",
      "Epoch 10/10\n",
      "5361937/5361937 [==============================] - 90s 17us/sample - loss: 0.0036 - mae: 0.0130 - mse: 0.0036 - val_loss: 0.0037 - val_mae: 0.0128 - val_mse: 0.0037\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7faea8022e50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model.fit(X_train, y_train,\n",
    "               validation_split=0.2,\n",
    "               batch_size=128,\n",
    "               epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To have some basis of comparison, let's define and train a simple fully-connected model with roughly the same number of trainable parameters as the LSTM model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_model = tf.keras.Sequential()\n",
    "dense_model.add(layers.Flatten(input_shape=X_train.shape[-2:]))\n",
    "dense_model.add(layers.Dense(384, activation='relu'))\n",
    "dense_model.add(layers.Dense(128, activation='relu'))\n",
    "dense_model.add(layers.Dense(8))\n",
    "\n",
    "dense_model.compile(loss='mse',\n",
    "                    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "                    metrics=['mae', 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 72)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 384)               28032     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               49280     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 1032      \n",
      "=================================================================\n",
      "Total params: 78,344\n",
      "Trainable params: 78,344\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dense_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5361937 samples, validate on 1340485 samples\n",
      "Epoch 1/10\n",
      "5361937/5361937 [==============================] - 58s 11us/sample - loss: 0.0049 - mae: 0.0187 - mse: 0.0049 - val_loss: 0.0043 - val_mae: 0.0164 - val_mse: 0.0043\n",
      "Epoch 2/10\n",
      "5361937/5361937 [==============================] - 58s 11us/sample - loss: 0.0040 - mae: 0.0155 - mse: 0.0040 - val_loss: 0.0039 - val_mae: 0.0151 - val_mse: 0.0039\n",
      "Epoch 3/10\n",
      "5361937/5361937 [==============================] - 58s 11us/sample - loss: 0.0038 - mae: 0.0147 - mse: 0.0038 - val_loss: 0.0039 - val_mae: 0.0141 - val_mse: 0.0039\n",
      "Epoch 4/10\n",
      "5361937/5361937 [==============================] - 58s 11us/sample - loss: 0.0037 - mae: 0.0143 - mse: 0.0037 - val_loss: 0.0037 - val_mae: 0.0151 - val_mse: 0.0037\n",
      "Epoch 5/10\n",
      "5361937/5361937 [==============================] - 58s 11us/sample - loss: 0.0036 - mae: 0.0140 - mse: 0.0036 - val_loss: 0.0036 - val_mae: 0.0137 - val_mse: 0.0036\n",
      "Epoch 6/10\n",
      "5361937/5361937 [==============================] - 58s 11us/sample - loss: 0.0035 - mae: 0.0138 - mse: 0.0035 - val_loss: 0.0036 - val_mae: 0.0139 - val_mse: 0.0036\n",
      "Epoch 7/10\n",
      "5361937/5361937 [==============================] - 58s 11us/sample - loss: 0.0035 - mae: 0.0137 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0142 - val_mse: 0.0035\n",
      "Epoch 8/10\n",
      "5361937/5361937 [==============================] - 58s 11us/sample - loss: 0.0034 - mae: 0.0136 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0138 - val_mse: 0.0035\n",
      "Epoch 9/10\n",
      "5361937/5361937 [==============================] - 58s 11us/sample - loss: 0.0034 - mae: 0.0135 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0132 - val_mse: 0.0035\n",
      "Epoch 10/10\n",
      "5361937/5361937 [==============================] - 58s 11us/sample - loss: 0.0034 - mae: 0.0134 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0134 - val_mse: 0.0035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fadac1e7950>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_model.fit(X_train, y_train,\n",
    "                validation_split=0.2,\n",
    "                batch_size=128,\n",
    "                epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's also try a fully-connected model that only uses a single observation to make a prediction (instead of using a sequence of 9 observations).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_single = X_train[:, -1, :]\n",
    "X_test_single = X_test[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_single_model = tf.keras.Sequential()\n",
    "dense_single_model.add(layers.Dense(256, activation='relu', input_dim=X_train_single.shape[-1]))\n",
    "dense_single_model.add(layers.Dense(8))\n",
    "\n",
    "dense_single_model.compile(loss='mse',\n",
    "                           optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "                           metrics=['mae', 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 256)               2304      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 8)                 2056      \n",
      "=================================================================\n",
      "Total params: 4,360\n",
      "Trainable params: 4,360\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dense_single_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5361937 samples, validate on 1340485 samples\n",
      "Epoch 1/10\n",
      "5361937/5361937 [==============================] - 54s 10us/sample - loss: 0.0065 - mae: 0.0190 - mse: 0.0065 - val_loss: 0.0048 - val_mae: 0.0151 - val_mse: 0.0048\n",
      "Epoch 2/10\n",
      "5361937/5361937 [==============================] - 55s 10us/sample - loss: 0.0047 - mae: 0.0147 - mse: 0.0047 - val_loss: 0.0046 - val_mae: 0.0145 - val_mse: 0.0046\n",
      "Epoch 3/10\n",
      "5361937/5361937 [==============================] - 54s 10us/sample - loss: 0.0045 - mae: 0.0144 - mse: 0.0045 - val_loss: 0.0045 - val_mae: 0.0144 - val_mse: 0.0045\n",
      "Epoch 4/10\n",
      "5361937/5361937 [==============================] - 54s 10us/sample - loss: 0.0044 - mae: 0.0143 - mse: 0.0044 - val_loss: 0.0044 - val_mae: 0.0146 - val_mse: 0.0044\n",
      "Epoch 5/10\n",
      "5361937/5361937 [==============================] - 54s 10us/sample - loss: 0.0044 - mae: 0.0142 - mse: 0.0044 - val_loss: 0.0044 - val_mae: 0.0142 - val_mse: 0.0044\n",
      "Epoch 6/10\n",
      "5361937/5361937 [==============================] - 54s 10us/sample - loss: 0.0043 - mae: 0.0141 - mse: 0.0043 - val_loss: 0.0043 - val_mae: 0.0140 - val_mse: 0.0043\n",
      "Epoch 7/10\n",
      "5361937/5361937 [==============================] - 54s 10us/sample - loss: 0.0043 - mae: 0.0140 - mse: 0.0043 - val_loss: 0.0043 - val_mae: 0.0141 - val_mse: 0.0043\n",
      "Epoch 8/10\n",
      "5361937/5361937 [==============================] - 54s 10us/sample - loss: 0.0043 - mae: 0.0140 - mse: 0.0043 - val_loss: 0.0043 - val_mae: 0.0137 - val_mse: 0.0043\n",
      "Epoch 9/10\n",
      "5361937/5361937 [==============================] - 54s 10us/sample - loss: 0.0043 - mae: 0.0139 - mse: 0.0043 - val_loss: 0.0043 - val_mae: 0.0143 - val_mse: 0.0043\n",
      "Epoch 10/10\n",
      "5361937/5361937 [==============================] - 54s 10us/sample - loss: 0.0043 - mae: 0.0139 - mse: 0.0043 - val_loss: 0.0043 - val_mae: 0.0141 - val_mse: 0.0043\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fadac074d50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_single_model.fit(X_train_single, y_train,\n",
    "                       validation_split=0.2,\n",
    "                       batch_size=128,\n",
    "                       epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finally, let's take a look at the results. I also compare the models to a naive baseline that uses the last-seen state as its \"prediction\".**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Network\n",
      "MSE: 0.0036692955\n",
      "MAE: 0.0128733255\n"
     ]
    }
   ],
   "source": [
    "y_lstm_pred = lstm_model.predict(X_test)\n",
    "\n",
    "print(\"LSTM Network\")\n",
    "print(\"MSE:\", np.mean(tf.keras.losses.mean_squared_error(y_test, y_lstm_pred)))\n",
    "print(\"MAE:\", np.mean(tf.keras.losses.mean_absolute_error(y_test, y_lstm_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense Network\n",
      "MSE: 0.0034199469\n",
      "MAE: 0.013440048\n"
     ]
    }
   ],
   "source": [
    "y_dense_pred = dense_model.predict(X_test)\n",
    "\n",
    "print(\"Dense Network\")\n",
    "print(\"MSE:\", np.mean(tf.keras.losses.mean_squared_error(y_test, y_dense_pred)))\n",
    "print(\"MAE:\", np.mean(tf.keras.losses.mean_absolute_error(y_test, y_dense_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense Network (Single Observation)\n",
      "MSE: 0.0042579677\n",
      "MAE: 0.014133502\n"
     ]
    }
   ],
   "source": [
    "y_dense_single_pred = dense_single_model.predict(X_test_single)\n",
    "\n",
    "print(\"Dense Network (Single Observation)\")\n",
    "print(\"MSE:\", np.mean(tf.keras.losses.mean_squared_error(y_test, y_dense_single_pred)))\n",
    "print(\"MAE:\", np.mean(tf.keras.losses.mean_absolute_error(y_test, y_dense_single_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Baseline\n",
      "MSE: 0.0066404184\n",
      "MAE: 0.015631419\n"
     ]
    }
   ],
   "source": [
    "y_naive_baseline = X_test_single\n",
    "\n",
    "print(\"Naive Baseline\")\n",
    "print(\"MSE:\", np.mean(tf.keras.losses.mean_squared_error(y_test, y_naive_baseline)))\n",
    "print(\"MAE:\", np.mean(tf.keras.losses.mean_absolute_error(y_test, y_naive_baseline)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:environment-modeling] *",
   "language": "python",
   "name": "conda-env-environment-modeling-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
