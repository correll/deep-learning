{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1\n",
    "## CSCI 7000 - Applied Machine Learning\n",
    "### Adam Resnick\n",
    "\n",
    "#### Dataset: CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Adam\\Anaconda\\envs\\DeepLearningEnv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Adam\\Anaconda\\envs\\DeepLearningEnv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Adam\\Anaconda\\envs\\DeepLearningEnv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Adam\\Anaconda\\envs\\DeepLearningEnv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Adam\\Anaconda\\envs\\DeepLearningEnv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Adam\\Anaconda\\envs\\DeepLearningEnv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Adam\\Anaconda\\envs\\DeepLearningEnv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Adam\\Anaconda\\envs\\DeepLearningEnv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Adam\\Anaconda\\envs\\DeepLearningEnv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Adam\\Anaconda\\envs\\DeepLearningEnv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Adam\\Anaconda\\envs\\DeepLearningEnv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Adam\\Anaconda\\envs\\DeepLearningEnv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras as k\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "import numpy as np\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Dense, Activation, Flatten\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.utils import np_utils\n",
    "np.random.seed(101) # for reproducibility‚Äù\n",
    "from skimage import data\n",
    "from skimage.color import rgb2gray\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#Loading Dataset\n",
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing CIFAR10 Dataset for NN and DNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I decided to convert the CIFAR-10 data to grayscale for the NN for simplicity's sake. Each image was reshaped to a 1x1024 vector, creating a 50,000x1024 training set. One important not: you do not need to divide by 255 to normalize the data, as the rgb2gray function does this automaticall. (It took me a while to figure this out)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVcAAAD8CAYAAADDneeBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOy9ebRnV1bf9zl3/M1vHmpSDVKpqqQWParnBmO6TeO4ITYNBrJwcFghK3EnjpdxgKysOOPCQ2zHieOBFYMhscEG7ABphQaanoAepFZLLZWGUs3Te6/qzb/5Dufkj33uub9Sl0qq4ZWe4LfX0tJ9t+69v3v33XefPX63MsYwpjGNaUxjurfkvdk3MKYxjWlMfxxprFzHNKYxjWkHaKxcxzSmMY1pB2isXMc0pjGNaQdorFzHNKYxjWkHaKxcxzSmMY1pB+iulKtS6uNKqZeVUqeVUj99r25qTEJj/u4cjXm7czTmrZC60zpXpZQPnAI+BlwGngR+2Bjzwr27vT+5NObvztGYtztHY96WdDeW63uB08aYs8aYBPgV4PvuzW2NiTF/d5LGvN05GvPWUnAX5+4DLo38fRl4361OCOO6qUaT7m/jKQB0qND2TowPKLutynNVDsqMHFOQHtnvAXZbmZHjTLlf/nHkeM+U+25mxNubyNbXyTtddZMjdopui7/hRM14kzMAeMNyv47Ai3IAqmGKrzQA24MKaihrq90FCM8KvtfqQ2bDNgADE7E2rMkxRmGKgwYeSi4v17E89HJQefFi5B0DmKA8BlO+u97a5VVjzNwtOXLv6LZld3baNwcP3M3ncmtKjKZrIgDqKiG3Qhoq8O32nQrfhUsZq+v5/ZLd2+Zt5FVNNZqwf6nyQZWCUc86zcr9VneQ5+DbD93zMIHItA48vFQEW+UjAq417gdGrmMCjzySbX+oQRu338l0pskr8lvGk+8kaa+TDW6uF+5GWm52wW9RT0qpnwB+AqDiN3lf94Nyo80m6sAeAHoHJ9g+JLeSx8p97EZB0JdLBn3w7Meq/VIZe1mpRPNYjgP5sPtzwmjjgW8Vjo5K5ePlhqym3DHFdYwCf2CPSUUhnP7lv38brLkn9Lr8HeVtMDvB3p/9TwHwrlQwgRwaPtDF94Whx+dW8Kw2e/K5B6leFiYm0xp/fw+ADx48x0enxIP7YOUCk940AG2jGViF2tMB1/IGAP/J536MiedCuTkflJV/f2gILA/jrZz+jDA3qyrH58qaJhjK/Xz5V//Ghdvm0J3TbcvuA/sCnvzMAzt2Q18cwC9e+zAAl7uTLLebAPyfb/9F3h1Hd3Xt9373pdc/6N7RHemFDy78sPxDlmHqVTlmmGLisDgBPPmes5k6wYbIq7lwBbVf9Eg21ySZkOMH0z5Tz2zKqUmKblZk/3yN6hUxGLJWha2Hqu6eOgfk1uM1mHlRhDeZCBi2RGCjtqazzypXBdG24cXf+gevyYi7CQtcBg6M/L0fuPrqg4wxP2eMeY8x5j2RV331P4/ptel1+TvKW79Vv6839xan25bduRn/1f88ppvTWC9YuhvL9UngqFLqMHAF+CHgR255hlJ4dVECav8i/QMtAHoLQWlBKgh69uYS49bBvAI6s+6RhuG0bHsp5HZh93LQdqHzErFqAbIapHa/DsFuoo26YU3N7DsOeuW52BWqcH3vI90Wf40BPbQrbF+RHpWVd9gLMYns701FNEIx2w8cuc6xd10D4CMTL/NoLPIfKs2cfXhfKQZGrN5LWY22FgYt+ts8Fm0AcOTwCtdf2i/3oCDqCkOTCYW276WyQRmuyQ3RtmyHPYN6c4CDbl92gdzo1zvktkhj8KyA/8bGe/jcU48C4PU98oYI3Esn9vBt0TV3jncHwQFz03jXjtHt89ZTzkJNj8wRbFnXMo4gSWXbGLoPixe1fSBg7huy2/cfYPu4hBRUjtMXSVMxXBRdY3xFf05U3bDlgSdewfYDAVlVTqisl9/4cAY2H4wB0RdFuEAHHl4ivBxOKfzEhhZfg+5YuRpjMqXUp4DPAD7w88aYk7c8SYE3J3HB7pFJkkbhh0O8ITetdBkK0AEMJ20MJYJo0+4PIRX+ELZx7qc/KIUorSt8ywi0whTeRQ7a/qw/LJUxplTqKi9DBEpD1NE3xCXvB902f40Cu/jksUGviWYL5vu8/+HTAHx06gVaNt4x0CHbVln+3sYj/Mrgve5SL1pleeL4Zf7e4V+Ta+Lx0lDcr3/XfRcty/R6mHBpTvhcv6jIK3IPQRfiLWFaHimSCbu/Z/AyOd5LjTv+ftIdyS7gq3tcFm40G1riWF9afhBTs1/39BC1Jh/35zeP8+frS/b3FYWzGao3bkmrO47W3j7dCW9N4NN/UPRC+4GQxhVRS1nNo7osirbzQIXUKsKsARvHJf6ftOr4NrRkPEVuDaSwbdg8Kt+ADsr9/gA6e+X6xlcEvVJZFiHFeN0QWh3U2eORNuyNKuWMrrAt17qVXrirCL0x5gngibu5xphem8b83Tka83bnaMxboZ1Lf96MPA89KctA0vQZTJZufpE11kFZReBluMQV4CxR4ysq1+0lU0NoXVEvg7RWZPxGXCEFWgwBgh7OXYXS6vXS8viobQi7siSFnRxvmLvM464lrSCUZ0inct796FkAPjn/ddZs8unXVt7DWl9W/NWtBsmmMCVeCUgmyjKLo78sTHnxR/dTOSLPPekN+NP1l9zPvdgVK/b55w7i2eRZ2lTOtQoT495jb65c8atr2rluOlQMpv7kNQkW4QVfeTw1FFd39fw00aZN2FQDoo4w6fdOnuAPZr4GwHdUe2isN2DUvbek3yTSkUfaFEs86Bm2Dok7mdUhDyUR1T7guaR0/apmMF16tH6C2y7c9KhdhhSzSvmdB33jdERlXTOwnrHKoL4ivM1i5SpmgoEh3izvtbIlAu73NcPJYOcs19slHXj090ocJKsojG/d2GqZZQbKOFwqMdVin2c/3NwvQwBeXsZHvcwQdWU7WNXOtU/apRDGW5ruHvmH/qwisWGBeAOijlwz2tbEa/Img1cug++jBuk94cGOkTIoW1ZmQs2FLflo/9srnyDdEAGtXg3KxcozVFLrqg9gOC/MrSwH5DU5KNzy+aVNCRd8tPk8TU+k+BON5/lE43kAnj50gM2T4tL1FzT1y8JrLwPfLlg6USR2cdOhIhiIRA4m/BsWzz9plBvN/7vxDgDqF3ymTokgDyZ9egvW8LgY8d+f/gQAv3Di/+LBQPzbPy6KtaCgZxecQRnCCHvKlfBVr5fGj5fB5Bn5HvvTAXlhOPWNi+2nNeWUrj80NxhshU7JKsrpmqCDCzvksYQVAfKqoroq30ZteUjSKipjFIMpdUv5/eP1hsY0pjGNaZfQ/bVcQ0V3sQhW3xhkL8ICfr9coZIJRWorjOJNGBZJkT60LqX2+Hzk+LDMUF8fuCL2qoJkWqy36+8IqV6T/X6Cc4fzngJruepI0T1ga+32PkRlPcU8eXe1hjtOnsH0xCKvXQoYvDgLQBRAxa7gUds4t8kfQLwtvIu2M5oXbba2Zlg/JqaAyg3/4impS/7iwYf4kX3inj5ePc+0dRcWGm22tFiuYadMEFQ2tUtcpVWfaNsmDlqKtCr36SeGoHf/E1r3g3Kj0daM8ri5C5+R07WlLkEHahfE7apdAi+TjG13r8fq1xcA+Eezf4q/t+crcvJI5YLG3FaCazdSVrXuuSk90bCnJbuPJJiLRHTQh7RmE3t9TcUmw4cTHplNkOoIV0Od1pULC/RnPDKrU4yC2CbJg6FxVQFZXWGdNMKOcZ5WXvGd/gqGhnjr1lVE91W5Gr+MiehQYiFg4yFWVpJJNVK2U8ZT0oZyrsHEmT7BugiiGqbk0xJTXPqeCumCKN3pr9aZOdm319FlLGbTELXlx9K6j7KNK3lFYi0FFUzrHvBJmh75s7tbCQSBJmiL9LXOa+dORR1NvFGUs0C4ITzxtnuYinzYg30tkoYc3z4MWV34M/W8oq1E6Z7NF/g7a38GgO9/+Bl+bPrLAHxk5jTD94oYnT61B29YNIP4bsHEQGNJGJrFiuFInDXs/fGZ4Za/SuEV8VHwnDL0lecUbWZy/uKsLFhPth7D3+zI4Uox+bIck0cNvETezW899U6++6PPAfDxao+hGYmluV/6Vjm9z6VYt01GlXph2PRcHHM4oVyoTgeK7kF7glIufJDVlKtKaR/wiNrlddu2KSDahtSGzPJ4RO/0cMo4jxXRll0Mh6Bsh1bQGwk1NP0yBDGA5sUBfvLaQddxWGBMYxrTmHaA7nNCS1YIkJWqqCu9IeCc4LJ8XmIYTpWB6NY5se2DjR6m6CeuKPK6WFc6MqiOPNJgRtHbI8tMZTUl6InlNPN86sIFeVQlq9v1ReFqMVNdugVeAr0FVdbD7lLKhgETr8h28+IAvy28SqdrbFg3f+MRQ+W6TW5dm6Rvkyb9wwnNaUmJJut1vC3h4cTZhOq6bK89GnLgQam3vDyYJLWmRjuvcP7rUhfbfHgTJUUEpE9OUVu24Ze0TFhUVnPShg07aFxVxh8XyhA5S01OW4tlOe3HeJRue2Hheni8K14HoPkdKwy+JqGc+OQlfNtHP1kJ2Dgu76x5KuCn5r8fgOPv/mfs8W8eqtK73FJ9NflDTf2yyGs4GdGfFZmLOqWr3j4EWa2oFvJILBRB0oL2ocJaNzQvyjH9Oc81q0RtQ14krjcNflJa98V3HW0YQiujynj05+SYwYyisiHvtDvvYwLZP5wAfzFGh69tn973sED3gGWQgnC7BFAYLWkoMnCjcdnJMzl+X9xbXQ3RsRyUNkPyijzgxCvKZQLTOmWZjwld/M8faMKO7UBKR6oU1Ai2gF/eg5/YEMEul9ewXS5ca2+romyDwMYJQ+tB6aaqpAEDvwg4+eSRbdwINFkmD686Pp6tIvByTe2yrIBJo8EDDbnOfzD7Zfe7Z7uzzD8l11lNJjn2kXMAvPhozNACvUy9kpHaRWww5TtextuaoH//W9/uJb26ays18jz/ZPNRloeiAX5y7ovM+raK/YbQgSa32ep/dPyX+eQnPwXAI2crmI6EvaKLqzQaiwB09wQMvizX/JuLf45/+sBv29/UpFaph/icy2R7TVfp6ZhtvcsdVGOkKgcIZqYIBtK5aTxFf1a0X9jxiNplF2cRtou2IJkWHs58Q5Ha8FZaL8uvtmdK/TJaihl2yq7M1gXt5DJpKIKivDNRTnaTCUVlrcA6MQwmPRcHvhntcq6PaUxjGtNbk+5vlaHiBk2fV6zlZMqiXTxcciuvGSrXbMHv9YT+olhC/iAnbcqtbz7oO2tVhxBvjbTAWst3MO3TPSIH1S5ETL4iN6GDsn1N5RYOD8EquKE4eHfnsgDwEk1vTxm019YqDRd7bG/L8hycrxAXyHMjljpakaW+vU65yg+nQuLiXUQWi8FSERaYr7R5/oDN6AYl77/n4ZN8bVIyEO3+vEtotRfK9bwT+USNt876XlilHsq53kOT4o20pP5Gdx8A//R3P0a4Lfuf+dB+/vWxXwZg1q+76+TGUHRsPxTm/Ox3/SoAf+ulH2bvL0uMx/QG1F+WjhkdzeNZD+PJz57gf/2+ZQDeUzvHCwP53RzFc23ZvtSZYnsQc2Xw8zvBjntGOvJgWqBIs9kGXlJm54tEqzLS0goSqiss1PY7h4SXxBQN+4buvm+F0Uxb2lWlZJSobLUlQ7Ql2/0ZTxoPELS8wgv0UsPGw6XSqq7Ju1O5YKLsCLbAnZDSJfQfBsJuCb5S3GTQw3VcdfaXnT29xcjBffkDn+2Hig9ZE21Zs71l0DZG09+TE3Rkf3C0zcGWZGKvNCcZrImyiTdN2a1lRhStLguNRzFidzMVDRkA0aZiOGMVbeaj+zaE0jIuC+oPlOO5STxMNKJ07WZvxndAFVlVUQ9KoNjEKpTYy5xrldU0bdst8PX+AWZr4tqufM8qK89JuVbQK2VA9Q1J6y2wct2EvmEVwDODI1SUBOj/cPsov/P0YwDMPauororwLiX7+eohef4PVzaoKRG605nmmcEhAD7ZuMr31lfk2n/5j/jyRWneqH/2RUjl+o1TITw8BcDscx6/FH4nAF94/CjX2lIx0+vFDms3TzzQijzd3WVaxlOsvW8egLQhlQEAU6+krloomTDEG/aEEYWm1kMaElGwmXsrl5vGfc9hxyOyXVZpkxvKp4rw33BKOVnUYVmiabyyqWni5RKXWFcV0bbBu0XK4K1jNoxpTGMa01uI7nvzoWeRmzBSWwqQNg2V67K/dTErV4cVj+qqLA3dRY/0w5L+a19pEO0Rq2jf9BaXVsWlmJvoulV7ytMsr0nwPwxyljZa9poVl4EcTpSg2KM1uErfCCWm3gKWax6Vlqg/xPWpD5oBKi3+weD1rduUgw4LiHVDqymJq/Whj9qWJIKfljXHeRVCu+QnxsezMGM1Lym9jq5HbpMnoae5sCFWVqs64PB7BbD51LlFmi+K5RZtGwcX+Vagwp0HeGEoFRJ/5+nvRl0WQY42FZO2zjKrGpKm8KJ63fBT35Qs/7cfOMN0KLL7xZWH6FsszMsPPMu5vlQLVP2ElcfF2nzoqRZ6w4I+X1mhVrO1yfM15r4u1z8X7sPMizugB8HIaA4l0ybM7vYOjCdZeRCdMJgppgCE1Jfk+1/4mnYWZ1ZVDKeEP81zHo0rNkE9yInXCzi70hOtrJZYI0G/DCn0Fke+maS0aIMExzMvxTXGeLnU4RaUx7dm7X2uFjCkDXnioOs5lz/qKFoXbLaznZHZDp7WuczFVrv74MScxJ6e3aoQRXLyf3zgS/zBxMOAxAG15dbKoElrr8U0zQPXFdSpDtmYkO4XfyNwSh1GphX4ZUbRH1i82N0tnwAuyx+1Syg/r+3jD2U7bJex7axhyKeFh42pHgcnxOeqRykrNeFP+2DDxfi8FPqWKSk+kVU0NX9IMlWM04Akl+P3Nrbwrc90vVOnb0Ec3n70Ei80pOOo+kSd+vK3FsLvRlrOYv751lEAtvIqL7Sl5ixvh0xcsaGoOUNm4emS2YzaeXnmuWdS+Iws7l+cfJeL+XlJKXO/mn+X8yM7+w3ZlPB348MHmHxCNLbJMryzgrtbzffgz0g8Zv5rIYlF2le6VBJ+Yog6mrWt3W0d6AhXWjWcyzG24L+3x6e7V3j70K90XQnlcL5GS4pS6C349OaEoRPnM1oXRZ66C4Fz8wezhnTCyuh0QqspjTSDXkxw0mKd1MC3kIPhwBD0CwzX8j7TGiNloqKobwXcMg4LjGlMYxrTDtD9TWjlZdua8YxLwhhf+tsBksmAxGaQKxvQ2WuhyE5s8cKStXjORdT2iKv08mAPPzjzVfcb17OW2/5a9wgA3SzmRF1W/E5eIX5QslWnewv89hfeCUD9indDo4BLbhmb3Nrdiz9QeoNZVZFMygO0HtykWRHzyPc0qx1ZqZNeTKMm+7/v8HN8cuIpAGpexguJ8PnnFz/MyYfFQpuY6PFo/QoATW/gPIRQ5WgL8qyGnqsoCEYi/YemNli3UIdX2hMcnBMr+dKfM5gnGrwV6Hq/yT/4/McBMNWcf/btvwiARnHqmWOAJAwLb6y10KG/LuGqaCth+qTIXFYPGE7ZRpcp5dCXkonSuqKVUW3Iu1n6WIXqNbGYwy89h7HNBd6V6wQVeTf1RFP0wqS1wDXGNE+38Va38Hq7HNGNsnLIBAbftnHr0GBs6Erlxg0fNCMu/9bDOZW9EmbZON9AV23CdqqPH9iW68t1fuTb/wiAH578GgPrOnyhe5z/Y0VauuNVz1UL9faU0JkqL5uLKmtlhU3YNfiJuWXI8P6GBbgRUmyU/IEtc0m0608fTPt0PiSxwO85eIrf/7XHAUjrhsS6q7+zdJxPTnwdgEejKrkRpXsyTUgtJ65nLc72ZbDo+5pn+EhFlMTZ6lk+XXs7ANovjXiVlUNh0UhGcJcr17xuOPadZwB4cXmBRxZlNMiPLH6VD1bLAXVnU1l8NnWN0HZQHAg2OWIloeHVyY2ce71X56PHBMP1L83+IQNTrj7FdqhyKEqwBorUvpeKn1IPE7fdTy2Moa/p2Tjjvuktzn7IBt5/4R4xYodIDRUTL8qzbT+o2BdI/P+55T0snpLnTBuxy24PupPE24UhoVh/RFz43p5y4atcUyRTlnf7+5htCbuMfiFTc23Of6/Ero+tHEa/LO9Yb28TLMs187kJ1yk0mPHpzVvl+pLGbLdB7+5GDX8A9Uu2+H8rcJ1YGM+V9yUzVYK2MLe9P3RK7uCJq0zFoiPOhZkzJGarHSJfnvtr/UOc7sr3f6Y+w/fW5fiuOcv0Q9Iht1qbwLedibqinU+vEuUUvD/w3b15qVQX3CpnMA4LjGlMYxrTDtCbUC0g/zcjRez+EDeffDAbuyzr6jsNP/42abX8ZnufM9WT/QnFrNO3TS+xaccMnEk7tK1vfy1vut/87Opxnn1JxiL33xU5y/WVZBEqYkX09umRYHXZRhuvCYzebq8YaFSH/J1D/xaAq/ubHAvFssqBSMmD1ZTPnoo8WKg67tzUhHS0rPg9nbCuxZr8xL7nmQ7kuEvpjKsW8Eei+HqkrEJp6A1kKc+0T2RftqcMm5vyxoILFfa/X/g/yAK8ylsjoaXyMmusq5qXbOhkcKHpsttBT5DrQSoEmhfEQlKZZvIH5ZlNr0r4Bal5nXtmyGDGjoI+U6UjBQj4SYAORKY3Z3P2n5D611d+dJGjf1eSuvn6BvkVaSLwwgDPvuN6JSBp2tlRjQjvgb1weneXZChtHLKVnyra9uP2cvBtLfz68ZjFL4j7r0PoWISs7549R2hR9CeigavEOFRZo+aJTG/sr3FhW6z/34sfxVeCLLbP32KuLvLdnozJtu3w1Eyh7YBIExtIRMbTVgnZmTTt1JTdUi2gKLOjWfXGXv6OxU/Nqor2Qbnjdz9+ir88KS7/tz//AfQ+eQFvP3KZt01IDHUh3GY5k9jWyeF+vrghlQMvr88ztC7qdK1PZVoqB766/ABfaMnk35V0AobCLX+gbiwutvI4mDOE22VXx26lUOUs+PJB7vV7xEr4qdGug2i0s6ijB+R2O8R326N0rLLk3P/E+CQjTIhUAVDio/zyXJ0XcHpl/DXJfYzdH28ozl4SF+2xI1e45pcx8t1MSpeKs3E24Cf1DwFw8LO5CxlNtjW1U3b+kDFge/yzPVNc/aJozmgbZp+XjyC+tEm8JDytLjSoL8vnGK8lDGdFAL3UkMdSYD85AWafbHuDIWZoP6aVVYjl3UeVkPqEXKe/UMHsrZJf2uXCq5SDnsxj5TL1Wc04SFB/aFBXZJGJtybpPyRKdD7a5mgsi8wH6qfZzCW239UxdatcH5+5wJdXDwPwtWsH+a2nJM/yzkfOcXpZZNFcqLlQYNrMXALDr2XSQQboXmlI9BeNlDveQrmOwwJjGtOYxrQD9LqWq1LqAPBLwCLS9f9zxph/qJSaBv41cAg4D/ygMWbjta4DssCH26ULVaBeGQX9WdHzjas53W8TU/1Tez9rxwlD1g2hIS7kDyw+5ZIx/9vZ76I9kFW706mglsp6vyIDqQ94fOywJGZCldO0BW2zQRtla0NrV5VDzjJKuWVnOAGDBb0jkIP3krexlxJaWLtVnZBbIOV1HXEmlXla7bzKei6uTy+P6Vjk3+2swvWBZO1X+w1S2whwuLXOkfoqAA9VVpj25b0MTIg/YulWbGY7WQvJBnbSxAgS0yAP3THdAyH0fXdM0bywE3Qv+auDEmUt3DbMPC3PUH9xycFlEoWYwKKL9Ycu1NU+XCdt2frugcfGw8L3KSaJr4kFlsc+8bqEbILNAeGKxcvzSj42N7dRFTnXhOWna/IcBuKZmTh0Q/eMDxh2ZE7ZveRtHsLmUSsTVcjqRYVACQmY1hXJ28X6HE4o3r5Xwix7ww2Oh6vuWoNAEtpfHxzgSCSJ2QPhmrNcV5YnmXxeGPLi1aPUJZ+FPzSsvcsm1esZumvHb+dKhn8CumKcvjChxsu8Wya63wjbM+CvG2OeVko1ga8rpX4X+DHgs8aYv6WU+mngp4GfutWFlMEVt+uoBHHxctzohavfn/AL7/yXALwnSvg3ncP2IIPXltv99Oq3cbkjoYD2by+63vb6EAbzthe+oalekR/o0WR5XtzPv7r3d0ltzcWpwSL+wH4w3ZJLwUCXDQ5birSlHJjMPaZ7xtvl9gSPfvqvyP1vBETbpb9ShGJqK2WXS2/ec/gDOoB403a2vZxR35KHP/XgPC8Vwt1SdA7J/tbeNt95QIBF5sM2dTtHpj+RoXw7fDAPqfiiLBrhkHfskY/hQmPKdXHVgsQ1Lzzzxnl2O3TP+DsKlxltKiZfsS7/fMspV78zRNlQgKnGYBVt/cqAxUyU4mDKULtuG2Y6KWooPK1e2pZFHWRht8pT9YfopRW730NFRXeLjwpHYqm2IkBt9ahsiWvcm/VuWeR+l3TPeIvCjXPSkSGv2snLm+XE12QKrvwpMZzy2NC0OBeTXs+VVlVUzpyVv+PxEov25NTg4rKTT0du5JDKpREA7AJkw1tK4Ywr3QkJtsvSsKIhJ+j5+IO7bCIwxiwZY562223gRWAf8H3AL9rDfhH491/vWmO6kca83Vka83fnaMzb16fbchiUUoeAdwJfBRaMMUsgjFZKzb/uBUw5m0blCn8kgWS9Vf7CI8/QUrLi/E/XH+fJdZsWTDzXL//UxQfQ1vpp6NJ1yCuQTspF42slFGHYUTxzSRIK/7v6KCs9qSSI/cxB8/mJJNNA4MeKguKgK+g6O939ere8DduK1ovCCC+Dxc+Lv9N9sEVv1vZhnx84/g+m6u7cxiXYfL+4lb3HjPSnAwQJ8UWxuCZf0cw+K8v0cHKC3/7+EwD8xWNPo2zwf27PFp7dDjztKgkyDZEt6N5T33YNBt59LB6+a9kdQQvTvsDSgSSNCqp3huSTYjXqOCBcEhc1vN5xbn5LKVRbQgGbHzlE3dZXB9e2MZPyTrztPsaCwSut0dblx/NR1bi4HRd2IAzANheQ5dSuFrPjKuhQuZH0O0V3y1ulcVMDhpMQXy9brrOG9a58qFr4UT9SnO9IqKs3HaPu5lsAACAASURBVLOcS0jrULBFbOeT9XTMwI4TOZ9OMlsRng/Opc4LjdqewxlJ6wqvYy3UoUeBtel3fGrLxddfYm2g7Cyue1EtoJRqAL8O/JfGmG2l3pi6UUr9BPATAMHElHO3dVhOAVDGYGvb+X9+7/38+oJk8/YsbLLdL6aJGVIbi/E9QxxZV3S+QtixcdkqRGslLmkBDBN0FeZ5EdxvnD3mevB1YLDoZnQXlasQyCumLLGYhfj4FqqycxJ6T3g7O8Ge770AwLVOg+wZiZV09vrObc3qgYsrbz2SE81LvHNjtsr/8oFfA+DB8DrLubwMD01q47jtvMoftR8C4EtXHmRPTT7gP7j+IOsvSWmRlypqV+W3znxHzPv3yf3085DJUI4f+oGrItAogh30Wwu6V7Ib2dCJl0N7rx2FcyGl/oLE9kynR/6oVKLkFZ9oROGZtsSrTZK677N+qU+wacu1kpTMjiuKukN0xS6UbQ+/ZZH58xzVGxQ3hxnKN6CiEFMTYdcTNdKGPTex45N2cA27F7yNapPOvY62y6qd/rxx4apRAJVcK848L5i1/4Q/RTUQK+o/2vslHrVx1vPpLJtaFrprWcvBZVau9jDfOAmA/8jDJAuimLt7IsK2rRwaSgwcIOyWeSKlccrUeBBuj0wyuQm9oWoBpVSIMPBfGmP+rd29opRMTLL/v3azc40xP2eMeY8x5j1+rX6zQ/5E0z3j7UTt/tzwW4zuGX/rY9l9Nd0r3obxW6MF+nbpjVQLKOCfAy8aY/7+yD/9JvAfAn/L/v833sgP5gWcYAjFqHXjKZS1qCqrinxDVuGr+bQ7rzrVp7HXBqgzn80lWc0jU7prXirWEEBeNc78dzCH3Ii0H/WUS6oNZ80NkIOeDVwn0zknpte4Etz7Yvd7yVtPwcuv7AUg2AqYNXaEdiLjte0PuoSi3/MYWtDw2qWA/+qrAomn22UAP5vICSbEOmo2+mxcFeii6mzPWQvnP3uIuTPWhUo0jQu2z3uzxZdOCHB01tSoSdsKW02YrMu9NcKEuWrZzHCv6Z7KboExATACoOylBtMR69O020RXBdreRCEkZU+/6dtsfpLg1WQhDC9ex9hjjKeIlooKAYWXiPmm61WUHYGu0gx00YPvgw0RmMBHx8WQTv++TNG4l7z1+xm1laKaokT+DzuKaLPg80jT0cAwY0fdv+Lvo3lG/uEnF46QWqS3iedC1/hz4odfJLCxkcGeGrXLtrb10hJxX3RMHs870P2wa9zw1Dwu65t1oFw4KN7U9Gf9u8YW+BDwo8BzSqkiqftfI8z7N0qpHwcuAj/wBq6FbaYCU84PT1umHCzYxAmEapfYlIMg4sjsGgCdJObACYlnvbRxeBS+EtugYRHN7W8qg28Lk+tLhsqmdvewfUheTH+/dmUW8apXNhQ0UtYHtRtKi+4h3TPe5pnHwd+U7eqFDfkQgbknBzb9CSotQxuHtuuuOHrl8QCvaAQYeDRsn3f1Gx7BUD7s2oWU+eeeBiD50+9g+VMSt977hwPCDVEcqldmy2e/uM3sl2zZShRirJur44C0Jd0ya4cjtv789TfGqTujeyq7BQVdqGzY2HInRUXybCYMUV0b7+wPMdrC3Hke3tyMPSZwlQBGKRc3Nb6PCQvtoVwoRwUeZFb2Qh/ykXLBAsjEV+4dC6hJkUfQmEC5heAe0z3lbW1FFMBwMnAKtcB1BpkEWyhXlePGv1RWfPZ8URa0rBUTdIoFbeDCLF8++RCVKZHRyUmf8JiEFMJvnpVFEKieXcc7uuCu76fW2NvUDupQ5YbBTOC2g765ZbXA6ypXY8wf8Nrr33e93vljem0a83ZnaczfnaMxb1+f7vuAQq8ApI5HsQUU2qLf6Mi4bVPNCZviTmarFTp2PtMH587y9IYkDmbecY3r6xIiCE5Xidfs9X2FbpUrdv2qbE+eHZBVrLU6FzCwY3lVopxbEPQF+BhgarrD5dPzpMMd6CK4hxSEOZsP2ns0zRLO0SvnayltyOwY8jxUdPfJ/rnvuuLc85dr8wTPSw3xxMlNeoda9lyNakjcsfL0ObZfERi84KCiaa2swcMthxKU1hX1ZbFi6xc6qCtiofppgldY1asHOf2db414m8pxY5XjtiZsF5h0Cj0n/FL1apk78j1MKM+m49ChVunIdzOilOZGq9KBQakS5yLTqLT0tLykDE8Vlq4OvBJush44j0RpQ1b1yiaHXUo68unNi+xmFUXNTh9JGp6bIOAnxmX281hhS6iprhi8gfBkcKhB5zFxh73EUF2Xc+tnPboPFJkoSCZFSP2jB0gn5Ph4pcPMSVFO194VO4vUy5Rrwa2sJ/QWLGB8XRF2ze7BFjCBcWEBlZcuvFFgrMAlLQNWR3g9n9S6UF6mWHpS8Ct//aEW2RWbwPEsRBjg+8Z1fYVdXI+ylwnSOMDy41WHFm9UKdyV656Ls2Q1qBwTV+PgxAa9a7OoXQ6JmWUenfdZhPUPZ8R2UkMU5G4iQK49VzY1SAO3YFxcnuZ8InGoYDVk4SXLiAtX8BdFoZooQNn+dZKUfZ+Ta24eDRhOyn4dlGVx/hDiTWFaOlkh1OIWq6U1OCixYTVMaX5p4t4zYwfIy8rYddDT+EPZzqo+WdVO1+2G5aIW3Nh3XihIHSg3XUOG39l/z0sl+2plGLYtAE5uMFZxGq8MHYgcj5xQ9MjXPLJYcasJpbuBVGZcWGDrcERi8WjDnmHohgaW+ZE8LgGgwq4ha4mCLKAWQfhjw6loH0KbR1h/GzTPyna0FRGtihJafc800ydl4oOXxu46ldXyw09aIanVHeG2KNhb8XaXs31MYxrTmN6adF8tVy/UbD9s2/0uB87N8vJyaFjQLc1wlMFblVUk7ErmG6Bn6mCLi+PrHmG3mBEtKFZgC5O3bIFwfOOoXDc2OyjBu/1hOZSw90DG43PScvj88h4qa+x4IfbdkucZtB1EGHyzSXfW9rXPDzF2v78RumdXBrIHJMg/M91h9aws80FX0d0nloA/d4I8ttfsZegj4jkEZ5eoroiV3N5fuvVRggsLeLmg4ssfEC3Je1e+R+ewnWE2MLsehLwgZUrrUEeK3JpRab20UHXolSEYM1KtkhuK+k8de2WiNSxrUL28TG7J3/J/Gd5XDIw0+IORDEph4Bpc/bKXGrysEFZfwgq7XHZNoFwSLhiW7n8WqxtwEVyzUFSa6qqLm1AwnFJuhHZWg8aVMjHmPOMJ7SY1tA/GNKUUm7SpaB+2Ya914xJaxlP05yws5JQitlgEzcspxlfuuJvRfVWuoV+i1ifT2pUFVVaVi8V6IRirRL28LCgOusZ1UPn9clyMn5YuAkY6lUAmyqYW0tUfQGWt6MSg7BvGuAmoeVw2Eew9tMrawOKP/lGL6ReH+P3drQWUMpiBfPD7Ptd2bmjeilC23MfvdlxWuX20Rf4uKf35M3tf4peufhCAyrpPVhUGdfYrqtflOmuP1dh4m2w//PNzTomEPYmHgbi2xbl5BFs2Bty6kEmtGGBaDdZOiNgFfejt2d18LUgH0F2woCx5Wd0CZamO8XwXg1O6HPmi9YjL7yunpL3UuPchJ5Wxca/gqTYua+4lBs++Vy83aL8IzKqREq1yCKXKDb42O1UtcM/IeIrBrMhK0Dc3THktKB8JbwxnjGvoCDuQ1eS9+ANcZ6U/hLBnMQouatbtQt/Y9hx/+jMe/VkJ6dSXtQOPMp5ymAbbB8v4a9gxDpegNx/ip+WoqpvROCwwpjGNaUw7QPfVcvWVIWyIWZpXPJK+nVkTBYQjKE65nVOjc1x9al5Rzi0wfolG8+rhgYVFIRUI9noRxLYu0UsUiW21VUo5yxUj880BNrtV+l0JRxz7nXW8rQ7ecHdntLQusyPnv6+Bl1grKCt5Zby6W9mzmoENMe1/ZfvdeF1Z/fMYpl6QwL5/+TqDRwWT4eqHY/y+zXhXA2dBBX19w+rtYBs9xfY+2Q47PsMJSWjNfOkKrQvWouhqgv4uB3K2ZHxcMkOZ0tMKO6VlqcPy+VVeWlpeTumaG5y8Km5MZLkQQVbuUxrCjoXCG47490o5cGeVl6GCrB64+zGedYl3ebUACgeT6GUjGA5B6ZWqpKxzjTYVlfWSR1ndWq7DskW2up678EJvzne6I9ou31dWLWvhB1Nlg01/3lBZLcx/CNtyzahjXH0tClJTJtluRvdVuWbaw7OQYFGckcV24mslJLPo6X7HI+gWnRJl6VZeEdxHsN0ahWvvgymSe6qELjNBiWKeV4yb4BivG5R9e8MpHM5A67xm6mnRruem5zF77Fv1FfnsBGZ1dysB39OELVm4vOkBaWKLnZVxPI/j1A1w6w0j2h1xiaIoIz4k1RHtuEnvtJRW1NS8c7lqS4bBjBW+hQpBv1CuhtAWbgedBK8v27oa0t0jq1jz0pDKadt/v7HF1DckppssNh2ozFuCCi88KUMBflpCZxqPEjk/0zfE7VxWWZXVADco1hEy3sgipXClW8YfwXAdqRDwUl0aGMaU19cWwV/v9rAAZc++gsxOxI03tXv2rCpxUZDmoyKGGq8b1vfbcI2G4aTs7+4PXMxb6XJxSyaUwyhB4fjW3Yf7Qwdlg5PSArcJ8v/iXYcdWVjvCnJwTGMa05jGdPt0Xy3XJA1Ir4ppmUwlBJEsJ9X6kGjCjrvtxQztiOF8M3CBaxgJBeTI5D1Lhbsw6kaQluf5A4UdPoDxSzNf5RBv2eaCF7ZgSayroD9POCkW3vbDLcKuxpzZ3etQlnvkdk6VH2jMNTHnJ15SJaxaA5bnLBPnhlh0NhZbbdfe2+tN0Ju3Sa99TRpLwuiZk302HxJL1x9ook3hj98ewqoAXputbXI718mrVplbeNQen5Puk2qEzvv3uXrEwZy55Wji3UZ+gfyXlpUrwcBIYgrbdlq4tL5yDRs64IYqjcKSNCNA9sYbndOmCPpl9l/b96eDEhfDH2iCdnFRRVYva2eLwnujIKvt/iYCwFmZekQejFcmtPO4HBoa6DJxNZwuGy7yaunpDieNe19Ru7xOVil/I+wokglbIz9QBL0yoeh0SgR2qAdBF+rXyveSVdTuaSJAGbTFSZS2armzZnXIQ5PikntKs2pHjixtt9jaFBfV9IOyRAvAgrH4A+UwWY1v3GSBoFsyXQelq0RXuYaCPCr7l9WJCZLHpdOm++iQDx6UGo2vvPcEtWWf7KndLqBKRlIAea4wlicLn19Fn78kR0QRnY89AsDSBypuWsHyMwccIvv+syn1F60L3+6U5UHTk8xu2OaCa2vkq9IKlwMqsCGd2Rn0AwLf2Vuo0t5nO+EeD0nsmBPjAxbb1agyRLPraQS4xUvLacB5OFr0X8b5jVd+eF5mXMxP5biyLOOX4S3jleVISosyKY4JbNZ7VNEaX0FR9pUZvMQ2NdR810gD3PLj3y1kPJwPrfRIHHRmZGiowlWuKA1JESKojVQU9bihsyopOjRH4txBX5QwiLI01sKorEL9mlyoN+dR2bBdYvWyuqO+nBFtyqqatiKSpnfLEs3dbY6NaUxjGtNblJS5jzVwSqnrQBdYfb1j7zPN8vr3dNAYM3c/buZO6C3OW9j9/G0DL7/Z9/Eq+uPC27ey7L4mb++rcgVQSj1ljHnPff3R16HdeE93QrvxOXbjPd0J7cbn2I33dKe0G5/lbu9pHBYY05jGNKYdoLFyHdOYxjSmHaA3Q7n+3Jvwm69Hu/Ge7oR243Psxnu6E9qNz7Eb7+lOaTc+y13d032PuY5pTGMa058EuivLVSn1caXUy0qp00qpn75XNzUmoTF/d47GvN05GvPWkjHmjv4DfOAMcASIgGeBR25x/MeRUpbTwE/f6e/ezX/AAeBzwIvASeCv2v3/HXAFeMb+92ffjPu7U/6OeTuW3d3C3zFvR657Fzf0AeAzI3//DPAz94LhO8jEPcC77HYTOAU8Ypn4k2+mUN4pf8e83Tnejvk75u3d8PZu2l/3AZdG/r4MvO81jn0vcDqcqJxp7JHWVmPUyYljMso28HK81xgAntv+wEx7+A6CRpHZ/QpD6BX7Dcb2vI52/RVXnjo+izEwdXyeyWNzxf6TcoyidWzh797sHgyKwfIW6Vb/fjYTvlH+vhc47VdqZ6KGHRqkOFldlAGOKofcogCpRBHYfusbEJnUCCzhyIV1qGBGGqu1Vm7SgR/l5AMRnWIOWn1qP9qH+MABov378VJQWnirNNRnD/xdsChPxaxHhWu77W5cXjX3r9D9tmW3Nhmeyabk9vyudzI+IPzFNxTYf8ozRL70QzaDIXXb6J7joSxnc+ORUSKBxXY4m0Hh2wb7WGUEtkU2M4YEn4cfi+nmMdWH9lJ5cA++p/GUOQkwTEIqD+0V/mbeDT2vKoN0c528271fsnv7ekFVzlR9i2yvONlqyOhrHXl4wwLaCge4DjJgEyCrl4hX/mAELS8WZDwAPINn35EBjC7ACDzAED2wD5Uq6jMHqE3vL9qSTxa/VdkrsovHDehmGMjW18k7N+ft3SjXm13wWzSkUuongJ8CWkEl4KM//xcAUZa9TBAUZisdGkFy0x9ZTwQIYHNYpRWJZtBGlZMCPM1C1Q4WU5rMYoKNKms9ImyZ8dzf2igyi9CgjSLNLXTZyLm58ci0x9P/2f99C1bsCL0uf0d56wUxx77/rwGiFAv8hHjDsPY+O1rnfMjUKZHEsHPjuJCgX/T7l5gMvfkQ/pJMbd3uVehdF55P79tk6yXBZ138agl315/x2HrY4mmulAMfo7YphT7EAcOYEKZPyu9+5d/8jQu3wZu7pduW3bjqM/8//hUAmk9W6Ry0kx6aOX7dDoOMUx6YFhCbD8+e4b21MwC0ddUZBtt5hdWs5X7joXgZgNQEND1ZaY6GG8xZeMGVPONKLgbJl7tH+VdnpKa9WRlSDUUxn744T7Upiry/VkVl5dijcMPj0j/+B7fJnrui2+at7wV8YPYHiv2kRxYB6O2t0LggQmR8RV4p1VV3r+iOa++FaFOed/JlTWrhCrcfhNQaBn49o1YX3ZFlPokdzKk3I4xVutUrARNn5B0NpjzyAnLQ4PCf84oRHGSQiSoalv72P3xNRtyNcr2MxCoK2g9cffVBxpifU0ptAN/tteo/fmpNVv+NtQbhkjDoVGTIG/ZjD0Y++sxDFQAtHc8BtKAEDBsEnejsYWHc2w9eZioSAU2N5xTta5EeUbSjNKqYravwZtDr8neUt2FU//H6SjHuGYatAuPSULkkwjR5WtM8J6amGmQunZnXY7y0HBWdNeT4qKNZekaAWNLZDDWCNGaK8ThhidS09bAhPiwLXadVo3JVruOlFr0IwT7Nq3JuMp+hX35T8FxvW3Z1q/nj7zwkBtk3w73sn5YROdooLp21BvflKi8fFFSQXhrRnpcvdDro8lAsM9lSE/BMWwDIF+I204GMNH8svsxDobyD9RzaWhRD1wR8uStjzH/rymOkT00BcGV/xpGHRDHH9YT+lvyWGvgO6LWy4uOn3BJzdAfotnkb+fUfVxULyjxMUJnccG/Oo7Jmx79sDsEq17QRsPY2kafF4yusbcuiv1ZpOKN9/u0r/Ht7xfhcS+vum469jKaFy2rnFZYGMn145UST7Y8ID1tBylRFlHrkZcxF8o4awZDQmsmhysmNxz/5x+3XZMTdKNcngaNKqcNI0PeHgB95jWMvAweybkjyh2Lx1NUIhFum3CC80TVudLBaXinRh3Q5+ZagB+E3RaCfvf4gtcMi9AenNpirCFNS7ZNYRZtpD23NKH3TRfbGEdQaRa493gQd+0b564S5RMEHIwBfDCc957rHWzleu2C6AotsH6R5OcspzYh6ItBK11h4UvavHw/pHRXrqBpm6MMyCe56NkltyYKbb0MlEmvqh9//JX7h2Q/ITyVVhygV9iEYFCDmvhtXfZ/ptmW3P4jo2JHLnzj6PE+cFTjFQSfCa8jDhd2A+FnhXXshZn8kVuzABPzi0gfdBfdUt9z2XCDy+u444lQqL+pvL32cB2viMRyrLHGssgTA74XHqS3LO+7vgz01OTfNfS735XdNpIkssHvYsShk91d2b5u3JvDJ563AZpqsKUaXl0Ie2zHYw5Toqshu0KxQvyxKcS1ddPOukgVN7YAouw/On+OR6hVApp5M+sLbGa9HYq2KS+kMD8TiFZyJ52lbhOxU+7RsvOrxxjkmfVG0OQrfMnNgQnLjUfFee0LJHStXY0ymlPoU8BkkMP3zxpiTr3H4k8DRO/2tP4l0G/wd8/Y2aSy7O0dj3pZ0V3iuxpgngCfewHGZUupTKufTo/iMBWhtHn9roBiK+UGy7bVxbmyqy+PzCBfba1zy0EuyAr7SmuDkPllVJmc67JsQayHyMmexjoYEbthGuaRApj3yNwkU843wd0SYP12EAnSg6C3acEpfRmSABWcO7dyyWugmxHq9YTkRt1FFV+WYrUMVOg/IdcI2eJtiHX383S/wlfXDAHzyz/0+/8Nn/zwAi19UrL9NrLv/ZvYlfm/hOADdz1UcgLOXwbI14pSG7uKbM+bldmXXG6pPv3xmLwBLcy20TYooBYtzIltXHw2Ilu14nWHIP3v5w+46R2YE/1YSs8KLd9fPczSU/adS+N2u5VceMWGFejOvcWogMciFapurNl6tahlntsQLXL40jUpssnGgiOwEZC+DLObmUdAdpNvlbVbzPr32NrEgo66heVY++rmvdN2xan0Lk9opxv0ai39o8YGjwGEOdw/U2T4oFu3/xyM89oiEcT5WO8+sLx9BqGIuZnL986niWioB1T9cOcLSqpyrO6ED7/7qkUPsb4qX9s7WJRfe8ZWm4iV4vLbndd/Aso0xT1QXRkIxpnT7FSWyuPHKcAFKsoEA4XaJLK5yHLp+XiknEaikvGZlVRFtifYe1Kc5aec5LR5coxWJH1EPhy6plr8q0WVGtrVRrgphN5Ix5ona3AG2D9lwRwxZRQSu1lfklZGZQXbG+/KHmvQW7BSGUzB5xiYLfc8NH9QBTHxQhGmzU6P1Ocno/urhd9IfiKL9QuUYftsClA9z0svywoYmpZfKMdW13KHybx3xCBZEuLO1Kp2P2Q9oNzY/WjLGPFFdPEB0TYS03W9haiJoc3u2aISSjH34yBKvDCXTbToxpm6BlVeqXK8Kf7998QxDiwa9mdf4/e7DAEz6PS4ORVkeqa262N6ZwTy/+e9kNVIGdKWsTFi+KvFXNfRcZtxLytHRSZk327VkjHmi8fAiqx8Sxbn/077kAwB1fR0y2TaeD1Oi/Ewckdflux1OxzcMZKytiOymT7T42Wd/EIDf/jMv8tf3fgaAaa/PK6nw7fRgkc9dE/5fPTNHZakcdFhZE362Ty3y7KQsbl/d9yD/+Qc+C8DecINNUyM1r20cjIFbxjSmMY1pB+i+jnlRBsJuMd9HuXKHUTIK58YEXUNWtRZkqNysIrFgC2tsZPbQiHFpgpHr9KD5ijzq+to812y22t/bY25SrKhmNMSzJwx14GZKGSTBdZ+TArdNyozMBtqGxkXZXv82jWcrK/LII5mx2ew9Bv+QPPtas0Zv0U6C3QI/sZUAsWLTjt/W6zHpETtm49Qk2lpKX3nhMabPFVaToXFB+PYHgwp/89hvAfBrP/M4z/6LtwFS1+p/TVzAxlXNte99i0x/VeDbGUvp/pTwioQ/VnvTDk35He84y3/xnWIhLQZbLGdiaf1S9X1cXxcz8tl4HxVfrLGTm3s41pKROh9uneKdNalGq3gpa5nw6DOXj7P/9yVEEK51aR+XWubelQpticyQTuTl9FQf0oa8j6CnMMHuH/WyGG/TXJDkXOV6jWzKuvBJE64Jd82eeQb7RRaNwpmF/RnflR0CTl9kdYjEm+cbv3uCT71P+HZ86hobQzmhm0V0k3JoV2yPx0C8LbJeX9EMpmyCcDvkucfEM9k/vcYgD2/p0d7fGVpmZICgNmWGGijGY43sQgfKfehSu2njiENT6ta8vKYuq1AwauS3TBmjjdcUtcQq7AsNVmfFjb26JyVsiBsXx5kr3dBGkedvXtz1jZJRkMcFr6AqyWb8viLbK2GQjWMVgq7Nvm6A2RZhreYlf8SVLOc3RS+KIKoMkokybhpt2CaOkZBT2vDdQve59iP89OyTABxa/B0+cUKy6/GGIpTviKidE7488mXsYlJZ+axqPSKzpYNB18Oz8vSN5w/zzUn5+KZaPR5fkBXuO/e9wu9clHjq6aV56rbm8tG5ZY7Vlt1vFFnpptcnVHbsfBbg2dKk1ffOsmXTP1nNwLxNk/cCF3OtrKlyHH0VyMpvYrdSVaWsX5fFZyrU5JGtPgHRE5b6dgx7Vim/RX8IlQ05Jq0pN/DS+GJAgJQNFiGU6+sttC3vVH6pR0ykGUzbb6MNaVXuId7IqC8J/4cTMVXfxn0xpCa4pXIdhwXGNKYxjWkH6P5aruCycF4Ovh1xLfF9m+Ec8RJNALpoeTPuEJmMWez2cGO2vbwcVuqNNnzdrBcWGYvcuGx3Xw3JI1n2shqkNmShI4MOwAx3t/tqAgjbhfkP29ZlrKxCL7RJu6h0Eb0UlLVwRi2bPKLk10hVRtYwrlbVH6pyaqmPq0wAReeIWFxfXTvEv47FfD4UXeeBE2Khrfeq9HviUl84GtHas3EvHv++UJF0DbqKZK88Z6agfklkw3g+bIhLuxFV+Z0t8YqmJrrM1MUqbUxtMB1LEu+DE2fYG5bPv5mLFX8xnXF1mZ3NKsMZmwz8s13Xuvno3hUmI7nml04+TLQux0RbBmv0ktXVDbXiu5UCpZzrGq100NViVK7C2ISWynMnf6Y+4oluaTJrZSYt5UJjQQc3LXo4ZWAox+S5Qtltr+u5Cchpw5DaCcVhx3MVNhjwbYJt8ozHV5YOAvBdEy8wMMFr1srDmxBzLVx1pUFZTegPRdGBVAGMtkqaEdvauWUapyS9Kbm60QAAIABJREFUkQ4U86re31FP3oUL/JH9o/+el/HgsIMbmesnBqNgpXfnz30/yEul1RUAhWsD9BJonSnd/CI+pXT5Lowq+aPykd7/kYqOZCbH61kBrRrMgmhmnXlgF55g2yfYku2LX9nP/9yS0qW9R69z5aJkwlUlx/RE7KI1n3a9kOLdTV4u5Wgg4SrVs4utkVJCAJTwydFAjlntTFA/bBea+jpd67ueG87xSEUK3esq4VI27U6tWMyB2qmY9j55OX/tsbK6qa0rXBmKq0vi4feL3ATYUC86AHUj1MCuJG1G3HPPYzgrMuFNVoiXJCZNmhF2iyoWz40e91PD9mHZHswYKqt2f1LKsZ8ojK0uol/yKtpWripA5YrBvHHnRp0ibp2ibPdi5fKQSy/LO+o+HNH0Bg4P4mY0DguMaUxjGtMO0P21XHVpoSqD8+Gjtna1ap29N7rfRT0rqrTMoo5m64gFaEnKgHZegdFuNGeNjVi6jOTRjD9y/EjYwR8a4i1ZrWrnpUA86BXZsd1JKjc0luWeVVYW5/fnlEtupRHOZYzaxoVOhtOK7SNyrpco52IC2Pg90Zrv6mXzVo5vD1G9gIUjktGthSlXN8RsGi7VaJ6Re9hYWiSygBdZzadxRU6uX9Vcq5XZ2t1MRkHQs/3pG5CsybN195ZgHkGndAGaCx3ay013flHze7k3SWSrBXSkHG7AnnCD53pSB36hN81EKEmv5iVN+4Dw60C05qoIltJJ+rlcc/rAJpstCUFk5yukzULwDSYwDgdit1LXhITrooqyyQq5dfNVJwffYmTkmrAjfBtORM4aHzZ9hpNWtpo5ZkOuE28aASEChjPl8wd95eTeSyDaLnSQcS34RkFlXb4Hf3uAGtgT+gPql8VyXc8bhCrfXdUCRfY/rSmymjxMWi8/5gKCDqC3oGw8VtyytCEPkrR8kpb90KuGwZzN/ukyzqJyqF6zbn5vNKiIU7R+YtDBCBiJvY1gaKhetD7g2iZ6fROT3hy1a7eQyiHeEE0YbA7oz0qn2mBBk7ZsiCA1xGu246prnMvfixXxosQ9lDL0W+KWVc+HZezawEPvlI6Xq9stuudFiXo5rFy3xd25YnZO+Pb+957n81XJkNfPhHgW9MXMDDFXJaCtA4WJ3hRsgTuiood9OF1m5IOecoBC/pCy0cCvoyrC4JnZNo/NCD7A461z9Cw4Rq24CHBqsIc/WDkCwPKFGcJ1USpzQ01qqzR+d+ttNOxN7Ik2+VD9FADfO/0NBjbY+I23HWQzLSswrg0bfLZa/s5upNx4xB37bU9FVK6L0AUbPbITD8j+iYjqFZGtaDJAh8Kfwawiq1sZ8o2raGmdM0T2E+5pRWDzEUFXuXBYvGmIN61Bog11G+tNmwovsWWH/SFkFjEuTV24cKhDhoQ3BX4qaBwWGNOYxjSmHaD7nNAqmwLSuqJ5xbpHQdkgUFnp0d8rLk5nX0DzUoniHNj+9KThMXFOlpDuok9u696mXxyS1WRF23wwoL9gg9uXIOjbmjdfwhAA0UaCtqg7fi8jmZLVP234Nyw7yvdQrw1+sysojxVpTV6nNwydh2B8Q9CRh5l6RaO07cn2FL4FIm5chu1AXFilQS1YXMuFnMRmVieOr7nfaq80iKylkVcNwWWxxCpriq0Z4eHnZyYIJ8RiCj/QpntV6hhnZzpsvVveXfT5Gmpid3sEBY1WVGQVXFjES8vESV6F6jUrc4OI5BFxw941f8lZnBeHM8TWdEqNz5WheBi/ffoE2TWbyMmUq/wwviJdEB4tD1rMRlJFoI1yLbKLwSYfqYpl/L7KVU7bfvm1vMFcsM1z0WvD4u0KUiNeYy8nWLewmMOU85+QRGjj0XWSfyUJvPrSkN6MfLfJRAk/apLAhb2CgUbZyop4zb8hGR7aKqXK/8/em0dZdl3nfb9zpzfXq7Gru3ruRmMGSAwEZ1ISB0m0JMqiLdmWHTmhRMu24sjTsuIktpKslWh5JU4kZ0U2bdmSTNkyJcqiLFKRORviABJsYm400PNQ8/hevekO5+SPfd65r0D0AKCqUbDfXgsLt1+dd9+9+557zt7f3vvba9pBgTryqM7Ll9dGQreOECcuY4FMbylY8FT+/ZeTW56K1avL1ZRWDEkfFih77iK9tMTSmyz5hYa42q8bVsS6j7kawpYlKN700Hbh7I0FFFbl8/Kix0bNprCcgPoLcp7KQkpx1pJrr2262mXdaFLZMwlA+/YpvE1ba7/ZEtxHXUeLu0B0BNpGULuTRbTffzk1ZQuP1P79Sbxj4mZt3jXuKBzDtmHiOXlRezXPRVyVUWzcJucfL3c4tygTvTAf5sUDJud2CNqGqqUKyBZCdEFWnfVjKZMHpfxlZblGUBCdr74p44HDkgt3YTuVsQOifXFBQe63N9YvqFDuJQ6becZJVlJkNlugmeSliOtJmXG7QK4kFZ5YEW7XtBvSb1CgQ+0KZoqrKVFZdva7qnnBwZXuGFe6sjCn2qc7dRKA+6I5MvsyPdM5wL2lK44QfreKwtDdJ3PCizWqJ/e7/tA0D7/neQB+fuY/8j/9jBAErfzbgy52E7QUxaV+hoChT+EcdLSDGMNN3y3eXmIorhs3Piv2CW80YcPCau1gIB1RQybvhm63SSzXyeFomdj4hFw7120ICwxlKEMZyg7ILbVcta+IR77bck3LedR+9c6Izn7ZxSoXArJSPxgjkW8QC8IocUWTCpSXLHP5Hg/tW6LnTKK6AO29sC6xFSrzBq9pt7TAl50JIMvQy6tybYGPadkAj+9jst2fiT2YEaHDPFfY63qENmfPZJnzZ1WG9H8i/x7Ibl5elvvNIo+0JKbA0tWDaNvaRFc1WVmOy5cDF+hRmaG0qt35+5ke0YZP/Lx4BVUfdGif3W0xp5f2bJ8SdlCUybMFQOHbktewYdBRzsrUL800Cnwb0Iq1z5ptVzQWtenYPNeeDrh/XEj6H5y87CzcFzemmGsKE1MWea7/04dHvsNvrb0NEEZ9z7oPa1nIrGV6OhSsumu+0Jng2eY+VpNL26yN7ZWeDglsYFNHHmuPyL13/vw6P7vvSwDs9Xv809t+G4C//pM/zvKvSzL/xDOJg7e8RKP7pbONmK7tBJGW8qyA4roh6PShMbFYAcJm6qCf+tmY4iXxtEy35yxXtCGelONj0SLP9fZfl3Lk1i6uIez/oDzoFy5NQ8emU/U8Ry6iD3Scm9WZ9twkDlqK7t5+1rs13bFkJSo3wHuj1v2fz6jM5TRs7Rn5fOWeCD+27u35ZfSaVaIx+NVK//SoQM6fdbru77td+q56WlQusd1LFaHtj+UfP0zjrjE3vp/+lhbzSp6gZ2hN57BMedE2zVvPCJs2XaaiMFbnxTWdp9dl5BM91nh2Yc4in9rlxP1mf0L7nYjGXW8M58lLDaXlHK/uGwlZmOvO7+VVbM2j4NnGmc8t7HUdGsbKHZeW1WgXGSnL/Cr4GcdHJKXtjtFFrkzLc4prEb2WLMZP9A7y7tpp+S2luZpIWtBgxPqLm3e71jEP1i6RGJ/HrtGfbrdIK4s48i3RydoJeNdPPw7A35z6En0agSUdsGor2H7p6O/xow/+PAC3/3rbxRFUu+fSO021ROOQXd4UrjFnuJkRtHNjyXVAAbqToufq86swL/mL2d1H8J8XQh2Mdj23nugeZjmpkZhrL6FvjJk9lKEMZShvMLm1AS0F/8PRPwRg/VCZy4lYkInxaVtTazGpuY6vjcMlmrZv0WqrzEhoAyGNMs0TYvJ7XY+u7Q9XWvCon5VdqT3lU7FJ9cV14yyN9n7NuaOWxHn2AHtOiltaurSB8exe04vzCKHRqChyjRJ3s/StRqFntC75uiLasFHQt+xh9S75fOIZQ9KncxzgHPAHot9pUVG9IlaPlxp64znkUj8v5ww3M9eme0u7bsC3pNt+TxPXbIlsVxN05bnUL6S09+3uYEtf0qJi7Q7LIRBAb8oWXYzGmD5fxlyR0NaqZ5UU3bMN9RoRvYrortOL6G6KhaQ2A7qpzdLI4GJdJnJYjfHnrOuhDGrNEpOv38GdFQlqnWnvoRIIHnOitOAYteaSUdeA772li1SUxyf8geTxXShjYdvBf51HWvyD6S8DkBjoIzFtHbqS4MOB4eg9tuehP4KyOaksr6EKotu1R6ZpHLd57k3l5ma0HhOsiz5M4BHad76zv8LlH5IxR7qjlBti/b/w0QL7/9jma//uY5QvyTNdSyvX5RWAW52KlcEnV6SF+Q+OPckHKhIJnPY9fHuhJ+MiT3elUuWh4gWupuIezad1x9R+dXSU8IhM7oVOjY2eLLSzlUlUKrfUebjNSst2MZ3PK2e8RJHZpOPu3R0u2sWGxji1F+XlmXy6R+Ep4cVTpZJABN3dvbiqDIrnBW8zxyfwqpYybdWgbOPCxUegdEjuK3ys4iCXQT4HgOqs3aAmfdfCuLScOjKL4OE1NpQ8lz2PJ65bJ55CZXIcjxZckYjxoDPepyj0qMxb3H2hy+RTspGe20Zd7ISYimb8XbKw7Sk32WvbuY+HLdc2+7ejh8jOCLRUvhygbUudtGrIbEpbnBYorud0jX2ayKipiGxGS1oJc5imq4nWZF72soAvLQlz/ukzM47sJKjHPHRY4La1bpm2TSk8Hi5yOOjsekhrRPX4Oz/77wBJK+tLqBQFi2rOBB36e3fPKP7U3mcA+K0Hv5+p78hC6GV5RZfxYPSU6Ke8klK+IpuPv7DuMoRUEKDHZXO7/D6ff/ju3wPgnzz+EUqPyQJcqHdZ+Qn53fpjB5j5E/n8Wx86zI9MPUGkrl25OYQFhjKUoQxlB+SGlqtS6iDwm8BehDDw48aYX1ZKjQP/DjiCpCn+uDHmuvxxxoMXG+L6aN7Me0YEnH9r8TJHQ6mZvjNs4SMA8rTf4ZitsfaYo1mRreuXl7+Ht1XPAjCzZ83BCxdnJjn/gESlW2nk+mMtH6ywYJng9UKR0mW5bT8OHLluUjc0bxdzoXk8oPrAHXL+/9REXZjfkTzX7dStyiA7cx6AcrtL9hbJn8xC34H25cMN9tRkl9dpGd+6U17qoXROSt4v6CitZnl5sMrLiZunRrHsjOjQQ1eshVb2CBuyk3fHfcK2JZRuGwc7VC93yGwDRH9lk+LoQJ/0bZbt1O9Uqcl/ffhrAIQqdS2VExM4a+tf997KuDwCwpZ2UJR3BZd10Zk2xONWL5vKJcD7HVymBSt5cLK4GuMl4jI0kqIjcScw1J8Rz6w76fMtLdHzYimmEYtOn16f4U9NP8Oa/uYr0tvNyHbqNkHx5oLkO2coEmtplz2fVRusGiSr30h93mu93j/6iXtoL+wDoLacB2tVJmXKILnw/XbdOppwY9ozRWbfI8d/4T1f5UQknknjKOyxHph5ocoPf+gbAHzjLY9Q/WOxmJ+4dDv/1d6vOa/l5eRmYIEU+NvGmJNKqRrwbaXU54C/DHzBGPNLSqlfAH4B+HvXO5EJoJPKhHhmdR9//PxdAJSeLdHeJxf5gbc/ySM1maFPG9/VX0cqc8cfqD/DXl/c23EvZsoTk//OaI5uVW7pajrmarj/7dVHyFJZYEaPr9GclskazxWpXrAVSOcM2jbvi+uK1ow84CvfV2PmUQ/zRJ+Hb1tl23SbFSH9vgcB8J84T+1xobLTbztAMiI6KUUJqy1xw0eBoNWvkAtdQQEmx18Lq4njsvTaMdG66G30TJ6UnZU8olXBZUuXcmwv2iiQ2YoxlWiK8zaMrrVbXAkDl5mwQ7Jt+i2pmL2hLKKZ8Rz+p/E4GMhcNK2Aiadk80pGIpqHZP5NPZkMFFoENG0jSWVg5JzNxmhowmafu9S4zc4EeRuj56/uZXJM4Ig7jsxxOpauB17HQ1vax8pYTKsnC8n6Zpkv+HfSSJ965Zq7sWzf3MWjZaPu2ni0+662zuhn82sUTcuf4ClNZKn+/ttDX+B/nv4pAKrtDiqU93TxLfC//9BvAfCF9bt5cll0tb6ZU1zeu+8sH5t6ApD15Wws8Rd1pIWK5Dxjzxv2/aiQN80/4nHb5yzt5mZAU5fIruP83xAWMMbMGWNO2uMmcArYD3wY+A077DeAH73RuYayVYa63VkZ6nfnZKjbG8srMhuUUkeAB4DHgGljzByIopVSN8wGD9qw9gUx4XvjhqmnZXcee3ady98vpXxf+90HeOp7hWR5rNhhvCBW6UjYZbknwYL7R64yGcgOvmop2EAau/VL/8pezGcW7gOg+3/PcPucnGf2PRPc9WEJn7T2RFzUsqN1ppUr+zQeVK5YCsRDhtV7yqSndxaefq26NZHh4g/KbruvfoKRr10AoP7teZr3TwOwdHHMZT2M6Qy/ZfMf66EjLldJnnVgAuWseaKA1Lr/fi8jtOzh3f21vBa83cXUxDJORiLiuh3f0RR7fZZ0n3BFvpuNFF2O7E7La9WvpwyZNddXs3zOlb0ez8WiX3/Tx1+Xe2vvLzsYpXS54ZiVwo0q1VmbQ130CJv282Ys5dggQRlb7LH6wDidA6K7arnnclo3ekUOH1u092ZYb4tFVonynNaJSptOen3mpu2Q16pbhXFdGEa8LrHV81JWcO+zj6GhJXC9x9903z0RLtPeZwOzi0sEe+VZlI82+HBF8obfXfwcoR2zkHlcTQUibJuC80C6JmRUybM7PLUGEwIxZJHitoLABccfuYSakfOTKab8xnXLX296cVVKVYFPAT9vjGmom8QglVIfAz4GUCiOUr1iK3vmFLVLlsziB0f51Z/5fwH46U/+VfzPyg0sHzRoy0Wpq5mLjj5RP8DecXHFCkFKxSZJB17mcFZPGVb/hdTRT5y8BDZF48C/XuDp244CcPi2RXSxX1HkkVj6TTPQ6NBLYPNA3j5iJ2Q7dOuPj7osiOX7AqJ1wVyLz12hclZ05XdG86wAbVCb4sb7vZKrscbgXNK04hPadKruTJml+3No5PCnZUENWim9/UI5GG4U0FF/QU0pt2Ti9sYKjoxHh8pRI6pE05nc+Zjqduh3ciZ02P5yUqNtJ0QzLeLRT/NRmJIl/6koKgsWdjl91qX2RckR1F6rrwZ4Fnbx1zfBFqxQLGBsh4bmIY977pQYxNmlSeojOQlLsyewwyN7LpKOCiwwGrT5vRffBMBto8tMFjZ50t85LuLt0m1fyl7iUpzmszrzidXVQL+aaOC47PXy4iLluff88NgabW1xcaBt53SGcjhpNwuJlehNG4+yLTU8Ul3l/IzEXDYPKvd779vzPJ++7/3yU5lch7pOjdZNzWylVIgo8LeMMb9nP15QSu2zf98HLL7cd40xHzfGPGyMeTgMKzfzc/9FyXbp1q8Ndftysl36rY/f+nZzu12Gur2+3Ey2gAJ+DThljPnHA3/6A+CngF+y///0jc6VFZSrvfYSSGo2J3Um34nSfT32fkp2nMZiJe9DXsovVYcVViqymGRFHFmxjow7Dloet31HaPJmP3yE9ftld7vzV5vsfVT2lOW9FYy1XKNZn8lnLBVcxaM72qeOU+jCzriu26lbwJUN98Y1K/eKVbOns5dwtl9vPkrhoM0WKJQcw3q40cOLxXrICjlDWXGx6xiKgs2YKUTn7ckAE/XpDVMHF2SlkKRuzxN5hC15rmnFcyxdXmrwO7a5Xzlk8/DOwQLbqV+NQluzfzJssmhp/Z7enKFh86x7k5pzPy7wVrSuKC1Zi+rNd+YkS3Hq8oJ7U0UqpyRYYjbbNN4rZNlpUVGy/A7dPZqgb2ltRoS2tr2XBTw4JRH2D40+hWcDPM90D3JwQgJvlSDmGwtHaCXb73Ztp25T4zmoReM5iMBTmikL/zV1kdgGvRazmoMDa36XwNJWeqUipizPYixqMJv1te6zosUT0Maja+wcxaORyedz8ajLADm9vodSW47TSoHH2+LpbqQleiMyB4IWXErGic3Va97XzWwZ7wT+EvC0UuoJ+9nfR5T3SaXUR4FLwJ+9iXO5FJOsIB0F5ELzdhdqNcK7IIz3I+kedFkU4cV5a1ddCFxqiw491xYiLSoX9a7MxW58+Ufm+X9u/10AfubKz3HkkwsArN8xTdmSjpQXDIWVnr3GyPHoFdcMaVE5cpJtlm3Vbb9XmjLQ3iv3vnFbmfG2TD6/qzg0LlkxGyNVKtZV9ToJXscuoqHv2mPIH/stNzqUrtg2J0sBmevQiStSyMoBviXFyCLPPYvCauoWVC/J3G+t3FfBO9y6qVt7lbJt+h2k7dPGo2vL2MYLbfaXZYFc3FeFs7IBdR9oc/Hefi+cCGN5NGa+4FOek8nUq/uUNwSyYe8Uc++0c/eyR2IpBytH13nTqCyih+5bZd2mZV3eHHPpSZ9dv5+Hq5Jhs5CMcKBi6R17ZVrdaKcw1+3TLT6nuhJnqfpdzrQFpj1cXOUdlRcBGPVbDvOeT+tciYVXoeglaGtUqFIRVuTev3nxMI+OCl/meLDpnldbF9x315OygyAaSZHRUGCyy5cmuWtV8FodVjjbnnLX2ueFrp9WvNDdR9c8f837uuHiaoz5E65NCfu+G31/KNeWoW53Vob63TkZ6vbGckvBDi+F8tJA9wFr8Uw86fO79z4AwPhTCles7Su8rlg53rlZdNuWsEURQZSD4KpoyYij0FEIms0WZr/sgLePzvNiLDRm3X0ZxrbrPfyHJbyGrTOeW3TUYuVKhT7huD60h85MxV3rG0FUmvMDNI4riusSqSsuKVY7cme6ovKySK3BAv6qF+NleWK0CWyDOG0gtnmYXl50oFKdZx0AqmVZnsIcOjBRQFrpeyApxkIEzUMQRbu78WNfMuNxoSsBrZKfOBfyRGWRCx2bmH6+wp7HRXdzxSLG0jJ6PQ8zYnWnDa2ZPl2mwtggVm9/zfFBFNYNzSNySj/z+MQX3g2ALmlHOl4IUr45J4UDvSTg3KQUzxyqrHGiLPN7JawQ64DZYHdTZsY6ILEs17Ww6yxIX2lHq7iSjnDZsoBtpOUt1rhxlmuJbF7uffL3j/GJMSm1//CBJx2k09YRc10Jkl1pjdLLZI6Ww9idszAXODhMFzQtGyRvp5HzvEdf7PDUxn7XJPLl5JYjyf2Kn3AzI2ja5POrGd1/IhhW+dlL6LYo13vhkuNS1WmK6Yk7ZXq9rRVTA5SDyrqiRhuCEVlUXlifomY5x4KGh+nI+dVz59CJTHqTJnilPMFYFeUFyEohQSvjOu3Jd4d4BjUq+tSNiH4hdrdmWD8mjznaMCxdFUxw36YBq08y7TYlNXAMoJI+56tB2e6b/mYn73OSaegXIKQZJraZAJWSe0a6EAisY6V1TJ51VoTN1YG+GbtYfKXZtORCY2GbNdsE8KsLx9h4zCafD3RZPfi5jMZhq/emYfUeeQk3jirK830qTFDlkv087+4QdIyjgzTPjXD0C/Kclt5UZDkS3WFAtWxmxlSXZ89ISuGp5mE++j7hQP3w2En+VfLuLZH23SiBythvyZdrfpcHypIdMeq3HU/tU+2DLPTk3o+Wl0ksTDPbG0XZ1J5sss7KB4SXZPSFDtk/lsX4n33gg8zcL+lU94/POiigEKTuu+0kYr4p68XoaePmtNKKVMtcb/SKrjNKsRyw0im7v72cDLkFhjKUoQxlB+TWkmUHQgUIEJY9gpGczLa4IlZXOjOOmhbrilS7oJTXS1HWyiROMEnijvtwAdo4SEF5CrMiu+HqN+7l9Lvl/OPPGpdzaPSAq688TP/87TbYVtrh6R6qXMTr7fIOhYBnOwukxQx6/Y5vmvZMv8U4qLjficCgW9b96vQwhX6ASrkgFt2es/IHvQP5MZWPt9aqiWO0PQ7KMy5x3l9roatioa3fXaN5WM7lJQaz8cZIw4lNwFxH3MnLrTHOLQkUEM9VGLeBvmREue4LxdWU0rLcZ7SRMqZEvwvvS/Bs9L4yp9FHJZCz+taEQlUs1NZijZJtl5XUYPEhgb3aM9rleqMVlcs2kLtapmBTZKMNwxfukxzNY4VFTs4f2JFsge2WnsWxamEHbW2+2Pgusj8ZbjIWSvDzYLjKaSPFSJ0soliWd1UZ4zqOrN5X5PZ/JRDK7f+sx/m/KOMvfE/X8TN00tDlKGujWFsQy/hQQ9O6W2DEoOm5bhmeZ2BC9L8ehnQ3r2+53vKZ7bIFIkVmG+rpADrjMoFUlo8xPq6LqZfmfKFKDyb5G1eT7XdTVM/2IU8y6Nqk4H+/RuM5Saof/8o5Mm+AQ7SP7xqD0bY/eZovpMr38fTIFld5t0raGsB/+s889UhrNn1nLKCwbGvQr7bcvWeLS3gFcXlNoYCyLr/JtLS5sMd9Ub6H6jO3hEG+0IYh3gAnbh+XJQzIqjLeTyByrHI5i/9ul24WcH5V3MxOJyJbl/sJuorEuophw9Ad76cOFh1FY3c8omObG45PNWiPCj468UzieBzCxRCu2Ij2fu04L0qLxkFpWUmjbOsYkymCrry+E6cSUpsxs/CwR9KUNKVvbB6nXIhdm5jdKpnxuNQT3Za9HgcjSaEc9dqugmrUb2/JFmiksl4kxiPuWZ7hXotoTXQ18p5FrvyAFCMd/MwKI2dFB6eO76VsN7GZkYbbeJYbFbymbWl0v+fIdbLRhGTNPkjfwAkLe3U8vF7o8N6XkyEsMJShDGUoOyC3PqDVN64CnNWSRcrVtnsKsoGrcpR34KKpg5ar9gELNXhJIa+Rz8Cz5w83MypXxW+K7zpAcEDy1rxmN/8hYxzRM1q7KDmeJ8GbzTeA+9o3LgMDgf1H10dZ8ygeMew5aRuynZt3VdEmScl6eSJvv3+YiiJnoSpPOWhAFaI80yBNczjFmJysuBfneTph4OCdwnpKf9oZ38spuHa5JJnvgh/lco8ktE0cG1W6U7a1+7hyRSzJVELpouiufkaz8pCMP1pr8uwhcT8bRyOmviWwS7ihyErWRS0aWgfkuHopz6pRA1ZSbazNxp2ix7EXDIH1QoqrPq2KeRwIAAAgAElEQVQrEpj5o/hujk6tXJcWbzdIYnzObYo138lCNkoSLNwXrjlmO8BlaGykZZZisc7n2nXMVbEsuwcD4roNUPUiWvfI+z3fHHcBQt0MaVs1bpYiuolljCskcEBgh+JtMdiiGs8zxLHM6WSjgF/rZxF4FEvX9wpeN1jAKFyWnJcZh1XpIP/cqK0QQf/YS8wWd9IttICymJTycE36erWA7Ih1HbTBtzXZflLLz+/huqAq7WoIUJk07ctmd/fiqhSoklWKAWXxV60VtOzkqOu8O2m3u/UEA1BJP0PDdHso77ub26lO4BbXLbXkvu+o2lQYujpvE/juGanUuMqtqKkwwRtjcU0zn27H3o9R1KoWi757lY6l+AuCjHZL5pZajVz34eqVHlNfFzf2Wf8AKpL7b3xfm8ZxwXGTqZjRSameu3tshXIgL/ET8/tpLdjS5jDHXI1RGPu8s4JHd8ymzKWCEwIklFgsVa+LC+4G6WUBS225xzjzWerKwpma46x3ZeEsBCljlsSpHnZZaMsG1UlCsnHR1aUPhBSOWc6RMMUblfHrb4OgIAbA3nqLNBNd+cpQtK2jQk+7VKxOLyJJZEypFDM+Ysl4iokb3+5FArmoay+uu1vrQxnKUIbyBpVb20NLg+2dhvFxDE1KW4uV/P/5l/LDzNYKGC8nEN4iRgJfAF5sBqwlaXsMAhX0mfZRA9cwEEjLIuXgCz82JOWtPaZ2q/gWCjDkbZ1NpnJXXRmWHrAR7OYdVJ+RMmDT3Mwj/tnWCJNr1IgE9+SHfPdYtliuhYJrEGeKkRR1ALoU5haqyqEelYHf2d3Blr54nqZia6W1UZRsq+yDtXXOrolLu7w4QuUFG7gbcAzSso/XbwCVKcIr1rrNILvN5lwnHuuzYo092SxRrcoJvv/wKZb2iSV3eXOMy4sS+EkSH89awLPvznNkMQYvzp+J75kbtNHbHVIMLGuYn7HYFlijHYc0Lbm1H2SkY7adu59QCeVZTBRblI7Is1iYqDJtO20kmY+251RjhpFiz/5Owoq1krVRdKz7v7BZIrOE48o3BLa4xRhFrdD/bsqapXb0PM16o0y2m7IF+uKlxtWwZ4V8wfNSHESgNG5xVRm52z7wPhovH2MGoAAdKgfneRkOj/SSHItVWY77EuYLszJmCxaofXXtQr9dIkoZ/IFKHN+30c7Ud6RoKlNkNnNg7h0+kxXbHuNCG99ysnqdHiT9hVaj+ourp6CPxQYvmTb9TIpiQXBUgIEKLV0MyUL5XBc8V6Hlx2ZrMcguFqXgninJjzo5e4DZc7KgzkbjzlUvzoWElhHQ+Hl2y/qJiOYAQU0/oj12JmV9Q/DFzWOZ49o1WtGYkwXmi+p23jwt5CCPTF6kk9jF4NI4XlWeUzbdw3TsMwk04ZKMCZoerW60pUXKbhRjYKMjltNGp8hmS47DKCWw2HYwMLfbaUTXVkZtxCXnzk9U2m5MK47cwtlpR2y2ZWEIw4z2sui8ON7F9W6cLRLaTSnZF5OlstC2NgrM2SG+p2nM2m69WkGmMMmwiGAoQxnKUG6pqFvZdlcptQS0gOVb9qM3J5Pc+JoOG2OmbjDmdZM3uG5h9+u3CZx+va/jJfKfi27fyHP3mrq9pYsrgFLqcWPMw7f0R28gu/GaXo3sxvvYjdf0amQ33sduvKZXK7vxXl7rNQ1hgaEMZShD2QEZLq5DGcpQhrID8nosrh9/HX7zRrIbr+nVyG68j914Ta9GduN97MZrerWyG+/lNV3TLcdchzKUoQzlvwQZwgJDGcpQhrID8poWV6XUDyilTiulziilfmG7xu6UKKUOKqW+pJQ6pZR6Vin139nPf1EpdVUp9YT970Ovx/W9VG5WZ0PdvnIZzt0dvdahbgGMMa/qP8AHzgLHgAh4Erj7tY7dyf+AfcCD9rgGvADcDfwi8Hdu9fVsh36Hut053Q71O9Tta9Hta7FcHwHOGGPOGWNi4LeBD2/D2B0TY8ycMeakPW4Cp4D9t/o6blJuVmdD3b5yGc7dnZOhbq286oCWUurPAD9gjPlp+++/BLzVGPNz1xobjhQ/Wthbd5/3+42jQNGnsGNLZ8f+GN/Tjt5LKUcPiqcMxo5/pXcyWNaujeJaqlBAd2GDZKNzy4q0b1a//XH+SOmj0R7RbT3qUvVy5pA+n6dBERupQQ9J6dkWGku9qqulJlEEltrV75lcpx45X6wn5DkgfA62caeQ8fS7xQSayBJnFP2UkqUuLHoJoT2RjyGwHLEnn4qXzS2qIno1c9cvlD8a1YQ0RZmc8EcHOHBtkExIpWCCgQnVN2MM+LZefizqsNwWUhYytZU0oy++oWBp7pIs/wGdekSW0lBp4/gajCLvVKwNqhfT0ZvEuntL5u6r0W2xHn20PiNkKptpRDWQuRKojMjLiYP6nQgaaZFOKhPNJJ50CABIPMcVYooG35d/jEYdSpYL9srmGMUrdoIb6E0Lj8HY6CaRkt9Kje+aOpa82L0zBii4MR4ZHktXezRX05fV7Wshbnm5E37X7FBKfQz4e8CIXwp5+Fd/EpDFrBULg5CnDJFVhO9puqm9mQHWmnqpSzm0Sve046iM/MwdZ9pzhMbXEmOUGxN4OYlwJw23TN5B8ZThO3/tX1/3vDsgN9TvoG69Qsjt/9dHAfjQoed4V/UFN67mCfNShsflRHo/7Q3WebEnfYL++dl3sroshBTBYsSoLfKsn+u5lzYt+fhd24k38ohroqu0qOiNWsKLEejulTGFPW0Ojcvbf2JkifurlwG4szDLXl9IYmrKMOkLy1Bx5vzFV6qg1yCvfO4GBe78sb8JCPmP7TJCd0KR1mzvslo+n8JVj3iyzxBE3p4l8RibFs7RHzvyJL/2+LtkyKaPifqddvNr8OsxR6el7cl8o+YMidZaiSO/I8dBJyWpWJKcSFFYkYXE7yR4L1zi65ufvlm9bIe8Yt0GpYCf/DfvB+CxpSO8deoCIH2zDkdSfeopzXomC/DnV+7imXnbQ2upjD9iiYYWChTWZC3onugyNiYMWT906FnuL8n8+7tf/zPc+bfk/GjD2b8mTbc+8kNf5UhRfmsxGWFfKL2I3ly8xIVESHoyFEdCGbOU1WhmJf7HH3v2mop4LYvrFeDgwL8PALMvHWSM+bhS6mngF4N6+YO9NP/J0C6o3STYQt0V2M+TzKNckAXV9zTNWJhtqmFMIch3tL6lq1E3ZLZPtecsYE+Z/LtGbe2FPvCdRHuuHe8tlBvqd1C3M3uyD/qWFf2pjf3cVZKhR8IlrqbSnniP32Q1FUtpKa3xoapMjL/4wFn+xYZMsqebB6i9X6zer84doxKJ/o+NrPCVb94NwG3/tkv5vDAQGd93VpkuR2RFy5xlAuKSvABPlvbzzZEHAWjvU3SnZBHSUzEze/oNtf7Rq1bUq5BXPncLlQ/2ecPLyymtadvWOoHOHnm57zo6ywuz0rdJN4tUpmUTmR5punNeWhwnsIxlv3PuAddI0lQzN+m8KCO05M61co+5DaEijHsBadz3MDw6E/Ld6myGF+duhb8pF+r1EukCcWuZx16xbvdM8sE3Vy4BsBpXnNWYGQ/Pel17/CZ9fre/MP0YixMj7lxf3zguB8fhfEOMh8sLY6xvyGK8kZaYCmRDO3FgkfTOQwD4zS6F+2T+rSQVJkNZjA9Eq7RsB4R/s/o2jhRlc6v7LZaymvvd2Phus3s5eS2L67eAE0qpo8BV4M8Bf+F6YzEv77p7Shq3AkRB5hZaT0Grl3euDK2lOWidDi6I3sDZr7cY9s/fMXlDv5cqafBfnjIOtriFcrP6/RZwouzFfPTYVwH4ndmH+GrjBADrlTL7Q9sT3usybXfkK/EEXevHNnXKg6ULAMzFo3QsndtPHv0mB8NVAO6MFvjzH/oGAH81/Sh3/oqcUwHG8rb6qcZvWs2lGWGfflApan3MRSlMaPllA4+sksNEt1Be8dzVAY6TNSt4W/h9w5Isron2HY9utr9LpyVzN6t6tC1V4Pccf5HRUDamTz36VrxxcVGjYurY78MwY7QqYxrtIt2L8kLrokZVLUdpMWP9dnl9o1bgrNW4njeD9No9krsPY07e0u6vr1i3mfE43xNEaDxqUbBQgEa5BoXzaZ3vtA8D8M7qCxwKZcGb8pscj4SXOFQZT4/Iuv7ixDTzXVmAN5IS65nQDP6Nw5/n77zvvwEgHi/yRw/8nwD8+urb+U8r8s5MlxosdOS7F9fH2F/fAASW6Rt1vTRgtVNmsXfhmop41QEtY0wK/BzwxwgA/EljzMvayANjh3KTcrP6Her2lctw7u6cDHWby2siyzbGfBb47M2Ord6+d4v7r1yAypBYuCAKMvz+7q89/H5TuDBhqiRm+0q3grYN2V7aH+iVuO+D1qrehYTCN6tfY8xnR+6Ydrt/JYz5zrIEO+c7NX5gSuZ2qFISC843s6K75wyYsLjs26tn+Ftf/QkAitUeP3/PF+U8WYumtizse7uugaO+PItXFqtAFQtQEjDSDDQlJNN5++1Mo2zXAy/T+CuvT4XgK527xZmDpLYVfPOgR2VOrru0aOhdkPu/CGSZJQXv+ezdL9Z9qj3eNCme8dHSMon1GG6/77KDqE6dn0FZuCAs9+jaWEOa+jzwljOABAYbiei3k4acbcwA4Hc0XiKudLiZkdRs0HLFo3moQPbMra0VeqW6rZzYxyeefwsAOvMoFGV+TFZb3H9E4IIzvWk+d/kOADozIfsL4oGNBS32BnJc8XrcUxBi8SPREr+fPgTAycX93F0ViOp8Z4rkTvEKfuWR3+b2UKCDR6rn+JNFgRfOrY0zXu64a1zYFM9hvNR2Pb08Zcj09f3ZW9+gcADv7EsYpO7fxihKYeL+ltjWIknmM98SU/3ywhhvOSbxjzjziW1vmFR7DpfJjOcWj2s1EbsezvrScbu9WUacBvz+Z94OSMcBfbvgfb0k4HRFAlfHRxfc+J4OOJvIYlxQ8yzZYME/fPaH2f8Hos9uPeKL+wSL3T+9yoQvm9vH7n+Uf/qL7wEgOrMPGweguKIprdh2HWs9vA2ZxKqTd5bFUxjbCkbXSqSjNjJ0bpsUsYPSPCL/T6uatGqzWDqKtGyzMZoR9LuBJh73jkvnghc3pnhyWRbCZ7y9vGfvWUCCsc9dlWdz++F5zszK80hTn3cdlgX1bGOSK81RQN6dgzVZSM6tTBBMCTbuxz5ZSZ5Z0M7oTcjCHE9XKTR03mJml0oa+/TW7DyINEk7h+v6mS5Vv+uw6uVe1f29rSM3L6HHqDUSanT5yMTjgGxoU4Hg3t/qHeEn7/kWAHeGy2zateP9pS4v7n/KnbdsAXZtPNo6cp91rXGijUdmPH41yhfhl8qw/HUoQxnKUHZAbqnlmvQC5i+P2182rsGa5xlC2xBMa0UrtK2KPT2Q4+c5z3Lf1AYLtolZpr2XzRwACOyul16nu+Dgnu5fK1D2+gS0XpGEQUa4KddcvaJpJGKJru8t8mV1GwD7C+t8v80QqHkdl5Z1JFzmly7+IADBH42itDyX6mzC4xclsnpbZYlDBQkivKV0nne/Q1K9iu9MuWSzEc709nK6LdHyRy8dJ3t+DwCTT2p6dZujeBsk02IVFCoxRyYX5Qa+vN0a2V5RxvZNAumTZedH2MIlvcajimxE5uLkwXUX6W7FEZn9br3Y5Q/P3QNAEgeoy+Jm1g91eNPhK4D0iOr3veplAQsLNujX8SncJs+mXu6w1JN3oHG4wMgF2zwx9Ag2ZYxKDca7YQLN6y7lUo+33COuS6C0g/bGo7bzRN9cvETvkFi0Vb9LxZP7LXs99gdr9jjPoQY4bD+fGdngxVjm4l/Z92UeLoilu5rBQibP63hY5afrTwMwn+VrgY8hHlg/2tZyzVBo4/EJ/9qW6y1dXL2eovqCNfm9PBHbKLDXjPIgsUnBiVFsjNsGZVMd6rYj5mSpxXpPJmVmFLPrAhf0eiE6lZP6gSYq5PBC36Xo9nKXQylDEtuc2tTDC2VMsRRvyUhQyly3y+NuEIWhOynXP35KE7TlemtnfXpXJE/vXz36A3z84XcCMFZrs9mVdJOPq3eh/0QWyPpKht+10E2ydbNZS2XBft7s41gki2I92OCEzf17R3GJyXF5SX7eT/j06gMALH2kx/37BXO8vbrInkjSYhLjM2OzFz63verYfjFgYT66ExDvlQ0iqQWYgs2bHu9S+aZN/1mZwP+A4IX7axvMt2QhPFRZo5+OuNoq06rL/J5vjfD2PecBeGL1AKfXZZMaKXSZnBKXdrNTcJv+O/ac5/dX3yS/dRvUz8s1tPZGrtGmH+cLzW6WibDFX9n3ZQASE7gMgWwAipsJmry98iIAI6pHzRYFDC58vjI5LIii7N5hzUomUMKJaJGqsimdATwRi7JOxW2OhTbrRcduc/OVIbEOvo8htBtmZvwt1/dysrtXjKEMZShDeYPKLbVcjQdZafAD+3+VH6s0d79UCn7LVl+N+UyUJUhzorZIeVQsh1PNvczOidUVLkRb8qVjJT+mQ4Ox1rDf9ba4SbbSDi9RGBuM6BWLbowyoAOD7r189dZuEW0UWcUm54cKv1/h50P9nHw++vg85vfsjYUBo9ZS7xys4fXkCybwKCxIIKo3XaZYFG8h9DK6Wnb2xNQYD8S1emvQoGczN2Yzn38w/zYAvvjZB9n3nHy+cazKySWJxJ7kOKZk3dZIY+L+/v7Y9ipkm0UHYJEWaQVvK64Ko10mazIvW3FIuyaD/J7icy9KMFB5mshCYLdXFij4Yi19qXGCd94v8EojKbpAzUxlg1OrYrk+NLHoMmICP2PdtqD+owt3k62IBaarxlVoGQVxtd+a3ifomjxTY5fKUlzj1+YlQHqssuyqC0OVMmWr+UKMm3++pwntnGuZgKItOkhMDueFSlMcqMDs58IWVUbPWP13R/jM2psBeF/9OY7Z3NmyMuRNunHnz4wisZZyYnxauoC+DuR4SxdXZaBf5TK4oL7UujY6/7xv2ZvViBcymXAXV8bJbK/4ZDNCtWxVUAJ+kp/MWvCuhPO7xAyUc2vw+jwGXV6SOqAYKHHelVIJYjxb7aMDCFvWPYrA1gSgayW8VVst1I1RNvm/OO/jNWURjWfqKJvWE2wmtDbkZa76XS53BS+/uzzrShE/vXmQF7qS5vLJUw8y8kVJSzrynQb+srj/o09EmKK9CGPyIoLQx+uKYi9tsz62XSKN9UQJ2orYzr9SISaxi9/qfJ2waEth6xrTtfOy5ZPaEs2/Nf48P3z6RwD407c9yd+dlMKMz3X28bWmJLHPdurMVCVxPcOjnUgMopcENBdlAS6OdTG2oMDEHknFuq6JLP4AYUvLO7C7wwUkaxHf+PbtAHTfHHAgksKVg9EKqzb5v+v1GLF8GV0Tkhhb4jtwcyGaUQv/Pdrdz+cSMbq+r/I8JztHAPjpb3wvqiPzT2UKXZfzvPMdL7rzNLW3BVtt6qL73a7NHOhjrul1nP8hLDCUoQxlKDsgtzbP1eTWJArHsjTIMoTCWbI6yJmGwoZHZoleYi/Cj62VOeCtmwCUtYxVlkdJVcoWVqK+vHRXd1asYQsssNt3foDJYJOWZWEqLySu1nzl3tIAg5WXu4ipBi1jvHaMrouFEC21UCsSufELk0x9RaCVX7v8QeJxGf+HtftQFmYpP1mitCjHx59YR12ViDeZxmRZfoGptbKSNP/caEyQBxh3tWTKzdGoAeqsWDNrSoKnABhILM9AuBgyflTczM1ugdQGWj+1OckLV8QDq4Y9fqrxYwA8PzvNeF1c4GP1Fbq2NHu2U2d2VQK2xWLC3oNi1b1r+hz/8ZLADntqm1y5KmWfYy9o57X06h6lVb3r52/Q1pTmbVGK8Tjblch+14SOZ+BguOICXW1TcMGkxATEdpF4qnOIJzYOABIgHC+Jc+9j+Je/8/0AHP9Kl6Qqz2L9Np/GXXL8bHs/bymK/3Syd8iVy/Z0SDOTZ91Ii64ApKcDtPFopNdO0L61i6vKF0ujJDMAAM2WWu3Bha2PlRpf4ff6DE0GbRcSXTAOl9WRoWcjt8UlL4cUBu3zATjCqAFE4iULqhoItN6AaGtXiI9h+rhE7dPSOKHuY8xQWrb16FqjLSaokhTVsmkkaYYOrZLKEf6mbGIq1Ux+TbICJj61iDcqKUGmGOXVV+uXpAILBM+xaXSSTO+7z/sQhIpCRySxZfGN2fXS2S/XW5z3CSwo12uGpAV7H6kCy2yljrdYXpMMgVK555Lk//uvfoR7jkkV0TNz+9BnxM0vrCvWHpLvnleGjZZsatP1JntGBd++emmCqWOCHT62dITJqizG9ajDObvx+bFBBzKR47rCS70tVIi7Vfrv3h0jC450qOzlxSe+0pzuSSHGcpoXEWQDL/e/+co72f9luy5EitP3yklPRUfZ96S8A43DBTYP9FncDMVZmZe//dW389x9toprbZx9IwJp7S9vuNSwXhYQW37NWAek2iPR11buEBYYylCGMpQdkFte/uqyAniJdTh4PDA22JT1XxnIrFWqxxI864odml7jLZNSCrsv2nDuwifOPEL3WSkb9Ac4ro03EFR7iaiXQgbfdUG7V7rG50/PnALgM1Pvpd6SnbqykBJuyA2rOAXP6jNJMYm4WQoI5yzfaLnosBav2cE0xTrSrTamay2JgeizCgJ3TrLMWbHKz/dtE+f5xltE6/y7u12McuTXadW4rBe/6ZFVLRRQixmpSNBls1PAXBZrtVWNCCfFS0gXypz/46MABBpHv9g6rPnpuyRj4teffZvjvVhplR3vsF9NuDAvhR+VapdjYwIRPHH5ALpoMz/GfIobclxYNfTGFPrWv+WvSIyvHA9w0Uuc++9j3PucGY8rsQSo5rojLLQFKjm/NI5vvdvpx6D2zJKcdL3J6ElLDxj4tI/KWtCZVgSWRz4eM4zbjJasoHhuUuCawrerLLTkty5NCDcswIfuepaeVWZP+3Sz0BWKvJzccsy1H3U3HluxIJWP6R8bH7fidfdkvP9BqS66qzLnlF5UKe+tCLuzNoqWxaqKJ1J+pf29AATPlPOfSV+C7w5cm8OANW+IBXVQYhNQtvlX3UlF2B6gahQPBxMFeE0LBXS6KJs0je85IhbVaEF/YfQ8TKvlzuPc+AxUH8cddO0hB8GV2no8KKYPC7wOLLmvUpQGv2lxQR/6WT7GB7Uqur7nocv8yJ4nAfhfHvshlDUGqCXsHZMsjWx0E/9LUtThdw2X3y/nPHrHHHWLNRzes+o4XJMkoL813b1/nmcuims8Xu6w3BGIJ2uGKJslYwIorMlLFnQ8kmq462EtHSiCSbsppQWHoQ52rSiqhJovY9b9kiNxOnfxICOWc6v+QjOHq3o9zLyM90brFBclhWLkgs/mPsuh60H9OwJ7te+YdNfTntGc+C05v0oymrfJs7hwaJyHxgSXXUvKdLxsS1XnS+UNYjYMZShDGcobS163bIHBRH6lB/JZB7MFQkhsCw1VypizBLYlP+ZgUVyir6ye4F+eETao9dUK09M2P1B7pB3LFBTajAHYYpEOZgsok49Rmu8OAuzy3T82Ab/54lsBKdTos9T7PShbK7N9qIbfsVkBGzGqY6n/2l2wAScTBjmLVZxgkr6rMeD+GDOQi6xya0GpXL3BdaaWzs9lsmu7VbtJVAqFtTwQ0jdLvAQ8Czs9c3WGOcvcZmLfBbcAFjckCPMTd5zkM9b9DFt5FHWqtMkTTeFxmG/U6HXleRSKiesjd25lgnpdrNuCn+JbSCVYD7a8V2nZWtihorKQ5+fuWvEg6ebzRVvlzid1ly2QGJ/zbbEuN5Ii941I0Otre48x8ZviXRlf0TssudiFjU2UnaRmpCKQGNAZV3Sn5LnMPGowCxIELo5WGP8P8owW32FoHhWvYOTUBtULYsU+e/oAb3u7lCh7ylDy42sy7sHrkC3gWllk+fGWZP6BxRUjKVgA/lKB0/NHAHh2/AD0STTWfcqzcrxn3VD7KVkYzs1OMjIhSt8sZEQv5KVhWanPKG9cXbjxDcom4QdtRdBW9nh7bn2nZWWzxsRXBFcihOK65WcoK3oT4rZuHAsoL9guD5nBjMjnhdnMFVqoRGPWLY7gqa2Lal9UnuqhPIVJb1Bh4Xn5gvrSLpAvd/5dKErjUs6CtiK2qu5NZq7iLPKMe9nedPslnnpCsNUTBxaphDIvf7z+OJ+4+90A1F9QhLZzw+MXDvOX7/s6AJ9fu4uwbMltwoS25YBoX6nwkXd9013Tp56S1jmmluHZIoVkpYTS/es0xCO7P1VAZdK7DaCRljjTlc3nt5992BE6JYlPtikbzgN3XnAR/NGxFsbCTl6jjZqw3MJRiKnIO5+MlQhs65viuiFsWYKjcw03L/2Fdao1uYbVRsFVa6okFeMDKMzX8yoxNJrr63YICwxlKEMZyg7I6xZH1EEOEXgJW7IIBl3wfgAsaOPy97KKh0r7ltbASY24VADBpSJdW7b20Pe+wPNVSUyerm3y4Lh0gqz7HSZDCTSMeB2XuL2aVvnisrCen/vcUcJNdj0s4Ldh7LQoY/n+0NWXBx1D0OlzDuTjjacI123Y1PPIaqKrYLWVW6JZ9t0BKwBjUP2SYuW9sgZ4equlqvrwwS53XY0P8Ui/Zn8g42QkcY5W3A6J+ixuXsaDD55x33+wLnNuRZdcl9f1ew3V8zYz49kSzx2RPEsSxW3T4q7ON/OGeIwm/H8X7wJgf30D07WWUykjelGstNKyobAiVrJKMtJSddfPXaWNs+AXujW+OSfwSOGZEjZ/n0I3925Xj1Ro2z5h9VKXziF5t0tfvkShPxe1doUx3T0FSpYwvDwfE66KO+qtNHKCwjBA2Zbk488aKvN9cg4DbQkC+11cEYGnDPoGTHm3HBboKyupGFdlFa0PjBmYCOYlV9evEKocaLK5KoozndB9p7iWEf1zElIAACAASURBVH9e/LXWI10C20HzaGWF944LGcSdhVmOBYLL+gqmfXG5CipkQ4sSTycB/2HuPkAWd2V2f/JA0DNEDZtapUOSmlxx7UrqXMPCmnGtSoJWgteWFSIdLRPO2YeQpChbLKBX17bgqS8rLyEF6S/GKghQoSUTyfR3wwHYdK03SCqWDmDzuCVrWfIJbBKFP19A28XS7ymuLkg0/+rhNv/o4U8B8Gjjdr65dgSAd1VP4/ebEj5Tdji/58PXnxPe3Wgp4PlUKq5UPXaucTBbgGV5gU7fXUaV5PPyc0X2fEeeZeNwSDwqczpaH+gAscvFt5vVlY06neflHa7PGzrT/Y4PUF6U9//ipUmqkdzbbSPLfP4j0sHhrgsHoCsnMpWSg7r8nsZv9dMIi+439fqGpA8CphC6rrm1CwYvtvM4STF2cdUDfR4T45MY77r71htjZg9lKEMZyhtMbmi5KqUOAr8J7EUyQT9ujPllpdQ48O+AI8AF4MeNMWvXO5fx8uh/tJbT4nmpcbuMGWDCQufQQfOo5ug9EiFsJyGtQHYgL1FEDZsLO+az8Yi4uj/30Jc5EElt92pa3RLV63u0k15EU8tu9Rubh/k/nny/XMOFCqUlGzDrWY6DGynqVch26laluXVYXDakZVsCWfPQYT84Z5xr6ze6qE3ZkQOAflaAzjkHBpP/le+/PESgX14zJtPO5VdKu4KF7xqX7Bzd2Hbql8AQrYgtkhYNvbHcWtU1y5sQ+kTLfTe/wj8s/TAAJyaWePKsWKLHjm7yzHv/OQD3Xvobrv9YsAaB7R2VVKA8Z2vYx0pu8tVmDTq0/8gUQT+QtpE/gyxS9Oq2RXdz52ynbZ27maF6Rebc/GydcsN6XVdj0pINdJ3QlG19AL5xXUZGgg4fvE8SXb/xwQcYuSg6KS10CZYE8iv2MlTXZsb4vrwrgJqaAFsYY7RB2fkdXWlKg03AbLYx9r1KqgbfAgmxDoh1sKXJ6UvlZmCBFPjbxpiTSqka8G2l1OeAvwx8wRjzS0qpXwB+Afh71zuRyqC0kONW/WT+/svfF3e9HnRm5Ib/6ns/z8WOpGKcaU6yVhJYIGwVWXmz3Pz73/kkD1QlyXfUz1tE3Fe8zLilKysqzaOdwwD884vvZvFRceMO/nGTo3b87HvUlvQVpXcMFtg23aI1flsuunY5pnGknyHgOyimPG+oXbELZJJCfwJFAZ27pVFe6cI6Zlbq100yUMqmPNRgcLRPDHGtaL/RjqwF33fuv4njHGdlayXXDsj26RfoTcv91KY3ma5Jes6lrx9wFHZeV6H7XQnaiuYVSctaLnfw1uWe/3DzDn52VLgF0j0J6qwtelnLSEtynvYBzb5HZcY1jygqNhumuKHpjIm+ipdDutLg175LNh5RyNPw6qdjog0ftTMNCrdVt1lk14Vihme7g6jUUFqR+dW4Lb8vjKIYyFx/an0/ddsksDtp2Ps1i6fGGaYs8IjXjXOSol4ClpjI1CpkRyQzIVhsoBryTE2ngypZLuhuF1WUFyirZA5z3UwjYh1ct9v0DWe2MWbOGHPSHjeRXuT7gQ8Dv2GH/Qbwozc611C2ylC3OytD/e6cDHV7Y3lFAS2l1BHgAYQ2ftoYMweiaKXUnhueYKCIYJBOUA3mvHr230A8YvjTb5M2uG8pned8R4DrO+sLTBYlonCmOslfPyL5gfcVL7teOZUBRp0vbd7NZ65KU7j1x6bZ+3WxyMonL3Jw+etuXPz9D8slpHlBwUuDajslr1m3mUa15Z69rJgzf/nQPSz3293nMfkd2eVbd06SFi30sakJOgMAfv+agmArFNC3VgeCWCbOrhn06rv8aoAXUgVBXhZrzHdlD+yUvFb9Kl/jtWyJMDBdEpfzzJ4Ur20/14rUdoNIZxKqI6Lr8WKL9G4ps3xH+SzfsAUC0VxIUrFMb0VFe58cP/jms5x/WoizhVNDriFoZfiWFFtpUImFKUrKeXvGy7NCskpE0E5c3utOyWueuwg0CGBS5WDBpOYTtvs8CYHjc1Adn5WuJPmfm5ukVO7zjJIHouaWXbBKVSt54HStgbFdN/TMFBvHxQMO9peof004StRond5R8ZLDx56Huqwpfj1xlivA9cNZr2BxVUpVgU8BP2+MaaibTL9RSn0M+BhAWBvL/2DyxTWp4er6vSRfgLPRlB8efQKAxaxGL5PLnYqafKguNdz+tGbCE1dgXZf4ZkvaifzBhXuJn5Ko4/Q3M8afngNgdOkJTCwPIxtIfg/27WVtWs7vpeQTMu3P2pu63Vcl26HbYqFO436ZEK1pn8SysqlMXmIAc6zN2l3yh9ZMDn3M/EmH4KpUvJEkzlU3L4UC+jLwsirfx9h/q2u1E/EGTuL7qEggi/4k32nZDv36k3VXcNK8OsK3EztXNn10uV8g4Tn8qDbS4YOHnpcxyvCzM18GYMbP+HhDGguqVJHaBSOuei6t8OT5Q4zYrI4Tb7ngFvLLj51wz7U3od07s3lU094v1xM2oDInf2jvLVC5eu3upNsh26HbQnGU3ojdNHq+gwvjqpc3W+zawiOkIq7Zkx3HrBTQz4sSgwxW75dMl4k4xZwb6G8xJp8rgGkx0lpHqw5OmXsXZNERGfpHp0hLAhdEtSrJfllHDkytuTYyvjLgZdftCn1TgJdSKkQU+FvGmN+zHy8opfbZv+8DFl/uu8aYjxtjHjbGPOyXKjfzc/9FyXbpNgyGun052ba5Wxvq96WybXM3/M9TtzeTLaCAXwNOGWP+8cCf/gD4KeCX7P8/fcNfU7mLs3lIUzogO/KJyRXmNyVZer1RdruDpxWLmXy+lI5wtCyh1T1hg8SWnu33G3y7K5HYX/zGh5n4ilhF+0+uo65KbqvpdNH9fLYBa1UFgQOus70TeR6bJu+7ZUC9TI7mdsh26jYteWwcEZ2kVajZVsvl5ZRoXUyilXvLNI/KfVWuGiaeFmjFe/Y8ph9YUl5e7+8puFaidD+Q5fu5dZtlW6GDPqSgX5JlcIsa5m3r3E09Aht997sKvSYmpKkZSpPiOaWpR7ok82my2qJlJ/tqXOYfzH0YgD93+HGK1mUI7tug3bDRRlWguGLLsi8VaO+T41NnZzhluxjs2+PRHbfvRpI7EF6iCCy/gfGheVjGTz2xc5UZ26lbHeXzoXzJd15ia19uuQZdYSMDCDc9lp8TL6122WPsBduKu+Qx9w5lvzvJoX+x/F2/tfbeI2wcFf10p7TLrw1m2iy8XZ7d2GcMlackM8kArX3yHO+pL7mso8hLiXVw3UD3zcAC7wT+EvC0UuoJ+9nfR5T3SaXUR5H+cn/2RicyFU3wXkmPeu+eWfd5PewwVZBI3cZIkeWOTNy1donIArA+msnAplao2Ln/n0tLfPoxqbG+49daeBcvyEkHCUE8b+uiWhBlqWoFVZTj1kzZ8V4qY5zLtaWR4vbL9uk2gNQyK6okz8QwniKpyo0V1g2B9RLHn1hDXRKoxCQJpv8eDvIAgFtETZZtwU4dt4BSYKkLTRznC2qGI28xcZIXFwyeY+fx1m3TLxoyWyyQHei6j03Pp7MoivdGEsr7ZR7Xwh6ZNRLuqC7wM3u/AsC7il3+1yWZr+VCTH2vPJDaoR4Ln5Islng6IVgT3flroXOHdZBXs/Q7cYDAaO7fAwZMeyqgfGbVpR5ts2ybbrNinqCvjIUJgXg0J53xO8rdu5cqaudk/hUa+b0pbfBsN+HehMHsF7hXXZglnbTG220ecd3iuwVD2ucWaUVQFkWv/am7Gf1DSe/SzSZxRdaapW6VZmA77holVVrXWV5vuLgaY/6Ea2cive9G3x/KtWWo252VoX53Toa6vbHc0vLXfeUN/re7fx+Az67fz2e//BAA3v5O3uQNMKesy3VHTtT8+ZW7uNSQgNjS7CjVF8VaKs+Z/7+9Nw+y7Lrv+z7nbm/v13v3bJjBYF9JgCABgiYli1pIxhJlV0TLiZUoxUROVHLsOK6IluOKKqlU2ZWyZDt2ZJESEymRrNU2pSJFSrIo0iJFEVwAARgAM8BgMFvPdE/vb73LOfnjd965rxvTM4OZ6Z430P1WTc3r9+67y++d+7u/9ftj0iYFWnfWqflSt+r1U5e9Vv0Eb1NcN1OOXLLKbGxirOXanQxclcL2KQQq3fbeCEIHULIdrOOv5e5g0M4I1iVxVFpW6JKtIezGzv1X5ZLL7Js0za1PNRQSMCa3/pXCs/sxxrg7zKuU88YD33eJQ4YtWqXyqgL/ctmy0YTSYCbl2sxmCJb93mv5LtGlez4dLevphe5+evtERh9oHmfGl7V8Nk252Jf61yPNFd7VlKTL85sHuNSzjQm1hPqseGlriw1KJ2WtbxxV9KYHNHoJ2Pra8Vd8Vt8nv3FwrkRpReTbH98VUdx0qAxiyTehA4MZcLj3lfMgk6Z2GSK/47m22P6Ux/rRfIae6xXKoHW37HRsZZML75W4bvdwkiepQ+1+R7+U4dux3Bc+4DF+TAYd8txLJLbxZqlbc+TYoZ9R8lOyK/AL7KlyNUbxcl/IKb6ycCcz35T3+69WiZtyATqyfJnAdKPD7689DMCzpw9Re0a06KHXU8KWLacIPU5/nyyy2oOLpL7cxM2oy8uLkvHrLUwStCRGM/2cYfyLdmJjmtI7LCvQeLipmSjIBo0NKs9SjjRMrlSrr1xCDTqfMo3pDmIB4yjb8aKGXHVKUR5G2daFNVzwP1CuaqgpgCR1SlRVyvn2vs8gc2yMAduhZTIN3V5+rHCITWaU4Uk5FoDqh27kiy5rR/dnNkOn8FTH4/VARrLMH17jVCI8oweCNR6ty4TchbjJDzSk6uVPV44Sf788HWdKMU/OSlnQH5l7iL4ma3TjLjB1+Q3K9ZhoQl73zkwwPi7Ke7XnU1oWmQY9gx7Le+xHFiYnwvHifMouXt5QZHzPcTgoDUnDPmQi44aYorCDMeX/1BoAhAH9KXm/MtEly2zs3N9qMYWBrP3JI2027pOKgsaxiNZh2e6u6ibx0MycVlxy+aHLoeAWKFCgQIFdwJ5arqtpld86I8H8lfNNpmz/e7RpGDttmcKnApIfkprLv33XFzkQSFvyB999jM8cfScAG3GFd4zL0/+OaJkjkTQdz/ht9lvLtax8Lh6Wfb6WTPCNzlEAPjXzfrz0TgCq53uuzq16KU94xfW81s7sbkLrpkFp8HuDIWAqHyYIblbWlstQCm9Mgvym1xv+JK9b9cld92FC7G3uvLNQM+1qZFW5JBYxoDzPWavbOQbcHK+Na7vOWwYNUVlk0J9UsCrX5k/2OTQja/Ts+f1ktokgq2hSO077TDLFPdEFAJ7vH+S7azJI8ud7H+BMKq7rP7rjd/nm7BEALiUNjrXEw/OVYfndlsZwzXcube9ShWxCZBp4MFMTy3VzZXLLzKysFu5Zdcb1wvh5s45Ref27CYyrEFBZHppLa3k/uvGGKOs8I64+NvI0eL/bcxSls2MtUuvK16P+Fs6RyLqo1SDmlXFJhjXHm5hJMas9ZVytvTaKfubfWELrZiJOfS5t2Jo2o/JRKgo6s3Iqa/fBT94jmdV3ls4SWoneHW7w9AGpMAiVcsn8YdM7MQYbtqJjUvfZrN/i8eopAD72rgr/rv4oAOO/V6N5Uhao0gYd2thNoNyejcebhymOILxMaAQBVKZdXNMkCcYW8atenI9zCXyo2/KCTENv8037NGmSVwsMd/log2FQ0a1cOZuqVdGTorCTZiWXZ+Tlrp4hz3iHirRsP/i1G7r8XYcyUK/YuGaQ0V6zctSKtY5cfzqVoGzuwAsMk+NSOTDpt5j3Jeb/86v3027aOH8W8j889zEA/tdHfpdnW8Jj+o3FQzRKcqxuP8Sr2VKjTOHZsEPQVsSe7Ke+Ynh9ScIOumwcHWLcVKhEj/zahSGFqnBuvvbBWKIaHRmMzeZ7UeZyNEGY4dlQQBSk1EuiCEM/49z9Qr5QP7PfcT7c01xiNZbfa7iio5NGW1z8Qf6FiTFCS12aap+SP9R4pDT+FZIxRVigQIECBXYBe2q5Rn7GgUkhql4MM3pTEqj30pzl/fEPvMxDJWEN2tSRG6HdMyENy2w1421tm7Qt8pSVh2cttr7R9OwjO0O5/TxQOc/aUXlyffnwYzRtbgttXIhgeGDigPZw1McTY6A3I25oFPr4PVssqDU6sq5MyXfTHLzM4HflKeyVS6hx2d7r9PIwQZbl/ABDjRQqCsHWCjM1TvcOcW3jMd/xFWQhQzWZOfOZ8XCP9GF+iVGHDuDSOdtCWc4IZiVJ6HmGvm2FHZ9usbEpa8sYeGJWpg9oPP6gLZMt1uJ8zPtCt8l33PEaAEtpg8WeVMkkqc/j++S7H5x9hd89J0ndC+0pR2kYtiGeG0w00HBJjutl+fy0qGVIq4Fb16MKE0B/xjb5hBpVtmGQKKUUyevQz6hZq7QUpIRDWebAzjmPvNS99pThlKU37ewruYRZX/ukNtbQzUJnrWqjXLIq8vN962aVelXuB41yIYXMXN0u3VPlWgv6PDl1CoCXozleaMpiXWvCvsekoP0jU3/OmpYFWB6a4ZIZz5EmaKA6qOZRinAo7qGtEsiGlEHPBCQ2qNPwehwqS4ysd2ef9nFREtULMTqyoQB/OEtpYz2jvT4BaM9bOrR9fu7WqK0KbODFqAxKG5Y/tFJzbnvY0QRdG3PNhkpbTP7wycqeU6JxQ5HYkTImyLtojDcUR/MNOZOMcsPf5HxuA8GCxPMGp6ogWbMPsokeTx48BcDrG1P0YpFpmvi8tCbVKg9UFzjVk8qByEv5nppwDpzoztHNZPuOLnFiWTLUB5rrrrvrqfpr/Gb8mBw30s699ZcVqm2nG8920WdtI0MGfiw/cvlSKmt6xP1TP0oZPySVEqUwd7uNUSi7AI1RzoXvpwGZrVZJhkqh6mG8JQY6GG4athIqiyLnFy/N07BKWsX5VILIy/AHihnjqpeykr+Fs3VYqV6NuGXExV6gQIECtyf21HItewlHLPX6Qr9J6T4JEdw3vch/Mf9VACKV0fDE5SqrlLI1waoqN9VDJRYrQIgitMXuofJJjGyXYejZJExiAkLLIRgqOBhJNcKHH36R39Pics39UURl2bom3lCtHTbIfjMFsUsY1ObqMG8n1Nt+4WGWoQGfQG9SOYu2iz+Uic0t+GFs8YiGt1FDbbeByZMUW+oV9dZH+i7xNtx0KFClNxc8V8uxsz59T3PfrPCUpMbj3Lp4Zr9z4VHWe2IlvWf2NF9oPQgIm/0LK1IVoI1HkorANvplgoYc63wy4azhj77jWY5vSBb71B8ekSJ7IOmGVNYtdWHdsHHIeniRz9SLIz75Ecm9DqzDOPXd9fb7IcZ6NrrnO1JyExpXz6r6+bBSXdKowULLYHzBTuZY6BA3JOy1cHac1aptmMmGrNAwI7AhiGo5JuhYD6GXstmSkEu/1s55T2zlwI1OIrhp0EaxmEh3SiPo8dE7nwfgPbXXHP9qWSWEaqAgh9x98ntSA72B+48hcS5n5t5va48VLUI5l06wlDbsOXhsWmr+QGUcOihcB+vT+yivWOWq8hjrbXLrA7kbnpVx3JduLAgSCtCDqbka+hW7KINc6RqPLUpxIHSjGBKKGn65pYh7mFfUfdcbUrS+cQX46goLc+SgQNkb2vMNZsy6lsqwZLkwOklIJciV2WxdqgWONJbZtGz2a0mFXzsjnYlTlQ4PTsjUh/Gw47Lecea7EqGLyRjjdak0eLpxgs8dF17idD4jtHFf1QtIq9Z95jbID2yD1srFrfu9EN0S5er1PNehFfYUfi9fu8PI7S7PcdkqkxsYG/c1WLtbFmN1dtM1D6Spv6WhILUEORuvjTNtKy42j9Yx5+S4x9f2uzVr7NTSuL+zCi3CAgUKFCiwC1BmD90ypdQS0AbezAV2azHN1c/psDFmZi9O5npwm8sWRl++m8Art/o8tuHtItvbee3uKNs9Va4ASqlvGGOe2NODXgWjeE7Xg1G8jlE8p+vBKF7HKJ7T9WIUr+VGz6kICxQoUKDALqBQrgUKFCiwC7gVyvWTt+CYV8MontP1YBSvYxTP6Xowitcxiud0vRjFa7mhc9rzmGuBAgUK/EXADVmuSqkPKaVeUUq9qpT6xM06qQKCQr67h0K2u4dCthbGmOv6B/jAa8BRIAKeAx68wvYfQkpZXgU+cb3HvZF/wCHgi8BLwIvA37Hv/zRwDnjW/vvIrTi/65VvIdti7Y6KfAvZDu33Bk7ovcAXhv7+B8A/uBkC30Uh7gMet68bwHHgQSvEv38rF+X1yreQ7e7JtpBvIdsbke2NhAUOAGeG/j5r37sc3gO8aow5aYyJEWrkj97Asa8LxpgFY8y37OtN5Em10znfalyrfAvZvnUUa3f3UMjW4roTWkqpHwK+zxjzX9u/fwR4jzHmb2/b7seAnwTGqlWmj951ZTqD4W5zs8P714IbSdMZlPu+RqGN4sK5hPWVbM+a4a9FvsOy9Qmmq2rszfvZutNrOPCbTuQaNtrhl7rcV822P+zfG9mlS2aPuoiuZ+2qUjgd7r/y6QkBSf631xXbJegaVLbDihwe8FCyNHpjhrGK8AboIZYcbWRtghCHDI6l8bbsZ/ByMKGod2GDeL27J2v3emTrl8Ppyh2Tl9/f0IUNrl3tcHebG+UFfQtKwyC/d+/COskOsr0R4pazSKxigIPA+TedhDGfVEqtAt93913Bx3/rs9Pus8uZzb7K30/M1vffCrav5bcyGTtDkdhF3TYBHV3iv/uBN97aCdw4rirfYdlW1djHnyp9+E07UcPK0fNyZel5oPXWz7ZvDxAGgx0N7XTbL2eG9jM0X+tN+8JOgh2MjDHaTZ39wsqn9lLAb3ntRgdmPn7gf//xy+5ssNQ8T2Msv6jWivKLwp4z81xCuGEJXZTasvBVYmc+acPmEeFkvfDhmA89eAyAjSTnHI21T2xnOJWDxDE0bR9RMszclGmPP/tvf/XK0ri5eMuyrd4x8fF3/dx/ftmdBUMsLam9Jz1lLsulmhpvy7VfDdsnt16J4epy3/U9zbd+/P/bcZsbUa7PAPcope5Egr4/DPxnO2x7FjiklKI0ILm+hgPcyETg8jb29ewaLPQBuY7GbNm+rBJH2ruHuFb5bl/Ml1Vq26GU2jpocCCv7Ypzp30Ny/cys9uv5RwA8G9JH8tbXrsAyrv8I3ogimSxQuM1kenYGxmlNWGwT2oBSdMyPfW1Y63yYu1oH0HTfEEIo6P1Br/3UZnz9t5HTlALhIErNR6BZeDvpaEjht6uWFe6oqSXV+qwXKLfja5FJjcLb1m2njKOTWy7UowzkWfkZ9xVFflMhm3+ZPEuAN44N8XktMx/m6m13SSC9DJrcjuGybgHfw9wuft9u/L1PX1FwuzrVq7GmFQp9RPAFxBd+WljzIs7bC4CB6JrveluMvxrOO5A1cTG0LH8fYnx8W8B8eBbkO8zwD3bvuteb1eiavA6DHLFmaa5UvW9NyvYAQZjcJTaeoxhBbndUh7AWskK3FPTZGy1evcI17N2UQbfH7Di55eplME8L+GYQ99KKS8JzaDXTejPyTDO1oF8/I0OIdqw1IVpzn/rx6AsT2RlOePob4oSffbsA6jHhPd4vrlJLbSTSDFOqXbTkAtrcg79i1Uq562CXwcvMVzsXr+s3iquR7aeMkRePoGgZ/lxu2noBgK2k4j3NGQmU8Pr8Xv9BwDwL0WstiYAWBuvsW9GZDVb3XSKeruFOoA2Ht6QZTwcgrnc+4MQ4QCRl17R6LohPldjzOeAz13DdgOBf/ZGjvcXDdci30K214di7e4eCtkK9ows2xjzucffUdoy7+pq8NSwu3PzrMfL7ddTyr2OMaxZou2ldIyq1ycd4Ul6xpjPNf3p3CqFLbFVZ1kqD1WyLmIYoieE5PnSuybozsn25SVDbVGspvLFLv6KWGKqF+f7TtOtbv9wHHcnDD7LcjZ/5XuYN5P7jxyMMZ+r3L3fWSm+b9CWIV99a4yDXxIy62C1A3agI0qhfZFvd1bRn7QjykNDvG4TXS1F0sit2CwaJGwCwg15HXQg+4ZMNDhXbjpi8ng6cyO3WSpRPS/7rK0alI1pmwCS6tapGqMGY8znph+YpmrDAqc3J9xcLGMU75iUYaXnu02OhML+F6qU8YqEXDYPtQksyXh/s8S5U5LTWag3uWNOJo4cqq+648U6cK68Rm15nQcGc2ij8NTlF6mHuWJsd08nEShyxeajyOyF+deicIdDfEOKdicF7Cl11f1mQ+5+YjRlJcrJN5qlVNysC2mT/eHqlsFnI4krPXys0lVhCGUZfJdNNTjzvXLT9h/pYC5K4sQoj7Qmy6IzXadm36+c3sRrW/9yOC2+03GHt7mcIrbfVbcm5npdCAIb7+xGlL8hLv/+L2/irdoHUKYxkbi0uloiqdsxOnf3mLZxQd/TpDaO2OqW0LG9BU+XCVvWzd+fogObvEnz3Hi0oZg4Lkp65f6A/qRl11/wqFyyCmZckYhOJx7XZM0UXRntFvfIS5krbQDQywKnsDppRN2XCSWzpRb3hbLNplE0I1mL57wmtYpsUy3HdPtiPPRaEadOyUicheYYR6atoq2tueOmOzx1PMw13e+BunLM9fZZ2QUKFChwG2FPLVfYaqXuZFl6Vue/nmaENrC83/edpRnukHC5lqRVhtly3GHrdfA6A0725al3tj/BZKP1lso0bgUMXLa0CnClTybTKPt+Vo/cLCLvVIXSmlxfFkEiRhlBO59XFM/W8Pt29thKOw8TaA2pdZu2y/9yv0cQSALtNoNShnZLrn/m8yVqC2ItZdWAtCYJlXg8ILbWqlEKO6qN/XNrTFdkKNNEqcNkKK8frJ5nU8tGvzX1OOdOiksbTvZIKtYC3gjdIMJoDcqXxH2OH4h5x6GzADz/p3fTsyW43uEW+ybEwpuvbVDxEz5rl7jm6wAAIABJREFUXehRRaA0s5FY9p4yJDYEt9hruHl6ntKU7X2foamHIn/P22o5VsvyfqWUW7H9dsQrp2QQ5MLkGPdNyxDJ+fLGjm79lZJg7ry9DH/7QK/h69rxk13CTqGAwftlFfAlW0ryt37/v8Ibk8X04fuO8XBNFtPT1de4L5QfIDGZU8bboS9T3bpdue9k/n9j7Q4Avn3iMA88tUB2Gxj5gwy+Umqb+23lkKaYtsQHozc0U2PzAFx4yqc3bWN/MVQvyHcbZxP8vnx37Z4S/XH7/ukyY8ftzbDZcTG+Lcp9J0VrTF69kGW3zfTXLPWZ/ZyEVCqLCTqU9bB+NCKpybWllXw4oN+Fvq2L9zKf9ViU6PGlGf77B78IwCPlM64SZf/RVZ6ZPQrASlzjGxekum4jrkNPblNdgo0jcg7fcdfz/JMDXwDgR/V/ylgoCrQWxJRs5j3wMmId3IoywreESKVMB7KeEuO7AaIArUyudzjnMe4FlLzLx0EHRpAxinIkukOpPEa+uVblmdUjAMzNrfPU3CkApsOWU+qJ9q9aJ6uNIryKch19jVGgQIECtyH21HI1XD155eHxlfa9AOz7kkfQE/foy3e9i88feAyAQ48u8O8f+DXYtr/LWarD+90OXyn3/oqO+cym1M59qPYSm7Yzpv5yxL+sfweL3Zeu5RJvKdS2ZJHDwLL0tHPJTbtL7RUZK165cw7PtsNVlzRBW+SYVTw2D4n82wcUvs1n6QCSSZFPqRfnGXK8nS3RHd6/3vbrvUbQUm5s+NLjJewkeJQWax8gisHvWw8gg9YRa5XWNzi+JH67fnGM/+PM98vrWubau8oLodunDqFxWj4o3amID8sHm5WAzj5Zrxd7DXdu75o4zWoi3l5fB3RtnWgJRTbi4SyAhpcyE0go4/X+DO1UrFWNYiIQT2vYkqx7ZWeda61cE4fGOMtVm7wmNXm1kY+Cn8irLBaXxvjs2sMAHJlb5ulpqaPdF63Ts3XuV6p9DVWGPyrVAstZRKhyd34YAyXZNwktK9ykqlxBe+2Cprws2yxeOsCPRH8VgH9552/R9GSf2pgt1QMDhNv6wQZKODGGshIR/PLau/iFL38nAK88Nc+rxyVGs++0ptuu423eRkb+cJvrMFT+vvI9jHXj+5PQn5bXwTMeSXUQN4SwI4tn4iXjZsIP1XuTNSsEfVsSpIc+MCYPEwxX3ft+Xo51myhWkGL8/oTIpbRiyGyrYeWSxrcPpl7Tozc1KEsDz4rl2Pn5/KYf0wwqexovh0ycEJlVzq6jy7IW01qAsdUC6/cEmJ6tYkkUvg2fvnjsEH9TfwyAhY0xDo1LFnyjX+Zg3XYyRW0pJboFTTBvFdoaORtpmXYmsVIPw/5Iyqh0PJQnGWo82R5zvRy8FJSlBSmfD+hJNIzqXJt+T4712rkZFtalQujxfWd4Z0NCkJPBpgsXAC486KNFuV7RoCtQoECBAjcde2q5XorrzmL18LZk9wfu+cWsy797Xtz/2cTQm5Btxk6n9Mdsn/Gm4vRvS/D/f/4bH+GfH/w8IEmxcOh5kdgnXIfE1bCGyse3lmwIrGTicn36hfcy82fy3S+sPoH1EKgsxXhpsMVaG0UoyCsElNpKxDJIIPkeKrA/eSlCWdKU2jnD+JNSoH3RTFNelO2rC4bS5iDRZUhqss+0ouhOixkbRR46GAcgvLCO6g8TlNjzGa4OGEpimUzfkvbX60XztcG1QXfK1gLPesRSLkxvNsNUbJtv36O0ZC3OZ2skdRt2WVaEbXldW0ipLEjlAB6EC2KlhZnGlES+hzfGyCpyrN6kcm208cWAS9+WpGu1ZTh1h1QslJcNr/himn39O7rcPb/kwgSjCgOsZRLWSI1PIxDzvBHApC81xBdVc8t3gh0SWjseIxCZJ2MGldoEZOoTRkNttzYE+ZVX7+LlyTkA/vL+EzxaFQbFUKUkJleZoUq3hAq2Y0+Va5r6XMzkYvb50RZFW7Ku/Z90DzH2LZshrBjSqnW/zrYo2wqBsFOlPWe3/8YDPP6SxGjrEx3+0UPSSTcfrBMNdVxkNuxwLp3geE9c/mOb+/j6qSMANL5aIezI9o3THuV1EVrcDNDB6Met8BTKFrCjvJwQxffzWKzvQyByM1HoGK/GT/TZsF0xn/rIL/D7G48A8JvPP070usRWvRjsmifcNO4m7zcD6udtY0i7iofEyFSS5rHeK5zzZZpiRhLGU7T3ibxaBxWpVZbZbB+jB5UQ4EVyQVr5+H2R9fTzCcbyKVTOt9m4W+Kla3cFtPaLK9o8lVA+ITex7ualU96pM64aoz50Psr33e+tKmUmG/KpiUIXjmm+NsHG1CH00p4St9wQMqMY3G6hyiirAaGLdiG/lum7nIgxirxYJTesDHnlgMTF7UNpKiNck98lXajiz8t69X1DNKRo1zalQ/MzJx7h2amDAHx4/gXeWT4t54kiMx5BERYoUKBAgb3F3ta5Jor/69IHAPjf5r5GSVkatqGM/69eeJLysjwNNo56LoCPMahErIJoPaUzY63YNY+pr1gzv9TkH54QdrO0nqHq9klkwL8o1nC4qWi+JvsvrWXst/3cXpy4c4g2lCTTsGxFV7PARgC6XqbzPrHgVZqTM3uZQaWXb1U1tlZTaUP2GSlg/1eN7+ITh4Rz47En3+CZh+4E4I3OJCdXpwBYWa6jWrJ0TCVjbVNeH/yjGtXXh7gDsqGn+uDY2TZT1R9dzoZhJDVY/x5rlXuGdEPWU6kao7MBh6uH51vLNfYJrMdfe/ECyX4petVRwKXHbMPGwS5jXxMLqT8eUD4o7ry/0c7lpbULr5g0zUMs2sjfAJPjXHpSml5WH4LaaWslL2vihkKPuIgVMO6LbMeCHn0t68lThmior3+QfH4uhq8vSEgkS70tFQIDGKO2LHe3G5O/Li17JH3pmOmNZaiqrQ8upVsY0E5dkt/ul1pP8dyc1B9/ePLPuTdcJNiBdwD2mltAwxfPCTtea/Y/cioRYRzrH6Bq61BOLk8xbstZVAq183KDeiubmKa4PjpQroQl6Cj6zXz/Y6/K67Dt4cfWbTLQt5Ur/QmoXBIhhmt9lt4l+8zKirBl3a+zKWFHtkmqAfHYiK9OYP7QMn/vn/0KAB1dcjGs9axKR9t+ax26hZtq3xGCxzqguyalQqnx+Vb3iGxvQiZCWfRfax9hdUFcWK+WYmxzB+0AXZcFtvRoyHxXFmt5wUDX1hZ56s3s5bcbAsNkU7Rlux+RlESO1XJMz66zLDNk2YCgRuU3tFKYyGaZWzGTjy4B8Il7Ps/P/roYAyozpBPymwWZ3srdMKjwSLMtjRqDh1c6WWN9QDp5uEO6Ir9BP1PEDcUIcw4BwrUcKrnfpsMWl5L6FbdvqISpmqzL8/2xLd2Tg1WmtXJhAh0KAQ6A3/bcw8YHonX5brgRoEvyQf+gBxVZ39ooymV5nWQ+XztzxB3r6f2/R1BwCxQoUKDA3mLPLdf1VyWr+c8OvZdmIFXpP//t91OuSiV23A9dQfv+r3bpTdlgfJqiVoQIVx8ewx8Ubq/jagu9GPd+0JU+eYC0rNi4y55DZkgrlvJt03MF4P1x6Nj6t/5EyKFPiQmsHztKbzJA73mj8FvDelblD9cfAmAi7PCe2msA3K8WXEZz3OtRHnJjBgXmHRPQm80v8A83pbD6ldYcCx2xVjv9CL8hT/AgyPCfFVdg7huxC0Gk1dRxEaRjZTxbt+m1+qiOje8M1bkqbp8mAlROTq2UAZvESjKfNLU2ilFbklsD08VUSqjYCkYpKqHIsadDVy8bdIxrqcX33PgbtHaWq/E91MByzbRLWqokw7djnJI0t8zKq4a1+w16xPNZMR5rmVjbE0HbWa79oZuur0M6WuRWVpp6JF6RUnk4YDgskGWea3lNJlOyshWKAd2wFv9MBon1KNoeQdt+P/ZIbbjKxD6pZUNTSsIQIPdOw/OvyGey5yqjvCQn96WLd/Nz98tsn3c8fZp/+sb3AvDqqTnMgPE+NS5T33nnHVS+dlxOupOh5+XUszJb3J7B76G0wbeea1KHrDwoKVIuXltaVlQv2YqFzHcEGb1Zg2qK8gg3Y9JKaaQ5MQHWOxU+f+JB9/eXpsRPnK60aCUSH9xX3WC2tOm2GSzGkpfSsMHt6WCTu8sXAaj6fVb69wPw3v2nXIlMqj0+iyjy9FiF2ikplyldyDADRRD6riieMQ9voFD7yWW5XUcdSkEvsWsuyxdDHAfO/TTD8yu1ckaC6if4nZwPdzCKZCkdI2zJax0q4nH7MOpXnMuvdB4WyEq+o4PUoUe0nrjXofwEdFqhux/iuuID732Bz9b2cBTBdcAYRVvLGh3zuq77KlSZCxdkxmPFPlhi49G3s8S2xFWVYeuoFvnfa/uuWiCdSvOBeokHge1GrMk/ObDGDB6YniEd/O59H2wZl68MTa+CfwXnf8RVRoECBQrcnthby9WA5b6lHKR0bD/lvL/Bvqq4/OeaTVoHxBVNqmX6TdH/i08oDvfEt/d7KcaTJ52XQO2sTUSdT0gauRkbdG2bazWgfGlAPpyHC/xuQtC2rbMzviMcrlzCWVdpPaQ3bTAjHhbAM85lMVqx0pEsdDWMGYvE4rzYbTjr81B5xfVNC52bWAgdXXI0eH0dOktgMmzzV8aeBeDF/gH+qCSVCVlYdTWcGA/Vs0xEcYJns+UYs7VyYAClRp2C3MFkis1lMW1Uz8frWZczCMG2YKpE5axYOm9VpR+TzUvWNVjcYOU3pG7y56YPMV0SuW8cDujss63Gx6rUFsTSjdZjdGRbxsdClh+Se6Z1f8y+P5B7oH6mx8QJkXtpPdhizp1uTWxxr0cRShmigYWK52gG/aGBkBtpmbaba+e59a21t2VW1nCQyeUES4bygk1urYeOClKHBmXNfO3njGY6yP/QZeNysV4rwITyx/G1GV6a79C9QhPMnkt9kJFf65b5o5a4sXeXL3BHRbpTHrn/HD//xvcAUF2E9iHrzh9us/BeicUc+vw65VXrIqSe63+vvL5KxR5HN6tuUcYNn8iOzYg2DH5s99mJiQYuqolIrdCrSxpsaVZvMiStmZEPC6ieR/SqXH1WNmy25ad96UIDry7X4gcZrVhuyLWxCqkNzjXCHmNW6bazknO5DlZW3evPvP4IyRHZ/lx3nNbLEjufvtDDG7i8aZYrUWOGyq+Gst/Xwvk6ijC4+JzXU65XXXl5/BXyEJXS4NkSOJOm9GZE7tWkzvwfLACw+B37WL3XupwlePQvnQDg2TsOsXZKFmO0WiIYDIDQxinsxosRmb3Ru3MlRw05fA5JTXHq+f3E3dHu0PIwrlpoJa27Xn4JC4iinQrbLl/gY7hvUiouvr55ON/PUFzcGMWAacdEmrQi+wy6kNqHoZfiurX8DGxhDDrAhSN1CfoDrtxYkUYi5wsvz/LXex/nZOcXrnBdBQoUKFDgpuOqlqtS6hDwy8A8Egr+pDHmnyulJoFfB44Ap4CPGWNWd9oPgK4Y1h60Fsx6jf/7hffK+4tlPJtMOvEjP8c9PyAJlb838zHUJfHh9UoZPWFbDscixo7JTJyNBycdzRtaw6LQ6HmrJTxbF1sNPaJNeXKVL3ZzS2tlHd8y6k++5NE+aF2NAExf3je+El6BXUhq30zZli71OfpLwuRjwiBvc/V9jG0bNiWftCYF0Wf9KZc4PBcoF/ZQWd408XLNd5UAc8sJzwTvAkCXPA7aNuZgs4/a7AwuKD+hK1EPDg801Du7VTeKmylfFRj8MVkTWRhA39olkc4t1yELVnlDhOVp6mS9dm+NsVPye9QupjTOWU/uaMhDY2LRPv7IGV67S8ylxHi8vCJ97snnZti4X6w3U8poWbYsExjGXxDrdOMuzcx9whORxSHmja09+TcLN1O2PoaOTWh5ylC2dGJlL3HW6sFombJ11XtGMV2yI8w9vYUM/HLE4H41pWfpH4lze1KlyiW3/J5HMhCVJq/08I1r0VYa/K71XhJF8u0JTGfnIuJrCQukwP9ojPmWUqoBfFMp9QfAjwL/wRjzj5VSnwA+AfzklXYUhikHHhDFqY1icU2UX7TiUbOL7N+36/zlipj8/+fTv8o/ee3DAJw5O4U5IEJvHSgx/swrAIylQxnntQ3XL4/R8jfCOVqyZStmfQPVsB0F1Qp6URZisLzK2MZ+ALqHG5iOKIykotChZpeCgzdNtqAcr6pSCrMmVQFKZ9Czge5+n8AqTq9cGiJxKaGCQalKvjhNvYqpyqJXmXE0eMlkhaRus7WBl3cNheFli993PmW12x1aN02+JvHIOjvcLoNJsKna8hBOK/n111+X3yOrhqR123RQ8kjq1i3tw7859oR8b6VM7Q3fbgNpVXY61jOULtr3K54re0vqediqdsZjtSWKOegoGh242L/SlV03bppsMxRLqdyT+8O1LaNdBpMaOrrEUpbXlJ3tCFkQRuUcAsq421Qpw+AvnXiorl1nOg8FqFTlsdXIuHgqqcK3MXWVqC3uvbKNT0Fb0ZvWV8zFXDUsYIxZMMZ8y77eBF4CDgAfBX7JbvZLwA9ebV8FtqKQ7e6ikO/uoZDt1fGWElpKqSPAY8CfAXPGmAUQQSulZq/6/aHXBmjWJTp/6VAJbS3Ong55wSZdAL748G8D8FOzj7NpM05f/+PH8CYloWKUwizIwDGSoRpKrfOZUp1uPl56/xznvldOtTtrOPqbNgn0/Cv4p88DUGuNY+z2vWklj6BdzrvcqGzxPfSEVFnoaoiatq2qnRhv0IY6xJ+gxxvOEjWB55J/SuccDmmj5CoBvH7m2gN7U9eYILmWBoE9SmjdqHxLq5pDvyvy6k75xA3LstSEzFqWOjRoa/0orVADkiWl8DYsL0E3IFgSk9OfGyOryrpfeSAiWbe1nid8mq/Ll+O6R+uQPe5sntEurSrXAON3lRsqWVo11M8NzkFTWk051d3dRo0blW1ifDp2VlY5SqjaCwtV6oi+LyZNliKxbssq4eymWK7GqKvOCDM6r+JAK2fxK4Oz+IcHNiid8w+oDNcY4qW4Zo3qBcPYSVhqsyOuWbkqperAbwN/1xizoa7xplBK/RjwYwDR7Bi9VA5Zi2JWNu2K0JKVA/iHn/3rzNxvuUUvjPO++6VT6v76BX7j6+8G4PDZFD0lykN1+njjNlhiDPERcYlEYdjyi0CxfqcohLWHU8b2SQio7mecXxHCkv2vVTGDovZWm/RhISxpHc4woc5X9S7gZsi2HDXJmvLwSSt+fhNudGGIws40RObxbC3fjzFk0UDRKnxbwpbWfOfmhkPkNTrALdAd46wjVAVwU+TrN6ielTupfiLBDMhUQp94SuQeNwN6dlpB3FSYQYlWqUT3bllnZ747pHbG3qBL2jUa9Gfz8SObRxXdWcsF21OOS1hliDM+eD0IXac4Ra4jRXfa9su3DeWVaxTSdeJmyHb/AZ9Jy3IzzJFa9hIS61z3deAaCsa9Lo/NSH7hS+27h/Y5FNIaChf45RTtyz5NzyfLBgaD59a3P1QB4sf5gyvoQrhhuXgvZW4N+IvrZHPj+L2dG2GuqVpAKRUiAvwVY8y/tW9fVErts5/vAxYv911jzCeNMU8YY54Im5XLbfIXGjdNtkF1b074NsPNkm/kFWt3O26WbCcm355FS9dSLaCAXwReMsb8zNBHvwP8l8A/tv9/5mr7yrTH8qoksVY9Q9qy7qVWkpUDjn6mz9oLYn0eXNO89DUZGviyeYA56970JqF60rq4K2sYm8jJHjzCa/+N5Q2IMvzA1qq2ImZmJUk2bRRdy2I0Ue3yxsPyiDo4M4VZkdlDqlZl8Qmx7IKZNmk/2JWwwM2UrfE94jFL4ZhoysfOAZAtXcqp6ZRCrUhSoBT4dI6IxW88RWbJr7NIEdnMtg7zBI0ZskiMx9bqiUFSSqm3PhdrFy3cmyrfKGDx3eItldeMszib375I+O0XAShVq4xZ0mqmJ0gmRCHHd8+hB2TZFxX3//DLAJz45fuon7MWVVnnRRRJzqjlpfkARBSXZbgynsyeBAiGQgB+bPBSjdoF/oabqhdQXEpFbutZhcwMPE6P5/sH7DaeI85uegkVPw9xDSzUTHskqa2g0LnlmvV8lG0WUkY5195LwEtzLggX3gmM22bi5cRNi1DtHlyyhQ+lyK7dG+MWeB/wI8DzSqln7Xs/hQjvN5RSHwdOAz90tR0pZVz8IstUfl4lja7Iarr4RIX2AesWLPnO/ezNavSUCNR0fBqnbe//wiK6LzHFYHED05EQT6og6VjlnXgsr8iPp3yDN+jt3qyhrFLPJhqYU8Iy7mUZ1UX5UTdTLyfjuPm4abJN6orFx+V6D/5xB9OVynNVKuXx5uHs/PIa0bjc/K07Km6ygPFAZTnPq+taCZWECYDutOeG75WnylQ2rNWstdDigSjZy3Vl7W3o4KbJ1wSK/uSAQEW5RhT9nnma5y/I617fuYKe5xFtyE3Zesd+utMiu/o5zVpf5N757hbhZ+xDfMlHBg9BeVkR2vE6WSXvKJRjy/9ZJBNmQcI0gyY5KaWT10lNkdSDvIPu5uKmyTY2AdOBlFatpDXXRLAQN1nPRFbdLGRTy+sTusSrm2KA9dsRqVWoOvYxg1KroXvW6+SkLH6sCKWIiNK6cfSjS+8MuPvJNwB46eR+KhdF6NF6TNqUmGW00XGhQz09QftQFX18Z6v7qsrVGPMn7KyeP3i17xfYGYVsdxeFfHcPhWyvjj1tf9VGUalZK9PXpNZCShLfMX93ZyKCjmWweWeLsZokY5pB6hJguqLYPCzW0uQLPup+GVZozi1SPS21qp07TZ6MafbxLftNtdx3LEaNcp9eWXyu1UemGf+2PdEso/myPN4WPljDr6a7mtC6GZiYaPHoR8TdPL58H/Nrwp/otbswsCZ9TxoMAFOvcPHdVp7fuUYcW0YmzxD3LPNSO68K8NsB7JPf4nvveZm1WKyIb/7x/Ry01dd+L29/VWne8ipUeYP++0w+g7ceQriFSEt5iKQ7C4F1G/tNxcS8eEv69DlXxbL+1EESS20ZdjStQ7L9vq/GvHJcvKJ3PPAGp+uydpsnoG+pM9uHM2a+Lt+tLmUsPWbd5Ajqp2yyqmPoTb5Zt/XHlaPdXH9Pj86JMsk3Rye5eDlkxnMWatlLON+V9dTNQp5svg7AhX6TJ0vikn9y7R28dEbWd3ghIm0ME4jnLv9Aj5QvKWoLcg/UzvUIL1jq0qVldNtOQGi+27XOTs9tsDkjUzfOfleNyFq6s6nB7JcqheVHKvSmFelXd76uPSZuUYxV5Qb1lWFpPWccj0Ixz3vNDEoirKNTa/RtdUGc+W6bVqvMpi1PmRofY+H9sqDnv2ycu9qYbeFbhVgrxaRWoUZ+RjgYxWEU83Up7j72yDRTc7ZqZHwsDylqmBxvcdEf7SmlPpr3jQuH6ysfnmW5I51YY2/08Pp5RjNuiruz/HDEvT8oFI4/tu9L7vP5YJM1S9zyXPcwPVslfaHfdHGuj40/w5lUFtkLD82zuCbyD7o55aOX4rpfdCkvdfESXLzSy4ZKYF68GVLYPegIR+sX9CCxkRDPQDovsvAuLLqGCr9vWL1XLq52zqO6YN38yCNatlOM/ZT+RF7mM+BhVYki6Nm1e65Ld0oegmlNUV2S37KylBCPye/kxzDxim0g0YbOjPwI5eNl4nE98pMIlvp1fvW4NFAEQUZr3SYPFRyflntyea3OmCVZaAZdPGuMVRYV/XhQWQG184PMfkppSXRNcGaJbEkqkFSphL5TRrWQJHhly/mwlHLyolR0vO/Ok5x+Wr578vQs0bNyz6zeW3GhobRqQzRXeG69PdN0BQoUKHCLsbeWqzKOHqwUpJRLYgm1OyUmqvJUyuY8R0ZcC2NnuU6Uu8QDlqskoHOX+D7tB2fpzNlC4/dNYJOO3NHYZLVnEwdx6CxXVTLEmexnrVVhoyJhiqyR0XtEnmir95YYt9UI0WJAby7YwnI+ighUxqFIeBU+fMcxvvWjci1vLE/SW7EWTsvHOyBu0PuPvMyTzZMA1Ly8P3LcS9m0/f6e0ry/ItZtrxLy1bYQcC9lNXqW3j5JAiqW6SzaMK4mM+hrl/HOSsr11ntpHq5BSXXC7QAVaTr7B5SAULEhDe0rkjGRRblcIrXt1PVnIKlJrXR3ynP8F+19AZ5tobyztsw3H5J1r/s+wZJNaC15LL5Ltj//nWUOfUEEWb4U89oPyW+paz4E8rs1JjqcnRVXuv6Gx+G/Jr9rO4lY65a5UM5HRo8iMu3Ra9mBj7WY0J5v3Am5eNGGnJZD/k3nPQDMH1h1lUZeAuMnZL3WFhJKz0oYgYlmPmPs4hJoy6g1P0c8LjIMm2OYliQdg3ZKsirn8BWOok6KazK2lK/Pznw+j8x4oP0rh7X2VLn6yjg299DTHGhK7GNBjdG3Ci8KUtY7cmH9NGCsJOZ5on1XWnF4aoVWQwSx8PScmzKw9pChck72c3atSTkSBdntR47rtFHu07XnMIjnAni1hNX7RRmvP5BR2rDns67odEpuZMSoIlDaFVnvi9b5/nmJT911xyINT27g/2fp/dxdlbLDu0sXnVLd73fo2FXT9HyW7H7uiha5L5Rt2qbLs5aMNzMeU774yP1uyOwZWbillT5+y47fSLKt1QJDnAPD3K6DGPCow/M04b0SfFucqFE/KecddGC1Icp13LvXTctIL1xk/Ityzf7Td9Kes06igqp1XT/760+jj4isP/Ohf8H/uyJERp9/4wH+5lFJwP8vM8f4mQ9IXLajI368IsXzP/XcD9JdlfX65L7T/NRjXwDgWDLNuCcP0J89972stKvsenvhDaISxiibE9k/sc4HZ4U35NmNg8SW8vI5fYixF0TOGxPl/JIMLoQSNwPKFVsB88CMi/NXV9fI1kTXEPgELTHMlOfljUPaMP6CzTVE+ZqQUFFxAAAIcklEQVRMKzLgEBA/f7CMPa7auVmEBQoUKFBgF7C3AwqVIbUW6kqnQt/2qtdKsZsrVA0TFyLopiHjZXntDWXry35KZoe5jb1j2VUdpNqjk0iht5/47B8XS6PdLZEmls0988lsiKAUps4artb79G0HWWW+xYYtsPfjAa3ZTRfHTYWvNDO+JOdOMsd6Ktb/OTXBVCCP3lrQd4xDM8EG8764RGWFo3YLicjs47jq9d3cok2dVw7MB5v5sD7P4CXDRM22pnZ4lHaaXb6+1RhUMtou6wCeMjRsCGnscA8sR3OnHxFbT+iNJyKad8lssfn/uIJ5VeqmG88vogNJzGSRorwmsh5/VbNmmzo+/e6/5Go309Tnz1aOAPDj8ZhjgFruVmkekvvhN5/4FKEtaP0Xi9/FX/nX/5N8t2rwH5B10F0r45Uy1+45qgg9Tc3yjARKc9CGt5YrNT7/W08BMNYV3gSA7vExBquxsqzxewMuBePa4v2+hkGFSr0O6zblP+xNBYHjHzGB52qX05py0wqMj2tjHoYOuKppuuc+2UBJ9pOADrKwAj+jbCsB0qGxDa1+RNt2U6WZz3RdlMF6XKbky/YztZZTlv0sILrb9h9XelRsh9ZYrUdqS6422mUyW3Qc+Bk2FEjgaVqH5Lvz1R6L98m5qQtlylF2VXKIUUDNuvNNv81cKN1mm1mF2Lr8T9VfYz4Q9+iA38IOHmVzOJ6sY7TJWz179rsllbkOmWH4QYbxBjSP5AvOGLe4r4hRf2pZKIWb2hp42j1cqmHi+DJ65T6d75R19vKjDWon3wnAwf+wQe28KOa0FtBvikxX7wkdQcuxn3gIvyv7P2JSTCZK4lRWk6GOQDP0+Nd/7T8B4GcPfIhgU4Q98RIc/py40qvfcw8X9pfdeXtXiQuOCh6cESrSyaiDtosow2P+6zYUFXluhNMdvx+zfqeEBXWAa9AIuoaydemj1T56QExUKaEGzTNp6roNs+kmyb3Clbt6T0RvJm+kGRDwmO2u/8AusCGCK0m3CAsUKFCgwC5gz5sIBll7rRXdru3rU4b2YK6NZ1y1QNyOtjCHd8bsQLZaj8maBO1rYezmQlXDmE4ilm4nCZ1FO1/fJLBu70qv5rbxPU09EkvDw9A8OkieedQa8joupVsGpY0qFMYNcJsKWhzwxULdCEqMe3ItHR26QYShgkH5Y8/4zhILvYTFTFqLp/yWCxd44MZva6OcSzoz3sIEYilddgghiNk3zE2ghpJb12LdjgCMkZASiOUa2OtXyhCEtl07SBmviIx6jTabc7IuX50eZ/9XrBwTQ1KTdTn+akrtT1/NDzJorez2nNU/qLIAUEHA4X81xINik4GqXiN+4A4AoUIcFNJXUrLE28qnN4LQRvFwQ+g+Z8MNYruOq17MyR+2XCErAWNSxs3GHWVa91iv9FhI2LZrSOHCTyrJIBT9svnwDA1LHk+5RG+fhMza8wGdOWvFlnH8JsZjS1WAc1qHl6q5jFW7DXscFsi5Fz3PEC/JTWk8Q9AcjFXRxMvyfrDhO3ZwHRnSDSsso4ita79/fINWX96PM98RN/RMgFcWl8LDMBFJrCo1vmsi6KeBu2EAp2C6cZg3IFSko2vUvdd0qFK8pmL2B6JE95M69+Sk8ZmzjQDTfoVQDVylFm+kEgqYVImrIsjw3Hc3TcBF24l1JFxi3makk8zfQkd4WewkvOEhhiMOTxmXFwDcGvKUcZyjAJrBQyojstuMP9rj3D6Jm6qFMmFr4Fv6qKdkonFcz2kiw3aG35Nj6dDDi+V1uN5zLm1vtsLKA2IkdOcM6YQdu1PrMlaV32+QU1gKdqbFGxW80ZWOqGOb+4htN8XLS3OonnXtfeO63MzdbSa+LAqycTalPzaY7GxQPZGDqYTuwV1eiYkfktLEtXtK9GwnnFQCDCnUwSQCk3d6KZM/m0xk0GOy/wP7V/jgvlf4xU9v7nhNRVigQIECBXYByuyh5aCUWgLawKU9O+i1YZqrn9NhY8zMXpzM9eA2ly2Mvnw3gVdu9Xlsw9tFtrfz2t1RtnuqXAGUUt8wxjyxpwe9CkbxnK4Ho3gdo3hO14NRvI5RPKfrxShey42eUxEWKFCgQIFdQKFcCxQoUGAXcCuU6ydvwTGvhlE8p+vBKF7HKJ7T9WAUr2MUz+l6MYrXckPntOcx1wIFChT4i4AiLFCgQIECu4A9U65KqQ8ppV5RSr2qlPrEXh132zkcUkp9USn1klLqRaXU37Hv/7RS6pxS6ln77yO34vyuF4VsdxeFfHcPb2vZGmN2/R/SafkacBSIgOeAB/fi2NvOYx/wuH3dAI4DDwI/Dfz9vT6fQraj/6+QbyHb693vXlmu7wFeNcacNMbEwK8BH92jYzsYYxaMMd+yrzeBl4ADe30eNxmFbHcXhXx3D29r2e6Vcj0AnBn6+yy3eGEopY4AjwF/Zt/6CaXUnyulPq2UmrhlJ/bWUch2d1HId/fwtpbtXinXyzF33LIyBaVUHfht4O8aYzaAnwPuAt4JLAD/9Fad23WgkO3uopDv7uFtLdu9Uq5ngUNDfx8Ezu/RsbdAKRUiAvwVY8y/BTDGXDTGZMYYDXwKcVduFxSy3V0U8t09vK1lu1fK9RngHqXUnUqpCPhh4Hf26NgOSikF/CLwkjHmZ4be3ze02V8FXtjrc7sBFLLdXRTy3T28rWW7J3yuxphUKfUTwBeQDOGnjTEv7sWxt+F9wI8AzyulnrXv/RTwN5RS70RcklPA37oF53ZdKGS7uyjku3t4u8u26NAqUKBAgV1A0aFVoECBAruAQrkWKFCgwC6gUK4FChQosAsolGuBAgUK7AIK5VqgQIECu4BCuRYoUKDALqBQrgUKFCiwCyiUa4ECBQrsAv5/JKf0E4PltYEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#LOAING DATASET FOR NN\n",
    "from keras.datasets import cifar10\n",
    "(x_trainNN, y_trainNN), (x_testNN, y_testNN) = cifar10.load_data()\n",
    "\n",
    "#DATA RESHAPING\n",
    "#X_train is 60000 rows of 32x32 values --> reshaped in 60000 x 1024\n",
    "x_trainNN = rgb2gray(x_trainNN)\n",
    "x_testNN = rgb2gray(x_testNN)\n",
    "x_trainNN = x_trainNN.reshape(50000, 1024)\n",
    "x_testNN = x_testNN.reshape(10000, 1024)\n",
    "x_trainNN = x_trainNN.astype('float32')\n",
    "x_testNN = x_testNN.astype('float32')\n",
    "\n",
    "#x_trainNN /= 255 ############ NEVER EVER DO THIS AGAIN WITH rgb2gray!!!!!!!!!!!!!!!!!!!!!!\n",
    "#x_testNN /= 255 ############ NEVER EVER DO THIS AGAIN WITH rgb2gray!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "print(x_trainNN.shape[0], 'train samples')\n",
    "print(x_testNN.shape[0], 'test samples')\n",
    "# convert class vectors to binary class matrices\n",
    "y_trainNN = np_utils.to_categorical(y_trainNN, 10)\n",
    "y_testNN = np_utils.to_categorical(y_testNN, 10)\n",
    "\n",
    "\n",
    "#PLOTTING IMAGES\n",
    "for I in range(4):\n",
    "    for J in range(4):\n",
    "        plt.subplot(4,4,I*4+J+1)\n",
    "        plt.imshow(x_trainNN[I*4+J,:].reshape(32,32))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Neural Network\n",
    "# >> Accuracy ~0.26-0.30, depending on batch size (highest with size of 100). AKA: Not Great"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With the simple neural network, I decided to play around with batch size. I used batch sizes of 10, 25, 100, 1,000, and 10,000. The best results were obtained with a batch size of 100. These results, however, were still quite poor, with the model only correctly predicting the classification 30% of the time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 10,250\n",
      "Trainable params: 10,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\Adam\\Anaconda\\envs\\DeepLearningEnv\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Adam\\Anaconda\\envs\\DeepLearningEnv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Adam\\Anaconda\\envs\\DeepLearningEnv\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\Adam\\Anaconda\\envs\\DeepLearningEnv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 4s 93us/step - loss: 2.1320 - categorical_accuracy: 0.2331 - val_loss: 2.0980 - val_categorical_accuracy: 0.2373\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 4s 89us/step - loss: 2.0843 - categorical_accuracy: 0.2597 - val_loss: 2.1400 - val_categorical_accuracy: 0.2532\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 4s 93us/step - loss: 2.0704 - categorical_accuracy: 0.2680 - val_loss: 2.1590 - val_categorical_accuracy: 0.2297\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 4s 90us/step - loss: 2.0600 - categorical_accuracy: 0.2717 - val_loss: 2.0821 - val_categorical_accuracy: 0.2607\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 4s 91us/step - loss: 2.0531 - categorical_accuracy: 0.2770 - val_loss: 2.0816 - val_categorical_accuracy: 0.2636\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 4s 90us/step - loss: 2.0508 - categorical_accuracy: 0.2781 - val_loss: 2.1263 - val_categorical_accuracy: 0.2429\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 4s 91us/step - loss: 2.0456 - categorical_accuracy: 0.2789 - val_loss: 2.0789 - val_categorical_accuracy: 0.2736\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 4s 90us/step - loss: 2.0405 - categorical_accuracy: 0.2835 - val_loss: 2.0494 - val_categorical_accuracy: 0.2748\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 4s 95us/step - loss: 2.0374 - categorical_accuracy: 0.2831 - val_loss: 2.0777 - val_categorical_accuracy: 0.2645\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 4s 90us/step - loss: 2.0368 - categorical_accuracy: 0.2821 - val_loss: 2.0752 - val_categorical_accuracy: 0.2657\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 4s 90us/step - loss: 2.0306 - categorical_accuracy: 0.2874 - val_loss: 2.0771 - val_categorical_accuracy: 0.2765\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 4s 90us/step - loss: 2.0317 - categorical_accuracy: 0.2864 - val_loss: 2.0911 - val_categorical_accuracy: 0.2762\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 4s 90us/step - loss: 2.0318 - categorical_accuracy: 0.2887 - val_loss: 2.0833 - val_categorical_accuracy: 0.2624\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 4s 89us/step - loss: 2.0290 - categorical_accuracy: 0.2886 - val_loss: 2.0433 - val_categorical_accuracy: 0.2858\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 4s 95us/step - loss: 2.0272 - categorical_accuracy: 0.2860 - val_loss: 2.0982 - val_categorical_accuracy: 0.2550\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 4s 91us/step - loss: 2.0242 - categorical_accuracy: 0.2909 - val_loss: 2.0456 - val_categorical_accuracy: 0.2756\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 4s 93us/step - loss: 2.0240 - categorical_accuracy: 0.2919 - val_loss: 2.0460 - val_categorical_accuracy: 0.2791\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 4s 91us/step - loss: 2.0237 - categorical_accuracy: 0.2901 - val_loss: 2.0500 - val_categorical_accuracy: 0.2789\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 4s 91us/step - loss: 2.0230 - categorical_accuracy: 0.2914 - val_loss: 2.0972 - val_categorical_accuracy: 0.2581\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 4s 90us/step - loss: 2.0218 - categorical_accuracy: 0.2921 - val_loss: 2.0730 - val_categorical_accuracy: 0.2647\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 4s 91us/step - loss: 2.0204 - categorical_accuracy: 0.2912 - val_loss: 2.1371 - val_categorical_accuracy: 0.2546\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 4s 106us/step - loss: 2.0181 - categorical_accuracy: 0.2936 - val_loss: 2.1790 - val_categorical_accuracy: 0.2143\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 4s 91us/step - loss: 2.0177 - categorical_accuracy: 0.2946 - val_loss: 2.1774 - val_categorical_accuracy: 0.2086\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 4s 90us/step - loss: 2.0163 - categorical_accuracy: 0.2924 - val_loss: 2.1339 - val_categorical_accuracy: 0.2529\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 4s 90us/step - loss: 2.0159 - categorical_accuracy: 0.2961 - val_loss: 2.1367 - val_categorical_accuracy: 0.2486\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 4s 92us/step - loss: 2.0153 - categorical_accuracy: 0.2942 - val_loss: 2.1284 - val_categorical_accuracy: 0.2378\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 4s 91us/step - loss: 2.0144 - categorical_accuracy: 0.2930 - val_loss: 2.1106 - val_categorical_accuracy: 0.2722\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 4s 90us/step - loss: 2.0127 - categorical_accuracy: 0.2963 - val_loss: 2.0696 - val_categorical_accuracy: 0.2743\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 4s 89us/step - loss: 2.0141 - categorical_accuracy: 0.2976 - val_loss: 2.0825 - val_categorical_accuracy: 0.2681\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 3s 87us/step - loss: 2.0113 - categorical_accuracy: 0.2964 - val_loss: 2.1163 - val_categorical_accuracy: 0.2607\n",
      "10000/10000 [==============================] - 0s 14us/step\n",
      "Test score: 2.1329007205963135\n",
      "Test accuracy: 0.2612\n"
     ]
    }
   ],
   "source": [
    "# BATCH SIZE = 10, stopped epochs at 30 after seeing no improvement\n",
    "modelNN1 = Sequential()\n",
    "modelNN1.add(Dense(10, activation='softmax', input_shape=(1024,), kernel_initializer='random_uniform'))\n",
    "modelNN1.summary()\n",
    "\n",
    "epochs_SNN1 = 30\n",
    "batch_size_SNN1 = 10\n",
    "\n",
    "modelNN1.compile(loss='categorical_crossentropy', optimizer=SGD(), metrics=['categorical_accuracy'])\n",
    "history = modelNN1.fit(x_trainNN, y_trainNN, batch_size=batch_size_SNN1, epochs=epochs_SNN1, verbose=1, validation_split=0.2)\n",
    "\n",
    "score = modelNN1.evaluate(x_testNN, y_testNN, verbose=1)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 10,250\n",
      "Trainable params: 10,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "40000/40000 [==============================] - 2s 45us/step - loss: 2.1230 - categorical_accuracy: 0.2310 - val_loss: 2.0724 - val_categorical_accuracy: 0.2711\n",
      "Epoch 2/50\n",
      "40000/40000 [==============================] - 2s 42us/step - loss: 2.0653 - categorical_accuracy: 0.2683 - val_loss: 2.0571 - val_categorical_accuracy: 0.2782\n",
      "Epoch 3/50\n",
      "40000/40000 [==============================] - 2s 42us/step - loss: 2.0510 - categorical_accuracy: 0.2747 - val_loss: 2.0739 - val_categorical_accuracy: 0.2585\n",
      "Epoch 4/50\n",
      "40000/40000 [==============================] - 2s 43us/step - loss: 2.0415 - categorical_accuracy: 0.2802 - val_loss: 2.0394 - val_categorical_accuracy: 0.2851\n",
      "Epoch 5/50\n",
      "40000/40000 [==============================] - 2s 42us/step - loss: 2.0367 - categorical_accuracy: 0.2817 - val_loss: 2.0561 - val_categorical_accuracy: 0.2585\n",
      "Epoch 6/50\n",
      "40000/40000 [==============================] - 2s 42us/step - loss: 2.0305 - categorical_accuracy: 0.2876 - val_loss: 2.0374 - val_categorical_accuracy: 0.2857\n",
      "Epoch 7/50\n",
      "40000/40000 [==============================] - 2s 43us/step - loss: 2.0246 - categorical_accuracy: 0.2892 - val_loss: 2.0656 - val_categorical_accuracy: 0.2794\n",
      "Epoch 8/50\n",
      "40000/40000 [==============================] - 2s 42us/step - loss: 2.0204 - categorical_accuracy: 0.2943 - val_loss: 2.0425 - val_categorical_accuracy: 0.2904\n",
      "Epoch 9/50\n",
      "40000/40000 [==============================] - 2s 43us/step - loss: 2.0179 - categorical_accuracy: 0.2913 - val_loss: 2.0454 - val_categorical_accuracy: 0.2895\n",
      "Epoch 10/50\n",
      "40000/40000 [==============================] - 2s 46us/step - loss: 2.0150 - categorical_accuracy: 0.2972 - val_loss: 2.0517 - val_categorical_accuracy: 0.2832\n",
      "Epoch 11/50\n",
      "40000/40000 [==============================] - 2s 43us/step - loss: 2.0129 - categorical_accuracy: 0.2962 - val_loss: 2.0339 - val_categorical_accuracy: 0.2935\n",
      "Epoch 12/50\n",
      "40000/40000 [==============================] - 2s 43us/step - loss: 2.0104 - categorical_accuracy: 0.3004 - val_loss: 2.0346 - val_categorical_accuracy: 0.2942\n",
      "Epoch 13/50\n",
      "40000/40000 [==============================] - 2s 43us/step - loss: 2.0081 - categorical_accuracy: 0.2962 - val_loss: 2.0191 - val_categorical_accuracy: 0.3010\n",
      "Epoch 14/50\n",
      "40000/40000 [==============================] - 2s 43us/step - loss: 2.0073 - categorical_accuracy: 0.2998 - val_loss: 2.0400 - val_categorical_accuracy: 0.2908\n",
      "Epoch 15/50\n",
      "40000/40000 [==============================] - 2s 43us/step - loss: 2.0054 - categorical_accuracy: 0.3004 - val_loss: 2.0418 - val_categorical_accuracy: 0.2847\n",
      "Epoch 16/50\n",
      "40000/40000 [==============================] - 2s 44us/step - loss: 2.0040 - categorical_accuracy: 0.2995 - val_loss: 2.0277 - val_categorical_accuracy: 0.2929\n",
      "Epoch 17/50\n",
      "40000/40000 [==============================] - 2s 43us/step - loss: 2.0016 - categorical_accuracy: 0.3016 - val_loss: 2.0274 - val_categorical_accuracy: 0.2891\n",
      "Epoch 18/50\n",
      "40000/40000 [==============================] - 2s 44us/step - loss: 1.9990 - categorical_accuracy: 0.3044 - val_loss: 2.0384 - val_categorical_accuracy: 0.2800\n",
      "Epoch 19/50\n",
      "40000/40000 [==============================] - 2s 43us/step - loss: 1.9993 - categorical_accuracy: 0.3039 - val_loss: 2.0220 - val_categorical_accuracy: 0.2972\n",
      "Epoch 20/50\n",
      "40000/40000 [==============================] - 2s 43us/step - loss: 1.9975 - categorical_accuracy: 0.3036 - val_loss: 2.0319 - val_categorical_accuracy: 0.2908\n",
      "Epoch 21/50\n",
      "40000/40000 [==============================] - 2s 43us/step - loss: 1.9959 - categorical_accuracy: 0.3051 - val_loss: 2.0308 - val_categorical_accuracy: 0.2853\n",
      "Epoch 22/50\n",
      "40000/40000 [==============================] - 2s 43us/step - loss: 1.9937 - categorical_accuracy: 0.3070 - val_loss: 2.0338 - val_categorical_accuracy: 0.2844\n",
      "Epoch 23/50\n",
      "40000/40000 [==============================] - 2s 46us/step - loss: 1.9941 - categorical_accuracy: 0.3051 - val_loss: 2.0281 - val_categorical_accuracy: 0.2833\n",
      "Epoch 24/50\n",
      "40000/40000 [==============================] - 2s 44us/step - loss: 1.9926 - categorical_accuracy: 0.3048 - val_loss: 2.0310 - val_categorical_accuracy: 0.2895\n",
      "Epoch 25/50\n",
      "40000/40000 [==============================] - 2s 43us/step - loss: 1.9911 - categorical_accuracy: 0.3079 - val_loss: 2.0480 - val_categorical_accuracy: 0.2685\n",
      "Epoch 26/50\n",
      "40000/40000 [==============================] - 2s 43us/step - loss: 1.9914 - categorical_accuracy: 0.3075 - val_loss: 2.0275 - val_categorical_accuracy: 0.2845\n",
      "Epoch 27/50\n",
      "40000/40000 [==============================] - 2s 44us/step - loss: 1.9896 - categorical_accuracy: 0.3087 - val_loss: 2.0437 - val_categorical_accuracy: 0.2690\n",
      "Epoch 28/50\n",
      "40000/40000 [==============================] - 2s 47us/step - loss: 1.9903 - categorical_accuracy: 0.3073 - val_loss: 2.0292 - val_categorical_accuracy: 0.2911\n",
      "Epoch 29/50\n",
      "40000/40000 [==============================] - 2s 44us/step - loss: 1.9889 - categorical_accuracy: 0.3088 - val_loss: 2.0834 - val_categorical_accuracy: 0.2768\n",
      "Epoch 30/50\n",
      "40000/40000 [==============================] - 2s 44us/step - loss: 1.9874 - categorical_accuracy: 0.3063 - val_loss: 2.0268 - val_categorical_accuracy: 0.2850\n",
      "Epoch 31/50\n",
      "40000/40000 [==============================] - 2s 43us/step - loss: 1.9871 - categorical_accuracy: 0.3098 - val_loss: 2.0206 - val_categorical_accuracy: 0.2979\n",
      "Epoch 32/50\n",
      "40000/40000 [==============================] - 2s 43us/step - loss: 1.9864 - categorical_accuracy: 0.3078 - val_loss: 2.0366 - val_categorical_accuracy: 0.2899\n",
      "Epoch 33/50\n",
      "40000/40000 [==============================] - 2s 44us/step - loss: 1.9859 - categorical_accuracy: 0.3105 - val_loss: 2.0321 - val_categorical_accuracy: 0.2917\n",
      "Epoch 34/50\n",
      "40000/40000 [==============================] - 2s 45us/step - loss: 1.9865 - categorical_accuracy: 0.3100 - val_loss: 2.0230 - val_categorical_accuracy: 0.2911\n",
      "Epoch 35/50\n",
      "40000/40000 [==============================] - 2s 43us/step - loss: 1.9847 - categorical_accuracy: 0.3085 - val_loss: 2.0439 - val_categorical_accuracy: 0.2776\n",
      "Epoch 36/50\n",
      "40000/40000 [==============================] - 2s 43us/step - loss: 1.9825 - categorical_accuracy: 0.3112 - val_loss: 2.0336 - val_categorical_accuracy: 0.2825\n",
      "Epoch 37/50\n",
      "40000/40000 [==============================] - 2s 43us/step - loss: 1.9831 - categorical_accuracy: 0.3088 - val_loss: 2.0471 - val_categorical_accuracy: 0.2742\n",
      "Epoch 38/50\n",
      "40000/40000 [==============================] - 2s 43us/step - loss: 1.9828 - categorical_accuracy: 0.3111 - val_loss: 2.0429 - val_categorical_accuracy: 0.2851\n",
      "Epoch 39/50\n",
      "40000/40000 [==============================] - 2s 43us/step - loss: 1.9830 - categorical_accuracy: 0.3105 - val_loss: 2.0426 - val_categorical_accuracy: 0.2899\n",
      "Epoch 40/50\n",
      "40000/40000 [==============================] - 2s 43us/step - loss: 1.9812 - categorical_accuracy: 0.3110 - val_loss: 2.0452 - val_categorical_accuracy: 0.2916\n",
      "Epoch 41/50\n",
      "40000/40000 [==============================] - 2s 43us/step - loss: 1.9801 - categorical_accuracy: 0.3115 - val_loss: 2.0460 - val_categorical_accuracy: 0.2711\n",
      "Epoch 42/50\n",
      "40000/40000 [==============================] - 2s 43us/step - loss: 1.9814 - categorical_accuracy: 0.3110 - val_loss: 2.0242 - val_categorical_accuracy: 0.2870\n",
      "Epoch 43/50\n",
      "40000/40000 [==============================] - 2s 43us/step - loss: 1.9816 - categorical_accuracy: 0.3101 - val_loss: 2.0300 - val_categorical_accuracy: 0.2870\n",
      "Epoch 44/50\n",
      "40000/40000 [==============================] - 2s 44us/step - loss: 1.9801 - categorical_accuracy: 0.3125 - val_loss: 2.0224 - val_categorical_accuracy: 0.2926\n",
      "Epoch 45/50\n",
      "40000/40000 [==============================] - 2s 43us/step - loss: 1.9784 - categorical_accuracy: 0.3132 - val_loss: 2.0343 - val_categorical_accuracy: 0.2893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 1.9790 - categorical_accuracy: 0.3139 - val_loss: 2.0580 - val_categorical_accuracy: 0.2847\n",
      "Epoch 47/50\n",
      "40000/40000 [==============================] - 2s 45us/step - loss: 1.9770 - categorical_accuracy: 0.3134 - val_loss: 2.0335 - val_categorical_accuracy: 0.2938\n",
      "Epoch 48/50\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 1.9775 - categorical_accuracy: 0.3131 - val_loss: 2.0207 - val_categorical_accuracy: 0.2923\n",
      "Epoch 49/50\n",
      "40000/40000 [==============================] - 2s 42us/step - loss: 1.9786 - categorical_accuracy: 0.3142 - val_loss: 2.0320 - val_categorical_accuracy: 0.2780\n",
      "Epoch 50/50\n",
      "40000/40000 [==============================] - 2s 42us/step - loss: 1.9768 - categorical_accuracy: 0.3124 - val_loss: 2.0371 - val_categorical_accuracy: 0.2826\n",
      "10000/10000 [==============================] - 0s 12us/step\n",
      "Test score: 2.046433031463623\n",
      "Test accuracy: 0.2808\n"
     ]
    }
   ],
   "source": [
    "# BATCH SIZE = 25, stopped epochs at 50 after seeing no improvement\n",
    "modelNN2 = Sequential()\n",
    "modelNN2.add(Dense(10, activation='softmax', input_shape=(1024,), kernel_initializer='random_uniform'))\n",
    "modelNN2.summary()\n",
    "\n",
    "epochs_SNN2 = 50\n",
    "batch_size_SNN2 = 25\n",
    "\n",
    "modelNN2.compile(loss='categorical_crossentropy', optimizer=SGD(), metrics=['categorical_accuracy'])\n",
    "history = modelNN2.fit(x_trainNN, y_trainNN, batch_size=batch_size_SNN2, epochs=epochs_SNN2, verbose=1, validation_split=0.2)\n",
    "\n",
    "score = modelNN2.evaluate(x_testNN, y_testNN, verbose=1)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 10,250\n",
      "Trainable params: 10,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "40000/40000 [==============================] - 1s 20us/step - loss: 2.1766 - categorical_accuracy: 0.2073 - val_loss: 2.1171 - val_categorical_accuracy: 0.2392\n",
      "Epoch 2/50\n",
      "40000/40000 [==============================] - 1s 19us/step - loss: 2.0980 - categorical_accuracy: 0.2513 - val_loss: 2.0829 - val_categorical_accuracy: 0.2599\n",
      "Epoch 3/50\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 2.0743 - categorical_accuracy: 0.2639 - val_loss: 2.0722 - val_categorical_accuracy: 0.2709\n",
      "Epoch 4/50\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 2.0609 - categorical_accuracy: 0.2706 - val_loss: 2.0632 - val_categorical_accuracy: 0.2812\n",
      "Epoch 5/50\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 2.0527 - categorical_accuracy: 0.2756 - val_loss: 2.0551 - val_categorical_accuracy: 0.2807\n",
      "Epoch 6/50\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 2.0469 - categorical_accuracy: 0.2800 - val_loss: 2.0551 - val_categorical_accuracy: 0.2784\n",
      "Epoch 7/50\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 2.0419 - categorical_accuracy: 0.2856 - val_loss: 2.0485 - val_categorical_accuracy: 0.2855\n",
      "Epoch 8/50\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 2.0377 - categorical_accuracy: 0.2851 - val_loss: 2.0438 - val_categorical_accuracy: 0.2929\n",
      "Epoch 9/50\n",
      "40000/40000 [==============================] - 1s 15us/step - loss: 2.0346 - categorical_accuracy: 0.2891 - val_loss: 2.0430 - val_categorical_accuracy: 0.2905\n",
      "Epoch 10/50\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 2.0316 - categorical_accuracy: 0.2911 - val_loss: 2.0427 - val_categorical_accuracy: 0.2868\n",
      "Epoch 11/50\n",
      "40000/40000 [==============================] - 1s 15us/step - loss: 2.0284 - categorical_accuracy: 0.2924 - val_loss: 2.0385 - val_categorical_accuracy: 0.2876\n",
      "Epoch 12/50\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 2.0260 - categorical_accuracy: 0.2949 - val_loss: 2.0381 - val_categorical_accuracy: 0.2804\n",
      "Epoch 13/50\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 2.0237 - categorical_accuracy: 0.2916 - val_loss: 2.0403 - val_categorical_accuracy: 0.2933\n",
      "Epoch 14/50\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 2.0220 - categorical_accuracy: 0.2960 - val_loss: 2.0351 - val_categorical_accuracy: 0.2882\n",
      "Epoch 15/50\n",
      "40000/40000 [==============================] - 1s 17us/step - loss: 2.0199 - categorical_accuracy: 0.2966 - val_loss: 2.0371 - val_categorical_accuracy: 0.2871\n",
      "Epoch 16/50\n",
      "40000/40000 [==============================] - 1s 17us/step - loss: 2.0182 - categorical_accuracy: 0.2977 - val_loss: 2.0326 - val_categorical_accuracy: 0.2980\n",
      "Epoch 17/50\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 2.0165 - categorical_accuracy: 0.2995 - val_loss: 2.0320 - val_categorical_accuracy: 0.2943\n",
      "Epoch 18/50\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 2.0151 - categorical_accuracy: 0.2997 - val_loss: 2.0296 - val_categorical_accuracy: 0.2951\n",
      "Epoch 19/50\n",
      "40000/40000 [==============================] - ETA: 0s - loss: 2.0138 - categorical_accuracy: 0.29 - 1s 16us/step - loss: 2.0142 - categorical_accuracy: 0.2988 - val_loss: 2.0351 - val_categorical_accuracy: 0.2937\n",
      "Epoch 20/50\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 2.0121 - categorical_accuracy: 0.3015 - val_loss: 2.0321 - val_categorical_accuracy: 0.2839\n",
      "Epoch 21/50\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 2.0108 - categorical_accuracy: 0.3027 - val_loss: 2.0317 - val_categorical_accuracy: 0.2977\n",
      "Epoch 22/50\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 2.0096 - categorical_accuracy: 0.3024 - val_loss: 2.0310 - val_categorical_accuracy: 0.2977\n",
      "Epoch 23/50\n",
      "40000/40000 [==============================] - 1s 17us/step - loss: 2.0077 - categorical_accuracy: 0.3035 - val_loss: 2.0290 - val_categorical_accuracy: 0.2950\n",
      "Epoch 24/50\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 2.0072 - categorical_accuracy: 0.3048 - val_loss: 2.0351 - val_categorical_accuracy: 0.2941\n",
      "Epoch 25/50\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 2.0057 - categorical_accuracy: 0.3038 - val_loss: 2.0331 - val_categorical_accuracy: 0.2897\n",
      "Epoch 26/50\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 2.0050 - categorical_accuracy: 0.3049 - val_loss: 2.0306 - val_categorical_accuracy: 0.2917\n",
      "Epoch 27/50\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 2.0040 - categorical_accuracy: 0.3055 - val_loss: 2.0260 - val_categorical_accuracy: 0.2910\n",
      "Epoch 28/50\n",
      "40000/40000 [==============================] - 1s 19us/step - loss: 2.0030 - categorical_accuracy: 0.3052 - val_loss: 2.0364 - val_categorical_accuracy: 0.2867\n",
      "Epoch 29/50\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 2.0020 - categorical_accuracy: 0.3072 - val_loss: 2.0259 - val_categorical_accuracy: 0.2994\n",
      "Epoch 30/50\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 2.0010 - categorical_accuracy: 0.3071 - val_loss: 2.0252 - val_categorical_accuracy: 0.2996\n",
      "Epoch 31/50\n",
      "40000/40000 [==============================] - 1s 17us/step - loss: 1.9998 - categorical_accuracy: 0.3083 - val_loss: 2.0242 - val_categorical_accuracy: 0.2986\n",
      "Epoch 32/50\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 1.9984 - categorical_accuracy: 0.3110 - val_loss: 2.0239 - val_categorical_accuracy: 0.2992\n",
      "Epoch 33/50\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 1.9977 - categorical_accuracy: 0.3094 - val_loss: 2.0226 - val_categorical_accuracy: 0.3023\n",
      "Epoch 34/50\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 1.9974 - categorical_accuracy: 0.3098 - val_loss: 2.0208 - val_categorical_accuracy: 0.2951\n",
      "Epoch 35/50\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 1.9968 - categorical_accuracy: 0.3087 - val_loss: 2.0248 - val_categorical_accuracy: 0.3071\n",
      "Epoch 36/50\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 1.9958 - categorical_accuracy: 0.3086 - val_loss: 2.0193 - val_categorical_accuracy: 0.2997\n",
      "Epoch 37/50\n",
      "40000/40000 [==============================] - 1s 17us/step - loss: 1.9952 - categorical_accuracy: 0.3113 - val_loss: 2.0212 - val_categorical_accuracy: 0.3056\n",
      "Epoch 38/50\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 1.9945 - categorical_accuracy: 0.3108 - val_loss: 2.0188 - val_categorical_accuracy: 0.3052\n",
      "Epoch 39/50\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 1.9938 - categorical_accuracy: 0.3096 - val_loss: 2.0224 - val_categorical_accuracy: 0.2959\n",
      "Epoch 40/50\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 1.9932 - categorical_accuracy: 0.3102 - val_loss: 2.0220 - val_categorical_accuracy: 0.3002\n",
      "Epoch 41/50\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 1.9929 - categorical_accuracy: 0.3117 - val_loss: 2.0211 - val_categorical_accuracy: 0.2889\n",
      "Epoch 42/50\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 1.9913 - categorical_accuracy: 0.3143 - val_loss: 2.0201 - val_categorical_accuracy: 0.2938\n",
      "Epoch 43/50\n",
      "40000/40000 [==============================] - 1s 18us/step - loss: 1.9907 - categorical_accuracy: 0.3110 - val_loss: 2.0200 - val_categorical_accuracy: 0.3003\n",
      "Epoch 44/50\n",
      "40000/40000 [==============================] - 1s 17us/step - loss: 1.9903 - categorical_accuracy: 0.3121 - val_loss: 2.0273 - val_categorical_accuracy: 0.2963\n",
      "Epoch 45/50\n",
      "40000/40000 [==============================] - 1s 15us/step - loss: 1.9900 - categorical_accuracy: 0.3113 - val_loss: 2.0191 - val_categorical_accuracy: 0.3022\n",
      "Epoch 46/50\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 1.9894 - categorical_accuracy: 0.3121 - val_loss: 2.0215 - val_categorical_accuracy: 0.2976\n",
      "Epoch 47/50\n",
      "40000/40000 [==============================] - 1s 15us/step - loss: 1.9890 - categorical_accuracy: 0.3127 - val_loss: 2.0155 - val_categorical_accuracy: 0.3019\n",
      "Epoch 48/50\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 1.9881 - categorical_accuracy: 0.3127 - val_loss: 2.0208 - val_categorical_accuracy: 0.2961\n",
      "Epoch 49/50\n",
      "40000/40000 [==============================] - 1s 18us/step - loss: 1.9877 - categorical_accuracy: 0.3141 - val_loss: 2.0203 - val_categorical_accuracy: 0.2943\n",
      "Epoch 50/50\n",
      "40000/40000 [==============================] - 1s 15us/step - loss: 1.9872 - categorical_accuracy: 0.3141 - val_loss: 2.0214 - val_categorical_accuracy: 0.2990\n",
      "10000/10000 [==============================] - 0s 13us/step\n",
      "Test score: 2.0269886547088625\n",
      "Test accuracy: 0.3013\n"
     ]
    }
   ],
   "source": [
    "# BATCH SIZE = 100, stopped epochs at 50 after seeing no improvement\n",
    "modelNN3 = Sequential()\n",
    "modelNN3.add(Dense(10, activation='softmax', input_shape=(1024,), kernel_initializer='random_uniform'))\n",
    "modelNN3.summary()\n",
    "\n",
    "epochs_NN3 = 50\n",
    "batch_size_NN3 = 100\n",
    "\n",
    "modelNN3.compile(loss='categorical_crossentropy', optimizer=SGD(), metrics=['categorical_accuracy'])\n",
    "history = modelNN3.fit(x_trainNN, y_trainNN, batch_size=batch_size_NN3, epochs=epochs_NN3, verbose=1, validation_split=0.2)\n",
    "\n",
    "score = modelNN3.evaluate(x_testNN, y_testNN, verbose=1)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 10,250\n",
      "Trainable params: 10,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 2.2974 - categorical_accuracy: 0.1284 - val_loss: 2.2611 - val_categorical_accuracy: 0.1682\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.2388 - categorical_accuracy: 0.1778 - val_loss: 2.2176 - val_categorical_accuracy: 0.1976\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.2032 - categorical_accuracy: 0.2006 - val_loss: 2.1888 - val_categorical_accuracy: 0.2110\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.1791 - categorical_accuracy: 0.2135 - val_loss: 2.1691 - val_categorical_accuracy: 0.2201\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.1616 - categorical_accuracy: 0.2224 - val_loss: 2.1550 - val_categorical_accuracy: 0.2288\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 0s 8us/step - loss: 2.1481 - categorical_accuracy: 0.2287 - val_loss: 2.1425 - val_categorical_accuracy: 0.2273\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 0s 8us/step - loss: 2.1373 - categorical_accuracy: 0.2337 - val_loss: 2.1339 - val_categorical_accuracy: 0.2367\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.1285 - categorical_accuracy: 0.2403 - val_loss: 2.1257 - val_categorical_accuracy: 0.2365\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.1210 - categorical_accuracy: 0.2424 - val_loss: 2.1193 - val_categorical_accuracy: 0.2421\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 0s 8us/step - loss: 2.1146 - categorical_accuracy: 0.2466 - val_loss: 2.1135 - val_categorical_accuracy: 0.2503\n",
      "Epoch 11/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.1092 - categorical_accuracy: 0.2518 - val_loss: 2.1083 - val_categorical_accuracy: 0.2457\n",
      "Epoch 12/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.1042 - categorical_accuracy: 0.2529 - val_loss: 2.1038 - val_categorical_accuracy: 0.2525\n",
      "Epoch 13/100\n",
      "40000/40000 [==============================] - 0s 8us/step - loss: 2.0997 - categorical_accuracy: 0.2551 - val_loss: 2.0998 - val_categorical_accuracy: 0.2562\n",
      "Epoch 14/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0956 - categorical_accuracy: 0.2594 - val_loss: 2.0967 - val_categorical_accuracy: 0.2572\n",
      "Epoch 15/100\n",
      "40000/40000 [==============================] - 0s 8us/step - loss: 2.0919 - categorical_accuracy: 0.2584 - val_loss: 2.0931 - val_categorical_accuracy: 0.2586\n",
      "Epoch 16/100\n",
      "40000/40000 [==============================] - 0s 8us/step - loss: 2.0885 - categorical_accuracy: 0.2615 - val_loss: 2.0902 - val_categorical_accuracy: 0.2569\n",
      "Epoch 17/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0856 - categorical_accuracy: 0.2626 - val_loss: 2.0876 - val_categorical_accuracy: 0.2639\n",
      "Epoch 18/100\n",
      "40000/40000 [==============================] - 0s 8us/step - loss: 2.0825 - categorical_accuracy: 0.2640 - val_loss: 2.0874 - val_categorical_accuracy: 0.2669\n",
      "Epoch 19/100\n",
      "40000/40000 [==============================] - 0s 8us/step - loss: 2.0802 - categorical_accuracy: 0.2664 - val_loss: 2.0825 - val_categorical_accuracy: 0.2644\n",
      "Epoch 20/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0778 - categorical_accuracy: 0.2682 - val_loss: 2.0799 - val_categorical_accuracy: 0.2608\n",
      "Epoch 21/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0754 - categorical_accuracy: 0.2678 - val_loss: 2.0784 - val_categorical_accuracy: 0.2679\n",
      "Epoch 22/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0732 - categorical_accuracy: 0.2700 - val_loss: 2.0765 - val_categorical_accuracy: 0.2680\n",
      "Epoch 23/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0713 - categorical_accuracy: 0.2710 - val_loss: 2.0751 - val_categorical_accuracy: 0.2677\n",
      "Epoch 24/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0695 - categorical_accuracy: 0.2720 - val_loss: 2.0736 - val_categorical_accuracy: 0.2673\n",
      "Epoch 25/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0677 - categorical_accuracy: 0.2731 - val_loss: 2.0721 - val_categorical_accuracy: 0.2730\n",
      "Epoch 26/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0661 - categorical_accuracy: 0.2734 - val_loss: 2.0700 - val_categorical_accuracy: 0.2706\n",
      "Epoch 27/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0645 - categorical_accuracy: 0.2742 - val_loss: 2.0694 - val_categorical_accuracy: 0.2744\n",
      "Epoch 28/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0631 - categorical_accuracy: 0.2777 - val_loss: 2.0679 - val_categorical_accuracy: 0.2727\n",
      "Epoch 29/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0618 - categorical_accuracy: 0.2764 - val_loss: 2.0667 - val_categorical_accuracy: 0.2746\n",
      "Epoch 30/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0603 - categorical_accuracy: 0.2774 - val_loss: 2.0651 - val_categorical_accuracy: 0.2750\n",
      "Epoch 31/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0589 - categorical_accuracy: 0.2775 - val_loss: 2.0641 - val_categorical_accuracy: 0.2750\n",
      "Epoch 32/100\n",
      "40000/40000 [==============================] - 0s 8us/step - loss: 2.0578 - categorical_accuracy: 0.2794 - val_loss: 2.0633 - val_categorical_accuracy: 0.2787\n",
      "Epoch 33/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0564 - categorical_accuracy: 0.2806 - val_loss: 2.0624 - val_categorical_accuracy: 0.2769\n",
      "Epoch 34/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0556 - categorical_accuracy: 0.2808 - val_loss: 2.0611 - val_categorical_accuracy: 0.2763\n",
      "Epoch 35/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0545 - categorical_accuracy: 0.2806 - val_loss: 2.0604 - val_categorical_accuracy: 0.2752\n",
      "Epoch 36/100\n",
      "40000/40000 [==============================] - 0s 8us/step - loss: 2.0534 - categorical_accuracy: 0.2809 - val_loss: 2.0591 - val_categorical_accuracy: 0.2789\n",
      "Epoch 37/100\n",
      "40000/40000 [==============================] - 0s 8us/step - loss: 2.0522 - categorical_accuracy: 0.2826 - val_loss: 2.0590 - val_categorical_accuracy: 0.2831\n",
      "Epoch 38/100\n",
      "40000/40000 [==============================] - 0s 8us/step - loss: 2.0514 - categorical_accuracy: 0.2828 - val_loss: 2.0580 - val_categorical_accuracy: 0.2790\n",
      "Epoch 39/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0506 - categorical_accuracy: 0.2825 - val_loss: 2.0571 - val_categorical_accuracy: 0.2753\n",
      "Epoch 40/100\n",
      "40000/40000 [==============================] - 0s 8us/step - loss: 2.0497 - categorical_accuracy: 0.2823 - val_loss: 2.0558 - val_categorical_accuracy: 0.2788\n",
      "Epoch 41/100\n",
      "40000/40000 [==============================] - 0s 10us/step - loss: 2.0488 - categorical_accuracy: 0.2838 - val_loss: 2.0560 - val_categorical_accuracy: 0.2804\n",
      "Epoch 42/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0481 - categorical_accuracy: 0.2847 - val_loss: 2.0550 - val_categorical_accuracy: 0.2789\n",
      "Epoch 43/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0473 - categorical_accuracy: 0.2842 - val_loss: 2.0543 - val_categorical_accuracy: 0.2818\n",
      "Epoch 44/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0466 - categorical_accuracy: 0.2846 - val_loss: 2.0536 - val_categorical_accuracy: 0.2826\n",
      "Epoch 45/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0458 - categorical_accuracy: 0.2863 - val_loss: 2.0531 - val_categorical_accuracy: 0.2789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0452 - categorical_accuracy: 0.2855 - val_loss: 2.0525 - val_categorical_accuracy: 0.2822\n",
      "Epoch 47/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0444 - categorical_accuracy: 0.2874 - val_loss: 2.0522 - val_categorical_accuracy: 0.2849\n",
      "Epoch 48/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0438 - categorical_accuracy: 0.2875 - val_loss: 2.0516 - val_categorical_accuracy: 0.2822\n",
      "Epoch 49/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0433 - categorical_accuracy: 0.2863 - val_loss: 2.0509 - val_categorical_accuracy: 0.2844\n",
      "Epoch 50/100\n",
      "40000/40000 [==============================] - 0s 10us/step - loss: 2.0424 - categorical_accuracy: 0.2864 - val_loss: 2.0515 - val_categorical_accuracy: 0.2864\n",
      "Epoch 51/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0418 - categorical_accuracy: 0.2888 - val_loss: 2.0505 - val_categorical_accuracy: 0.2861\n",
      "Epoch 52/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0413 - categorical_accuracy: 0.2885 - val_loss: 2.0497 - val_categorical_accuracy: 0.2822\n",
      "Epoch 53/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0407 - categorical_accuracy: 0.2881 - val_loss: 2.0495 - val_categorical_accuracy: 0.2861\n",
      "Epoch 54/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0401 - categorical_accuracy: 0.2891 - val_loss: 2.0483 - val_categorical_accuracy: 0.2848\n",
      "Epoch 55/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0397 - categorical_accuracy: 0.2887 - val_loss: 2.0484 - val_categorical_accuracy: 0.2854\n",
      "Epoch 56/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0391 - categorical_accuracy: 0.2890 - val_loss: 2.0478 - val_categorical_accuracy: 0.2847\n",
      "Epoch 57/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0384 - categorical_accuracy: 0.2905 - val_loss: 2.0476 - val_categorical_accuracy: 0.2865\n",
      "Epoch 58/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0381 - categorical_accuracy: 0.2907 - val_loss: 2.0470 - val_categorical_accuracy: 0.2829\n",
      "Epoch 59/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0376 - categorical_accuracy: 0.2900 - val_loss: 2.0465 - val_categorical_accuracy: 0.2867\n",
      "Epoch 60/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0371 - categorical_accuracy: 0.2915 - val_loss: 2.0461 - val_categorical_accuracy: 0.2866\n",
      "Epoch 61/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0367 - categorical_accuracy: 0.2901 - val_loss: 2.0454 - val_categorical_accuracy: 0.2857\n",
      "Epoch 62/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0361 - categorical_accuracy: 0.2910 - val_loss: 2.0459 - val_categorical_accuracy: 0.2880\n",
      "Epoch 63/100\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 2.0357 - categorical_accuracy: 0.2910 - val_loss: 2.0463 - val_categorical_accuracy: 0.2894\n",
      "Epoch 64/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0352 - categorical_accuracy: 0.2911 - val_loss: 2.0456 - val_categorical_accuracy: 0.2902\n",
      "Epoch 65/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0349 - categorical_accuracy: 0.2927 - val_loss: 2.0444 - val_categorical_accuracy: 0.2883\n",
      "Epoch 66/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0341 - categorical_accuracy: 0.2931 - val_loss: 2.0442 - val_categorical_accuracy: 0.2856\n",
      "Epoch 67/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0339 - categorical_accuracy: 0.2917 - val_loss: 2.0438 - val_categorical_accuracy: 0.2892\n",
      "Epoch 68/100\n",
      "40000/40000 [==============================] - 0s 10us/step - loss: 2.0336 - categorical_accuracy: 0.2919 - val_loss: 2.0435 - val_categorical_accuracy: 0.2883\n",
      "Epoch 69/100\n",
      "40000/40000 [==============================] - 0s 8us/step - loss: 2.0332 - categorical_accuracy: 0.2918 - val_loss: 2.0433 - val_categorical_accuracy: 0.2893\n",
      "Epoch 70/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0327 - categorical_accuracy: 0.2939 - val_loss: 2.0429 - val_categorical_accuracy: 0.2855\n",
      "Epoch 71/100\n",
      "40000/40000 [==============================] - 0s 8us/step - loss: 2.0323 - categorical_accuracy: 0.2928 - val_loss: 2.0426 - val_categorical_accuracy: 0.2880\n",
      "Epoch 72/100\n",
      "40000/40000 [==============================] - 0s 8us/step - loss: 2.0319 - categorical_accuracy: 0.2936 - val_loss: 2.0422 - val_categorical_accuracy: 0.2894\n",
      "Epoch 73/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0316 - categorical_accuracy: 0.2940 - val_loss: 2.0424 - val_categorical_accuracy: 0.2905\n",
      "Epoch 74/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0312 - categorical_accuracy: 0.2931 - val_loss: 2.0420 - val_categorical_accuracy: 0.2933\n",
      "Epoch 75/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0310 - categorical_accuracy: 0.2935 - val_loss: 2.0422 - val_categorical_accuracy: 0.2910\n",
      "Epoch 76/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0304 - categorical_accuracy: 0.2939 - val_loss: 2.0417 - val_categorical_accuracy: 0.2931\n",
      "Epoch 77/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0301 - categorical_accuracy: 0.2945 - val_loss: 2.0410 - val_categorical_accuracy: 0.2901\n",
      "Epoch 78/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0297 - categorical_accuracy: 0.2935 - val_loss: 2.0412 - val_categorical_accuracy: 0.2915\n",
      "Epoch 79/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0293 - categorical_accuracy: 0.2936 - val_loss: 2.0403 - val_categorical_accuracy: 0.2897\n",
      "Epoch 80/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0292 - categorical_accuracy: 0.2931 - val_loss: 2.0409 - val_categorical_accuracy: 0.2912\n",
      "Epoch 81/100\n",
      "40000/40000 [==============================] - 0s 8us/step - loss: 2.0287 - categorical_accuracy: 0.2940 - val_loss: 2.0396 - val_categorical_accuracy: 0.2884\n",
      "Epoch 82/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0286 - categorical_accuracy: 0.2949 - val_loss: 2.0398 - val_categorical_accuracy: 0.2912\n",
      "Epoch 83/100\n",
      "40000/40000 [==============================] - 0s 8us/step - loss: 2.0281 - categorical_accuracy: 0.2947 - val_loss: 2.0402 - val_categorical_accuracy: 0.2937\n",
      "Epoch 84/100\n",
      "40000/40000 [==============================] - 0s 8us/step - loss: 2.0280 - categorical_accuracy: 0.2963 - val_loss: 2.0391 - val_categorical_accuracy: 0.2895\n",
      "Epoch 85/100\n",
      "40000/40000 [==============================] - 0s 8us/step - loss: 2.0276 - categorical_accuracy: 0.2952 - val_loss: 2.0397 - val_categorical_accuracy: 0.2897\n",
      "Epoch 86/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0272 - categorical_accuracy: 0.2946 - val_loss: 2.0393 - val_categorical_accuracy: 0.2923\n",
      "Epoch 87/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0267 - categorical_accuracy: 0.2960 - val_loss: 2.0392 - val_categorical_accuracy: 0.2932\n",
      "Epoch 88/100\n",
      "40000/40000 [==============================] - 0s 8us/step - loss: 2.0267 - categorical_accuracy: 0.2973 - val_loss: 2.0380 - val_categorical_accuracy: 0.2895\n",
      "Epoch 89/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0262 - categorical_accuracy: 0.2959 - val_loss: 2.0386 - val_categorical_accuracy: 0.2923\n",
      "Epoch 90/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0258 - categorical_accuracy: 0.2972 - val_loss: 2.0389 - val_categorical_accuracy: 0.2917\n",
      "Epoch 91/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0256 - categorical_accuracy: 0.2966 - val_loss: 2.0386 - val_categorical_accuracy: 0.2946\n",
      "Epoch 92/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0252 - categorical_accuracy: 0.2982 - val_loss: 2.0375 - val_categorical_accuracy: 0.2886\n",
      "Epoch 93/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0252 - categorical_accuracy: 0.2957 - val_loss: 2.0380 - val_categorical_accuracy: 0.2931\n",
      "Epoch 94/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0248 - categorical_accuracy: 0.2974 - val_loss: 2.0374 - val_categorical_accuracy: 0.2946\n",
      "Epoch 95/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0246 - categorical_accuracy: 0.2968 - val_loss: 2.0380 - val_categorical_accuracy: 0.2944\n",
      "Epoch 96/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0241 - categorical_accuracy: 0.2982 - val_loss: 2.0370 - val_categorical_accuracy: 0.2921\n",
      "Epoch 97/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0240 - categorical_accuracy: 0.2980 - val_loss: 2.0366 - val_categorical_accuracy: 0.2943\n",
      "Epoch 98/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0235 - categorical_accuracy: 0.2979 - val_loss: 2.0369 - val_categorical_accuracy: 0.2946\n",
      "Epoch 99/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0235 - categorical_accuracy: 0.2978 - val_loss: 2.0366 - val_categorical_accuracy: 0.2924\n",
      "Epoch 100/100\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.0232 - categorical_accuracy: 0.2980 - val_loss: 2.0363 - val_categorical_accuracy: 0.2937\n",
      "10000/10000 [==============================] - 0s 13us/step\n",
      "Test score: 2.0437750957489014\n",
      "Test accuracy: 0.2951\n"
     ]
    }
   ],
   "source": [
    "# BATCH SIZE = 1000, stopped epochs at 100 after seeing no improvement\n",
    "modelNN4 = Sequential()\n",
    "modelNN4.add(Dense(10, activation='softmax', input_shape=(1024,), kernel_initializer='random_uniform'))\n",
    "modelNN4.summary()\n",
    "\n",
    "epochs_SNN4 = 100\n",
    "batch_size_SNN4 = 1000\n",
    "\n",
    "modelNN4.compile(loss='categorical_crossentropy', optimizer=SGD(), metrics=['categorical_accuracy'])\n",
    "history = modelNN4.fit(x_trainNN, y_trainNN, batch_size=batch_size_SNN4, epochs=epochs_SNN4, verbose=1, validation_split=0.2)\n",
    "\n",
    "score = modelNN4.evaluate(x_testNN, y_testNN, verbose=1)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 10,250\n",
      "Trainable params: 10,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/400\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 2.3751 - categorical_accuracy: 0.0987 - val_loss: 2.3231 - val_categorical_accuracy: 0.1090\n",
      "Epoch 2/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.3115 - categorical_accuracy: 0.1134 - val_loss: 2.3035 - val_categorical_accuracy: 0.1174\n",
      "Epoch 3/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.2978 - categorical_accuracy: 0.1220 - val_loss: 2.2939 - val_categorical_accuracy: 0.1279\n",
      "Epoch 4/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.2893 - categorical_accuracy: 0.1317 - val_loss: 2.2861 - val_categorical_accuracy: 0.1370\n",
      "Epoch 5/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.2819 - categorical_accuracy: 0.1404 - val_loss: 2.2788 - val_categorical_accuracy: 0.1470\n",
      "Epoch 6/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.2749 - categorical_accuracy: 0.1472 - val_loss: 2.2721 - val_categorical_accuracy: 0.1545\n",
      "Epoch 7/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.2683 - categorical_accuracy: 0.1543 - val_loss: 2.2656 - val_categorical_accuracy: 0.1624\n",
      "Epoch 8/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.2621 - categorical_accuracy: 0.1628 - val_loss: 2.2595 - val_categorical_accuracy: 0.1674\n",
      "Epoch 9/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.2561 - categorical_accuracy: 0.1687 - val_loss: 2.2537 - val_categorical_accuracy: 0.1735\n",
      "Epoch 10/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.2505 - categorical_accuracy: 0.1739 - val_loss: 2.2481 - val_categorical_accuracy: 0.1775\n",
      "Epoch 11/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.2451 - categorical_accuracy: 0.1792 - val_loss: 2.2429 - val_categorical_accuracy: 0.1833\n",
      "Epoch 12/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.2400 - categorical_accuracy: 0.1828 - val_loss: 2.2380 - val_categorical_accuracy: 0.1870\n",
      "Epoch 13/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.2351 - categorical_accuracy: 0.1876 - val_loss: 2.2332 - val_categorical_accuracy: 0.1910\n",
      "Epoch 14/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.2305 - categorical_accuracy: 0.1914 - val_loss: 2.2287 - val_categorical_accuracy: 0.1954\n",
      "Epoch 15/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.2261 - categorical_accuracy: 0.1945 - val_loss: 2.2244 - val_categorical_accuracy: 0.1968\n",
      "Epoch 16/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.2219 - categorical_accuracy: 0.1963 - val_loss: 2.2203 - val_categorical_accuracy: 0.2005\n",
      "Epoch 17/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.2179 - categorical_accuracy: 0.1994 - val_loss: 2.2163 - val_categorical_accuracy: 0.2028\n",
      "Epoch 18/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.2140 - categorical_accuracy: 0.2018 - val_loss: 2.2127 - val_categorical_accuracy: 0.2055\n",
      "Epoch 19/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.2104 - categorical_accuracy: 0.2046 - val_loss: 2.2091 - val_categorical_accuracy: 0.2060\n",
      "Epoch 20/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.2069 - categorical_accuracy: 0.2056 - val_loss: 2.2056 - val_categorical_accuracy: 0.2096\n",
      "Epoch 21/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.2036 - categorical_accuracy: 0.2088 - val_loss: 2.2024 - val_categorical_accuracy: 0.2118\n",
      "Epoch 22/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.2004 - categorical_accuracy: 0.2097 - val_loss: 2.1993 - val_categorical_accuracy: 0.2135\n",
      "Epoch 23/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1973 - categorical_accuracy: 0.2129 - val_loss: 2.1964 - val_categorical_accuracy: 0.2141\n",
      "Epoch 24/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1944 - categorical_accuracy: 0.2140 - val_loss: 2.1934 - val_categorical_accuracy: 0.2164\n",
      "Epoch 25/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1915 - categorical_accuracy: 0.2149 - val_loss: 2.1907 - val_categorical_accuracy: 0.2182\n",
      "Epoch 26/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.1889 - categorical_accuracy: 0.2162 - val_loss: 2.1881 - val_categorical_accuracy: 0.2205\n",
      "Epoch 27/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1863 - categorical_accuracy: 0.2183 - val_loss: 2.1856 - val_categorical_accuracy: 0.2206\n",
      "Epoch 28/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1838 - categorical_accuracy: 0.2205 - val_loss: 2.1830 - val_categorical_accuracy: 0.2221\n",
      "Epoch 29/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1813 - categorical_accuracy: 0.2199 - val_loss: 2.1808 - val_categorical_accuracy: 0.2245\n",
      "Epoch 30/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.1790 - categorical_accuracy: 0.2219 - val_loss: 2.1785 - val_categorical_accuracy: 0.2251\n",
      "Epoch 31/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1768 - categorical_accuracy: 0.2234 - val_loss: 2.1763 - val_categorical_accuracy: 0.2249\n",
      "Epoch 32/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1746 - categorical_accuracy: 0.2242 - val_loss: 2.1742 - val_categorical_accuracy: 0.2271\n",
      "Epoch 33/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.1726 - categorical_accuracy: 0.2255 - val_loss: 2.1721 - val_categorical_accuracy: 0.2272\n",
      "Epoch 34/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1705 - categorical_accuracy: 0.2254 - val_loss: 2.1702 - val_categorical_accuracy: 0.2283\n",
      "Epoch 35/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1686 - categorical_accuracy: 0.2262 - val_loss: 2.1684 - val_categorical_accuracy: 0.2277\n",
      "Epoch 36/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.1667 - categorical_accuracy: 0.2275 - val_loss: 2.1666 - val_categorical_accuracy: 0.2284\n",
      "Epoch 37/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.1649 - categorical_accuracy: 0.2283 - val_loss: 2.1649 - val_categorical_accuracy: 0.2296\n",
      "Epoch 38/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.1631 - categorical_accuracy: 0.2289 - val_loss: 2.1632 - val_categorical_accuracy: 0.2307\n",
      "Epoch 39/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.1615 - categorical_accuracy: 0.2298 - val_loss: 2.1614 - val_categorical_accuracy: 0.2305\n",
      "Epoch 40/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1598 - categorical_accuracy: 0.2303 - val_loss: 2.1598 - val_categorical_accuracy: 0.2314\n",
      "Epoch 41/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1583 - categorical_accuracy: 0.2309 - val_loss: 2.1583 - val_categorical_accuracy: 0.2306\n",
      "Epoch 42/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1566 - categorical_accuracy: 0.2314 - val_loss: 2.1568 - val_categorical_accuracy: 0.2321\n",
      "Epoch 43/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1552 - categorical_accuracy: 0.2330 - val_loss: 2.1554 - val_categorical_accuracy: 0.2330\n",
      "Epoch 44/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.1537 - categorical_accuracy: 0.2333 - val_loss: 2.1539 - val_categorical_accuracy: 0.2346\n",
      "Epoch 45/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.1523 - categorical_accuracy: 0.2341 - val_loss: 2.1526 - val_categorical_accuracy: 0.2346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.1509 - categorical_accuracy: 0.2353 - val_loss: 2.1512 - val_categorical_accuracy: 0.2361\n",
      "Epoch 47/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.1495 - categorical_accuracy: 0.2343 - val_loss: 2.1500 - val_categorical_accuracy: 0.2370\n",
      "Epoch 48/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.1482 - categorical_accuracy: 0.2362 - val_loss: 2.1487 - val_categorical_accuracy: 0.2369\n",
      "Epoch 49/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.1470 - categorical_accuracy: 0.2352 - val_loss: 2.1475 - val_categorical_accuracy: 0.2366\n",
      "Epoch 50/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.1457 - categorical_accuracy: 0.2369 - val_loss: 2.1462 - val_categorical_accuracy: 0.2385\n",
      "Epoch 51/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1445 - categorical_accuracy: 0.2356 - val_loss: 2.1451 - val_categorical_accuracy: 0.2383\n",
      "Epoch 52/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1433 - categorical_accuracy: 0.2367 - val_loss: 2.1440 - val_categorical_accuracy: 0.2396\n",
      "Epoch 53/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.1422 - categorical_accuracy: 0.2378 - val_loss: 2.1428 - val_categorical_accuracy: 0.2405\n",
      "Epoch 54/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.1410 - categorical_accuracy: 0.2379 - val_loss: 2.1417 - val_categorical_accuracy: 0.2396\n",
      "Epoch 55/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1399 - categorical_accuracy: 0.2387 - val_loss: 2.1406 - val_categorical_accuracy: 0.2413\n",
      "Epoch 56/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1389 - categorical_accuracy: 0.2396 - val_loss: 2.1396 - val_categorical_accuracy: 0.2408\n",
      "Epoch 57/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1378 - categorical_accuracy: 0.2391 - val_loss: 2.1386 - val_categorical_accuracy: 0.2429\n",
      "Epoch 58/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1368 - categorical_accuracy: 0.2400 - val_loss: 2.1377 - val_categorical_accuracy: 0.2425\n",
      "Epoch 59/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.1358 - categorical_accuracy: 0.2399 - val_loss: 2.1367 - val_categorical_accuracy: 0.2444\n",
      "Epoch 60/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.1348 - categorical_accuracy: 0.2408 - val_loss: 2.1357 - val_categorical_accuracy: 0.2450\n",
      "Epoch 61/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1339 - categorical_accuracy: 0.2417 - val_loss: 2.1348 - val_categorical_accuracy: 0.2437\n",
      "Epoch 62/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1329 - categorical_accuracy: 0.2411 - val_loss: 2.1339 - val_categorical_accuracy: 0.2445\n",
      "Epoch 63/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1320 - categorical_accuracy: 0.2420 - val_loss: 2.1330 - val_categorical_accuracy: 0.2446\n",
      "Epoch 64/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1311 - categorical_accuracy: 0.2418 - val_loss: 2.1322 - val_categorical_accuracy: 0.2454\n",
      "Epoch 65/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1302 - categorical_accuracy: 0.2430 - val_loss: 2.1313 - val_categorical_accuracy: 0.2462\n",
      "Epoch 66/400\n",
      "40000/40000 [==============================] - 0s 8us/step - loss: 2.1294 - categorical_accuracy: 0.2431 - val_loss: 2.1304 - val_categorical_accuracy: 0.2461\n",
      "Epoch 67/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.1285 - categorical_accuracy: 0.2427 - val_loss: 2.1296 - val_categorical_accuracy: 0.2464\n",
      "Epoch 68/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1277 - categorical_accuracy: 0.2440 - val_loss: 2.1288 - val_categorical_accuracy: 0.2468\n",
      "Epoch 69/400\n",
      "40000/40000 [==============================] - 0s 9us/step - loss: 2.1268 - categorical_accuracy: 0.2437 - val_loss: 2.1281 - val_categorical_accuracy: 0.2465\n",
      "Epoch 70/400\n",
      "40000/40000 [==============================] - 0s 8us/step - loss: 2.1261 - categorical_accuracy: 0.2440 - val_loss: 2.1273 - val_categorical_accuracy: 0.2475\n",
      "Epoch 71/400\n",
      "40000/40000 [==============================] - 0s 8us/step - loss: 2.1253 - categorical_accuracy: 0.2438 - val_loss: 2.1265 - val_categorical_accuracy: 0.2474\n",
      "Epoch 72/400\n",
      "40000/40000 [==============================] - 0s 8us/step - loss: 2.1245 - categorical_accuracy: 0.2449 - val_loss: 2.1257 - val_categorical_accuracy: 0.2482\n",
      "Epoch 73/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1238 - categorical_accuracy: 0.2442 - val_loss: 2.1251 - val_categorical_accuracy: 0.2473\n",
      "Epoch 74/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1230 - categorical_accuracy: 0.2461 - val_loss: 2.1243 - val_categorical_accuracy: 0.2474\n",
      "Epoch 75/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1223 - categorical_accuracy: 0.2458 - val_loss: 2.1236 - val_categorical_accuracy: 0.2474\n",
      "Epoch 76/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1216 - categorical_accuracy: 0.2460 - val_loss: 2.1229 - val_categorical_accuracy: 0.2474\n",
      "Epoch 77/400\n",
      "40000/40000 [==============================] - 0s 8us/step - loss: 2.1208 - categorical_accuracy: 0.2459 - val_loss: 2.1222 - val_categorical_accuracy: 0.2468\n",
      "Epoch 78/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.1202 - categorical_accuracy: 0.2472 - val_loss: 2.1215 - val_categorical_accuracy: 0.2484\n",
      "Epoch 79/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1195 - categorical_accuracy: 0.2465 - val_loss: 2.1209 - val_categorical_accuracy: 0.2490\n",
      "Epoch 80/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.1188 - categorical_accuracy: 0.2473 - val_loss: 2.1203 - val_categorical_accuracy: 0.2495\n",
      "Epoch 81/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.1181 - categorical_accuracy: 0.2481 - val_loss: 2.1196 - val_categorical_accuracy: 0.2501\n",
      "Epoch 82/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1175 - categorical_accuracy: 0.2477 - val_loss: 2.1191 - val_categorical_accuracy: 0.2499\n",
      "Epoch 83/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1169 - categorical_accuracy: 0.2486 - val_loss: 2.1184 - val_categorical_accuracy: 0.2485\n",
      "Epoch 84/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1162 - categorical_accuracy: 0.2492 - val_loss: 2.1177 - val_categorical_accuracy: 0.2496\n",
      "Epoch 85/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.1156 - categorical_accuracy: 0.2489 - val_loss: 2.1172 - val_categorical_accuracy: 0.2504\n",
      "Epoch 86/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.1150 - categorical_accuracy: 0.2484 - val_loss: 2.1166 - val_categorical_accuracy: 0.2502\n",
      "Epoch 87/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1144 - categorical_accuracy: 0.2502 - val_loss: 2.1160 - val_categorical_accuracy: 0.2506\n",
      "Epoch 88/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.1137 - categorical_accuracy: 0.2495 - val_loss: 2.1154 - val_categorical_accuracy: 0.2504\n",
      "Epoch 89/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.1132 - categorical_accuracy: 0.2508 - val_loss: 2.1148 - val_categorical_accuracy: 0.2497\n",
      "Epoch 90/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1126 - categorical_accuracy: 0.2505 - val_loss: 2.1144 - val_categorical_accuracy: 0.2514\n",
      "Epoch 91/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.1121 - categorical_accuracy: 0.2510 - val_loss: 2.1138 - val_categorical_accuracy: 0.2515\n",
      "Epoch 92/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1115 - categorical_accuracy: 0.2514 - val_loss: 2.1133 - val_categorical_accuracy: 0.2522\n",
      "Epoch 93/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.1109 - categorical_accuracy: 0.2516 - val_loss: 2.1127 - val_categorical_accuracy: 0.2515\n",
      "Epoch 94/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.1104 - categorical_accuracy: 0.2512 - val_loss: 2.1123 - val_categorical_accuracy: 0.2520\n",
      "Epoch 95/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1098 - categorical_accuracy: 0.2521 - val_loss: 2.1117 - val_categorical_accuracy: 0.2515\n",
      "Epoch 96/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1093 - categorical_accuracy: 0.2517 - val_loss: 2.1113 - val_categorical_accuracy: 0.2533\n",
      "Epoch 97/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1087 - categorical_accuracy: 0.2527 - val_loss: 2.1107 - val_categorical_accuracy: 0.2534\n",
      "Epoch 98/400\n",
      "40000/40000 [==============================] - 0s 8us/step - loss: 2.1082 - categorical_accuracy: 0.2527 - val_loss: 2.1102 - val_categorical_accuracy: 0.2530\n",
      "Epoch 99/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.1077 - categorical_accuracy: 0.2527 - val_loss: 2.1098 - val_categorical_accuracy: 0.2535\n",
      "Epoch 100/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.1072 - categorical_accuracy: 0.2533 - val_loss: 2.1092 - val_categorical_accuracy: 0.2534\n",
      "Epoch 101/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.1067 - categorical_accuracy: 0.2541 - val_loss: 2.1087 - val_categorical_accuracy: 0.2535\n",
      "Epoch 102/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1062 - categorical_accuracy: 0.2535 - val_loss: 2.1083 - val_categorical_accuracy: 0.2542\n",
      "Epoch 103/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1057 - categorical_accuracy: 0.2540 - val_loss: 2.1079 - val_categorical_accuracy: 0.2545\n",
      "Epoch 104/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1052 - categorical_accuracy: 0.2546 - val_loss: 2.1074 - val_categorical_accuracy: 0.2549\n",
      "Epoch 105/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1048 - categorical_accuracy: 0.2552 - val_loss: 2.1069 - val_categorical_accuracy: 0.2544\n",
      "Epoch 106/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1043 - categorical_accuracy: 0.2544 - val_loss: 2.1065 - val_categorical_accuracy: 0.2547\n",
      "Epoch 107/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.1038 - categorical_accuracy: 0.2555 - val_loss: 2.1060 - val_categorical_accuracy: 0.2545\n",
      "Epoch 108/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1033 - categorical_accuracy: 0.2547 - val_loss: 2.1056 - val_categorical_accuracy: 0.2548\n",
      "Epoch 109/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1029 - categorical_accuracy: 0.2555 - val_loss: 2.1052 - val_categorical_accuracy: 0.2556\n",
      "Epoch 110/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1024 - categorical_accuracy: 0.2561 - val_loss: 2.1047 - val_categorical_accuracy: 0.2551\n",
      "Epoch 111/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1020 - categorical_accuracy: 0.2558 - val_loss: 2.1042 - val_categorical_accuracy: 0.2554\n",
      "Epoch 112/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1016 - categorical_accuracy: 0.2561 - val_loss: 2.1038 - val_categorical_accuracy: 0.2555\n",
      "Epoch 113/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1011 - categorical_accuracy: 0.2570 - val_loss: 2.1034 - val_categorical_accuracy: 0.2555\n",
      "Epoch 114/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1007 - categorical_accuracy: 0.2565 - val_loss: 2.1030 - val_categorical_accuracy: 0.2564\n",
      "Epoch 115/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.1002 - categorical_accuracy: 0.2571 - val_loss: 2.1027 - val_categorical_accuracy: 0.2565\n",
      "Epoch 116/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0998 - categorical_accuracy: 0.2572 - val_loss: 2.1022 - val_categorical_accuracy: 0.2565\n",
      "Epoch 117/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0994 - categorical_accuracy: 0.2583 - val_loss: 2.1018 - val_categorical_accuracy: 0.2569\n",
      "Epoch 118/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0990 - categorical_accuracy: 0.2577 - val_loss: 2.1015 - val_categorical_accuracy: 0.2572\n",
      "Epoch 119/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0986 - categorical_accuracy: 0.2583 - val_loss: 2.1010 - val_categorical_accuracy: 0.2570\n",
      "Epoch 120/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0982 - categorical_accuracy: 0.2581 - val_loss: 2.1007 - val_categorical_accuracy: 0.2580\n",
      "Epoch 121/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0978 - categorical_accuracy: 0.2584 - val_loss: 2.1003 - val_categorical_accuracy: 0.2573\n",
      "Epoch 122/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0974 - categorical_accuracy: 0.2581 - val_loss: 2.1000 - val_categorical_accuracy: 0.2582\n",
      "Epoch 123/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0970 - categorical_accuracy: 0.2595 - val_loss: 2.0995 - val_categorical_accuracy: 0.2576\n",
      "Epoch 124/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0966 - categorical_accuracy: 0.2593 - val_loss: 2.0992 - val_categorical_accuracy: 0.2578\n",
      "Epoch 125/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0962 - categorical_accuracy: 0.2601 - val_loss: 2.0987 - val_categorical_accuracy: 0.2569\n",
      "Epoch 126/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0958 - categorical_accuracy: 0.2597 - val_loss: 2.0984 - val_categorical_accuracy: 0.2585\n",
      "Epoch 127/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0955 - categorical_accuracy: 0.2600 - val_loss: 2.0981 - val_categorical_accuracy: 0.2590\n",
      "Epoch 128/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0951 - categorical_accuracy: 0.2603 - val_loss: 2.0977 - val_categorical_accuracy: 0.2585\n",
      "Epoch 129/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0947 - categorical_accuracy: 0.2603 - val_loss: 2.0974 - val_categorical_accuracy: 0.2588\n",
      "Epoch 130/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0943 - categorical_accuracy: 0.2609 - val_loss: 2.0970 - val_categorical_accuracy: 0.2572\n",
      "Epoch 131/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0940 - categorical_accuracy: 0.2609 - val_loss: 2.0967 - val_categorical_accuracy: 0.2578\n",
      "Epoch 132/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0936 - categorical_accuracy: 0.2615 - val_loss: 2.0963 - val_categorical_accuracy: 0.2580\n",
      "Epoch 133/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0933 - categorical_accuracy: 0.2611 - val_loss: 2.0959 - val_categorical_accuracy: 0.2582\n",
      "Epoch 134/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0929 - categorical_accuracy: 0.2617 - val_loss: 2.0956 - val_categorical_accuracy: 0.2581\n",
      "Epoch 135/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0925 - categorical_accuracy: 0.2619 - val_loss: 2.0953 - val_categorical_accuracy: 0.2577\n",
      "Epoch 136/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0922 - categorical_accuracy: 0.2623 - val_loss: 2.0949 - val_categorical_accuracy: 0.2575\n",
      "Epoch 137/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0918 - categorical_accuracy: 0.2617 - val_loss: 2.0946 - val_categorical_accuracy: 0.2579\n",
      "Epoch 138/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0915 - categorical_accuracy: 0.2628 - val_loss: 2.0944 - val_categorical_accuracy: 0.2584\n",
      "Epoch 139/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0911 - categorical_accuracy: 0.2626 - val_loss: 2.0940 - val_categorical_accuracy: 0.2585\n",
      "Epoch 140/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0908 - categorical_accuracy: 0.2623 - val_loss: 2.0937 - val_categorical_accuracy: 0.2588\n",
      "Epoch 141/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0905 - categorical_accuracy: 0.2629 - val_loss: 2.0934 - val_categorical_accuracy: 0.2592\n",
      "Epoch 142/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0901 - categorical_accuracy: 0.2634 - val_loss: 2.0931 - val_categorical_accuracy: 0.2590\n",
      "Epoch 143/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0898 - categorical_accuracy: 0.2631 - val_loss: 2.0928 - val_categorical_accuracy: 0.2589\n",
      "Epoch 144/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0895 - categorical_accuracy: 0.2629 - val_loss: 2.0925 - val_categorical_accuracy: 0.2602\n",
      "Epoch 145/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0892 - categorical_accuracy: 0.2637 - val_loss: 2.0922 - val_categorical_accuracy: 0.2593\n",
      "Epoch 146/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0889 - categorical_accuracy: 0.2630 - val_loss: 2.0919 - val_categorical_accuracy: 0.2607\n",
      "Epoch 147/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0886 - categorical_accuracy: 0.2634 - val_loss: 2.0917 - val_categorical_accuracy: 0.2613\n",
      "Epoch 148/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0882 - categorical_accuracy: 0.2636 - val_loss: 2.0913 - val_categorical_accuracy: 0.2607\n",
      "Epoch 149/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0879 - categorical_accuracy: 0.2647 - val_loss: 2.0910 - val_categorical_accuracy: 0.2594\n",
      "Epoch 150/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0876 - categorical_accuracy: 0.2637 - val_loss: 2.0907 - val_categorical_accuracy: 0.2608\n",
      "Epoch 151/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0873 - categorical_accuracy: 0.2641 - val_loss: 2.0904 - val_categorical_accuracy: 0.2594\n",
      "Epoch 152/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0870 - categorical_accuracy: 0.2643 - val_loss: 2.0901 - val_categorical_accuracy: 0.2600\n",
      "Epoch 153/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0867 - categorical_accuracy: 0.2645 - val_loss: 2.0898 - val_categorical_accuracy: 0.2608\n",
      "Epoch 154/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0864 - categorical_accuracy: 0.2648 - val_loss: 2.0896 - val_categorical_accuracy: 0.2614\n",
      "Epoch 155/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0861 - categorical_accuracy: 0.2647 - val_loss: 2.0893 - val_categorical_accuracy: 0.2607\n",
      "Epoch 156/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0858 - categorical_accuracy: 0.2654 - val_loss: 2.0890 - val_categorical_accuracy: 0.2603\n",
      "Epoch 157/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0855 - categorical_accuracy: 0.2650 - val_loss: 2.0888 - val_categorical_accuracy: 0.2608\n",
      "Epoch 158/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0852 - categorical_accuracy: 0.2651 - val_loss: 2.0885 - val_categorical_accuracy: 0.2608\n",
      "Epoch 159/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0849 - categorical_accuracy: 0.2651 - val_loss: 2.0882 - val_categorical_accuracy: 0.2619\n",
      "Epoch 160/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0847 - categorical_accuracy: 0.2659 - val_loss: 2.0879 - val_categorical_accuracy: 0.2618\n",
      "Epoch 161/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0844 - categorical_accuracy: 0.2656 - val_loss: 2.0877 - val_categorical_accuracy: 0.2620\n",
      "Epoch 162/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0841 - categorical_accuracy: 0.2651 - val_loss: 2.0874 - val_categorical_accuracy: 0.2618\n",
      "Epoch 163/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0838 - categorical_accuracy: 0.2655 - val_loss: 2.0872 - val_categorical_accuracy: 0.2634\n",
      "Epoch 164/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0835 - categorical_accuracy: 0.2661 - val_loss: 2.0869 - val_categorical_accuracy: 0.2621\n",
      "Epoch 165/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0833 - categorical_accuracy: 0.2662 - val_loss: 2.0866 - val_categorical_accuracy: 0.2619\n",
      "Epoch 166/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0830 - categorical_accuracy: 0.2670 - val_loss: 2.0863 - val_categorical_accuracy: 0.2617\n",
      "Epoch 167/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0827 - categorical_accuracy: 0.2659 - val_loss: 2.0861 - val_categorical_accuracy: 0.2627\n",
      "Epoch 168/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0824 - categorical_accuracy: 0.2660 - val_loss: 2.0859 - val_categorical_accuracy: 0.2640\n",
      "Epoch 169/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0822 - categorical_accuracy: 0.2669 - val_loss: 2.0856 - val_categorical_accuracy: 0.2630\n",
      "Epoch 170/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0819 - categorical_accuracy: 0.2662 - val_loss: 2.0855 - val_categorical_accuracy: 0.2633\n",
      "Epoch 171/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0817 - categorical_accuracy: 0.2673 - val_loss: 2.0851 - val_categorical_accuracy: 0.2632\n",
      "Epoch 172/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0814 - categorical_accuracy: 0.2668 - val_loss: 2.0849 - val_categorical_accuracy: 0.2641\n",
      "Epoch 173/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0811 - categorical_accuracy: 0.2676 - val_loss: 2.0847 - val_categorical_accuracy: 0.2635\n",
      "Epoch 174/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0809 - categorical_accuracy: 0.2676 - val_loss: 2.0845 - val_categorical_accuracy: 0.2641\n",
      "Epoch 175/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0806 - categorical_accuracy: 0.2682 - val_loss: 2.0842 - val_categorical_accuracy: 0.2640\n",
      "Epoch 176/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0803 - categorical_accuracy: 0.2686 - val_loss: 2.0839 - val_categorical_accuracy: 0.2648\n",
      "Epoch 177/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0801 - categorical_accuracy: 0.2677 - val_loss: 2.0838 - val_categorical_accuracy: 0.2647\n",
      "Epoch 178/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0799 - categorical_accuracy: 0.2692 - val_loss: 2.0834 - val_categorical_accuracy: 0.2643\n",
      "Epoch 179/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0796 - categorical_accuracy: 0.2679 - val_loss: 2.0833 - val_categorical_accuracy: 0.2648\n",
      "Epoch 180/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0794 - categorical_accuracy: 0.2684 - val_loss: 2.0831 - val_categorical_accuracy: 0.2652\n",
      "Epoch 181/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0791 - categorical_accuracy: 0.2695 - val_loss: 2.0828 - val_categorical_accuracy: 0.2652\n",
      "Epoch 182/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0789 - categorical_accuracy: 0.2694 - val_loss: 2.0825 - val_categorical_accuracy: 0.2656\n",
      "Epoch 183/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0786 - categorical_accuracy: 0.2691 - val_loss: 2.0823 - val_categorical_accuracy: 0.2649\n",
      "Epoch 184/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0784 - categorical_accuracy: 0.2688 - val_loss: 2.0822 - val_categorical_accuracy: 0.2663\n",
      "Epoch 185/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0781 - categorical_accuracy: 0.2701 - val_loss: 2.0819 - val_categorical_accuracy: 0.2654\n",
      "Epoch 186/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0779 - categorical_accuracy: 0.2701 - val_loss: 2.0817 - val_categorical_accuracy: 0.2661\n",
      "Epoch 187/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0777 - categorical_accuracy: 0.2705 - val_loss: 2.0815 - val_categorical_accuracy: 0.2655\n",
      "Epoch 188/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0775 - categorical_accuracy: 0.2697 - val_loss: 2.0812 - val_categorical_accuracy: 0.2664\n",
      "Epoch 189/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0772 - categorical_accuracy: 0.2693 - val_loss: 2.0810 - val_categorical_accuracy: 0.2673\n",
      "Epoch 190/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0770 - categorical_accuracy: 0.2699 - val_loss: 2.0808 - val_categorical_accuracy: 0.2657\n",
      "Epoch 191/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0768 - categorical_accuracy: 0.2702 - val_loss: 2.0807 - val_categorical_accuracy: 0.2669\n",
      "Epoch 192/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0765 - categorical_accuracy: 0.2707 - val_loss: 2.0805 - val_categorical_accuracy: 0.2667\n",
      "Epoch 193/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0764 - categorical_accuracy: 0.2707 - val_loss: 2.0803 - val_categorical_accuracy: 0.2663\n",
      "Epoch 194/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0761 - categorical_accuracy: 0.2709 - val_loss: 2.0801 - val_categorical_accuracy: 0.2668\n",
      "Epoch 195/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0759 - categorical_accuracy: 0.2714 - val_loss: 2.0798 - val_categorical_accuracy: 0.2667\n",
      "Epoch 196/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0757 - categorical_accuracy: 0.2712 - val_loss: 2.0796 - val_categorical_accuracy: 0.2674\n",
      "Epoch 197/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0754 - categorical_accuracy: 0.2713 - val_loss: 2.0794 - val_categorical_accuracy: 0.2674\n",
      "Epoch 198/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0752 - categorical_accuracy: 0.2714 - val_loss: 2.0792 - val_categorical_accuracy: 0.2668\n",
      "Epoch 199/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0750 - categorical_accuracy: 0.2717 - val_loss: 2.0790 - val_categorical_accuracy: 0.2666\n",
      "Epoch 200/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0748 - categorical_accuracy: 0.2715 - val_loss: 2.0788 - val_categorical_accuracy: 0.2669\n",
      "Epoch 201/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0746 - categorical_accuracy: 0.2721 - val_loss: 2.0786 - val_categorical_accuracy: 0.2668\n",
      "Epoch 202/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0743 - categorical_accuracy: 0.2715 - val_loss: 2.0784 - val_categorical_accuracy: 0.2667\n",
      "Epoch 203/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0741 - categorical_accuracy: 0.2723 - val_loss: 2.0783 - val_categorical_accuracy: 0.2666\n",
      "Epoch 204/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0739 - categorical_accuracy: 0.2717 - val_loss: 2.0780 - val_categorical_accuracy: 0.2665\n",
      "Epoch 205/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0737 - categorical_accuracy: 0.2725 - val_loss: 2.0779 - val_categorical_accuracy: 0.2668\n",
      "Epoch 206/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0735 - categorical_accuracy: 0.2721 - val_loss: 2.0777 - val_categorical_accuracy: 0.2677\n",
      "Epoch 207/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0733 - categorical_accuracy: 0.2722 - val_loss: 2.0775 - val_categorical_accuracy: 0.2678\n",
      "Epoch 208/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0732 - categorical_accuracy: 0.2729 - val_loss: 2.0773 - val_categorical_accuracy: 0.2673\n",
      "Epoch 209/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0729 - categorical_accuracy: 0.2725 - val_loss: 2.0771 - val_categorical_accuracy: 0.2675\n",
      "Epoch 210/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0727 - categorical_accuracy: 0.2728 - val_loss: 2.0770 - val_categorical_accuracy: 0.2685\n",
      "Epoch 211/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0725 - categorical_accuracy: 0.2732 - val_loss: 2.0767 - val_categorical_accuracy: 0.2677\n",
      "Epoch 212/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0723 - categorical_accuracy: 0.2731 - val_loss: 2.0765 - val_categorical_accuracy: 0.2675\n",
      "Epoch 213/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0721 - categorical_accuracy: 0.2735 - val_loss: 2.0763 - val_categorical_accuracy: 0.2682\n",
      "Epoch 214/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0719 - categorical_accuracy: 0.2732 - val_loss: 2.0762 - val_categorical_accuracy: 0.2680\n",
      "Epoch 215/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0718 - categorical_accuracy: 0.2727 - val_loss: 2.0761 - val_categorical_accuracy: 0.2682\n",
      "Epoch 216/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0715 - categorical_accuracy: 0.2732 - val_loss: 2.0759 - val_categorical_accuracy: 0.2682\n",
      "Epoch 217/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0713 - categorical_accuracy: 0.2737 - val_loss: 2.0757 - val_categorical_accuracy: 0.2691\n",
      "Epoch 218/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0712 - categorical_accuracy: 0.2741 - val_loss: 2.0755 - val_categorical_accuracy: 0.2684\n",
      "Epoch 219/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0710 - categorical_accuracy: 0.2737 - val_loss: 2.0754 - val_categorical_accuracy: 0.2682\n",
      "Epoch 220/400\n",
      "40000/40000 [==============================] - 0s 8us/step - loss: 2.0707 - categorical_accuracy: 0.2740 - val_loss: 2.0752 - val_categorical_accuracy: 0.2684\n",
      "Epoch 221/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0706 - categorical_accuracy: 0.2743 - val_loss: 2.0749 - val_categorical_accuracy: 0.2692\n",
      "Epoch 222/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0704 - categorical_accuracy: 0.2733 - val_loss: 2.0749 - val_categorical_accuracy: 0.2695\n",
      "Epoch 223/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0702 - categorical_accuracy: 0.2747 - val_loss: 2.0746 - val_categorical_accuracy: 0.2687\n",
      "Epoch 224/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0700 - categorical_accuracy: 0.2748 - val_loss: 2.0744 - val_categorical_accuracy: 0.2687\n",
      "Epoch 225/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0698 - categorical_accuracy: 0.2737 - val_loss: 2.0743 - val_categorical_accuracy: 0.2687\n",
      "Epoch 226/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0697 - categorical_accuracy: 0.2754 - val_loss: 2.0741 - val_categorical_accuracy: 0.2688\n",
      "Epoch 227/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0695 - categorical_accuracy: 0.2741 - val_loss: 2.0740 - val_categorical_accuracy: 0.2699\n",
      "Epoch 228/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0693 - categorical_accuracy: 0.2746 - val_loss: 2.0739 - val_categorical_accuracy: 0.2696\n",
      "Epoch 229/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0691 - categorical_accuracy: 0.2752 - val_loss: 2.0738 - val_categorical_accuracy: 0.2703\n",
      "Epoch 230/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0689 - categorical_accuracy: 0.2750 - val_loss: 2.0735 - val_categorical_accuracy: 0.2704\n",
      "Epoch 231/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0688 - categorical_accuracy: 0.2755 - val_loss: 2.0733 - val_categorical_accuracy: 0.2700\n",
      "Epoch 232/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0686 - categorical_accuracy: 0.2761 - val_loss: 2.0731 - val_categorical_accuracy: 0.2698\n",
      "Epoch 233/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0684 - categorical_accuracy: 0.2753 - val_loss: 2.0730 - val_categorical_accuracy: 0.2703\n",
      "Epoch 234/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 0s 8us/step - loss: 2.0682 - categorical_accuracy: 0.2758 - val_loss: 2.0728 - val_categorical_accuracy: 0.2705\n",
      "Epoch 235/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0681 - categorical_accuracy: 0.2756 - val_loss: 2.0727 - val_categorical_accuracy: 0.2698\n",
      "Epoch 236/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0679 - categorical_accuracy: 0.2764 - val_loss: 2.0725 - val_categorical_accuracy: 0.2713\n",
      "Epoch 237/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0677 - categorical_accuracy: 0.2769 - val_loss: 2.0724 - val_categorical_accuracy: 0.2700\n",
      "Epoch 238/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0676 - categorical_accuracy: 0.2759 - val_loss: 2.0722 - val_categorical_accuracy: 0.2702\n",
      "Epoch 239/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0674 - categorical_accuracy: 0.2760 - val_loss: 2.0721 - val_categorical_accuracy: 0.2703\n",
      "Epoch 240/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0672 - categorical_accuracy: 0.2756 - val_loss: 2.0719 - val_categorical_accuracy: 0.2711\n",
      "Epoch 241/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0670 - categorical_accuracy: 0.2756 - val_loss: 2.0718 - val_categorical_accuracy: 0.2712\n",
      "Epoch 242/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0669 - categorical_accuracy: 0.2759 - val_loss: 2.0717 - val_categorical_accuracy: 0.2718\n",
      "Epoch 243/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0667 - categorical_accuracy: 0.2765 - val_loss: 2.0716 - val_categorical_accuracy: 0.2721\n",
      "Epoch 244/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0665 - categorical_accuracy: 0.2771 - val_loss: 2.0714 - val_categorical_accuracy: 0.2714\n",
      "Epoch 245/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0664 - categorical_accuracy: 0.2775 - val_loss: 2.0711 - val_categorical_accuracy: 0.2711\n",
      "Epoch 246/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0662 - categorical_accuracy: 0.2775 - val_loss: 2.0709 - val_categorical_accuracy: 0.2716\n",
      "Epoch 247/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0661 - categorical_accuracy: 0.2762 - val_loss: 2.0708 - val_categorical_accuracy: 0.2718\n",
      "Epoch 248/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0659 - categorical_accuracy: 0.2769 - val_loss: 2.0707 - val_categorical_accuracy: 0.2720\n",
      "Epoch 249/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0658 - categorical_accuracy: 0.2771 - val_loss: 2.0707 - val_categorical_accuracy: 0.2712\n",
      "Epoch 250/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0656 - categorical_accuracy: 0.2770 - val_loss: 2.0705 - val_categorical_accuracy: 0.2723\n",
      "Epoch 251/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0654 - categorical_accuracy: 0.2778 - val_loss: 2.0703 - val_categorical_accuracy: 0.2728\n",
      "Epoch 252/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0653 - categorical_accuracy: 0.2774 - val_loss: 2.0701 - val_categorical_accuracy: 0.2720\n",
      "Epoch 253/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0651 - categorical_accuracy: 0.2768 - val_loss: 2.0700 - val_categorical_accuracy: 0.2723\n",
      "Epoch 254/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0650 - categorical_accuracy: 0.2768 - val_loss: 2.0699 - val_categorical_accuracy: 0.2732\n",
      "Epoch 255/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0648 - categorical_accuracy: 0.2779 - val_loss: 2.0698 - val_categorical_accuracy: 0.2728\n",
      "Epoch 256/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0647 - categorical_accuracy: 0.2781 - val_loss: 2.0697 - val_categorical_accuracy: 0.2724\n",
      "Epoch 257/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0645 - categorical_accuracy: 0.2783 - val_loss: 2.0695 - val_categorical_accuracy: 0.2722\n",
      "Epoch 258/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0643 - categorical_accuracy: 0.2776 - val_loss: 2.0694 - val_categorical_accuracy: 0.2718\n",
      "Epoch 259/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0642 - categorical_accuracy: 0.2785 - val_loss: 2.0692 - val_categorical_accuracy: 0.2720\n",
      "Epoch 260/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0641 - categorical_accuracy: 0.2782 - val_loss: 2.0691 - val_categorical_accuracy: 0.2728\n",
      "Epoch 261/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0639 - categorical_accuracy: 0.2786 - val_loss: 2.0689 - val_categorical_accuracy: 0.2721\n",
      "Epoch 262/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0638 - categorical_accuracy: 0.2784 - val_loss: 2.0688 - val_categorical_accuracy: 0.2722\n",
      "Epoch 263/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0636 - categorical_accuracy: 0.2780 - val_loss: 2.0687 - val_categorical_accuracy: 0.2728\n",
      "Epoch 264/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0634 - categorical_accuracy: 0.2789 - val_loss: 2.0686 - val_categorical_accuracy: 0.2724\n",
      "Epoch 265/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0633 - categorical_accuracy: 0.2778 - val_loss: 2.0685 - val_categorical_accuracy: 0.2727\n",
      "Epoch 266/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0631 - categorical_accuracy: 0.2789 - val_loss: 2.0683 - val_categorical_accuracy: 0.2719\n",
      "Epoch 267/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0630 - categorical_accuracy: 0.2785 - val_loss: 2.0681 - val_categorical_accuracy: 0.2721\n",
      "Epoch 268/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0629 - categorical_accuracy: 0.2780 - val_loss: 2.0680 - val_categorical_accuracy: 0.2731\n",
      "Epoch 269/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0627 - categorical_accuracy: 0.2786 - val_loss: 2.0680 - val_categorical_accuracy: 0.2728\n",
      "Epoch 270/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0625 - categorical_accuracy: 0.2789 - val_loss: 2.0678 - val_categorical_accuracy: 0.2731\n",
      "Epoch 271/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0624 - categorical_accuracy: 0.2793 - val_loss: 2.0676 - val_categorical_accuracy: 0.2735\n",
      "Epoch 272/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0623 - categorical_accuracy: 0.2785 - val_loss: 2.0676 - val_categorical_accuracy: 0.2741\n",
      "Epoch 273/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0622 - categorical_accuracy: 0.2788 - val_loss: 2.0674 - val_categorical_accuracy: 0.2745\n",
      "Epoch 274/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0620 - categorical_accuracy: 0.2790 - val_loss: 2.0673 - val_categorical_accuracy: 0.2734\n",
      "Epoch 275/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0618 - categorical_accuracy: 0.2798 - val_loss: 2.0671 - val_categorical_accuracy: 0.2730\n",
      "Epoch 276/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0617 - categorical_accuracy: 0.2798 - val_loss: 2.0670 - val_categorical_accuracy: 0.2735\n",
      "Epoch 277/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0616 - categorical_accuracy: 0.2789 - val_loss: 2.0669 - val_categorical_accuracy: 0.2738\n",
      "Epoch 278/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0614 - categorical_accuracy: 0.2792 - val_loss: 2.0668 - val_categorical_accuracy: 0.2733\n",
      "Epoch 279/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0613 - categorical_accuracy: 0.2796 - val_loss: 2.0667 - val_categorical_accuracy: 0.2733\n",
      "Epoch 280/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0612 - categorical_accuracy: 0.2787 - val_loss: 2.0665 - val_categorical_accuracy: 0.2740\n",
      "Epoch 281/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0610 - categorical_accuracy: 0.2794 - val_loss: 2.0663 - val_categorical_accuracy: 0.2748\n",
      "Epoch 282/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0609 - categorical_accuracy: 0.2796 - val_loss: 2.0663 - val_categorical_accuracy: 0.2737\n",
      "Epoch 283/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0608 - categorical_accuracy: 0.2790 - val_loss: 2.0662 - val_categorical_accuracy: 0.2744\n",
      "Epoch 284/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0606 - categorical_accuracy: 0.2795 - val_loss: 2.0661 - val_categorical_accuracy: 0.2748\n",
      "Epoch 285/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0605 - categorical_accuracy: 0.2808 - val_loss: 2.0659 - val_categorical_accuracy: 0.2738\n",
      "Epoch 286/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0604 - categorical_accuracy: 0.2790 - val_loss: 2.0659 - val_categorical_accuracy: 0.2747\n",
      "Epoch 287/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0602 - categorical_accuracy: 0.2805 - val_loss: 2.0657 - val_categorical_accuracy: 0.2741\n",
      "Epoch 288/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0601 - categorical_accuracy: 0.2800 - val_loss: 2.0656 - val_categorical_accuracy: 0.2746\n",
      "Epoch 289/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0600 - categorical_accuracy: 0.2798 - val_loss: 2.0655 - val_categorical_accuracy: 0.2745\n",
      "Epoch 290/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0599 - categorical_accuracy: 0.2809 - val_loss: 2.0653 - val_categorical_accuracy: 0.2748\n",
      "Epoch 291/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0597 - categorical_accuracy: 0.2802 - val_loss: 2.0652 - val_categorical_accuracy: 0.2749\n",
      "Epoch 292/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0596 - categorical_accuracy: 0.2805 - val_loss: 2.0651 - val_categorical_accuracy: 0.2752\n",
      "Epoch 293/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0595 - categorical_accuracy: 0.2801 - val_loss: 2.0649 - val_categorical_accuracy: 0.2752\n",
      "Epoch 294/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0593 - categorical_accuracy: 0.2800 - val_loss: 2.0649 - val_categorical_accuracy: 0.2747\n",
      "Epoch 295/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0592 - categorical_accuracy: 0.2808 - val_loss: 2.0648 - val_categorical_accuracy: 0.2753\n",
      "Epoch 296/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0591 - categorical_accuracy: 0.2805 - val_loss: 2.0647 - val_categorical_accuracy: 0.2758\n",
      "Epoch 297/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0590 - categorical_accuracy: 0.2800 - val_loss: 2.0646 - val_categorical_accuracy: 0.2757\n",
      "Epoch 298/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0589 - categorical_accuracy: 0.2800 - val_loss: 2.0645 - val_categorical_accuracy: 0.2765\n",
      "Epoch 299/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0587 - categorical_accuracy: 0.2814 - val_loss: 2.0644 - val_categorical_accuracy: 0.2764\n",
      "Epoch 300/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0586 - categorical_accuracy: 0.2811 - val_loss: 2.0643 - val_categorical_accuracy: 0.2763\n",
      "Epoch 301/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0585 - categorical_accuracy: 0.2806 - val_loss: 2.0642 - val_categorical_accuracy: 0.2753\n",
      "Epoch 302/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0583 - categorical_accuracy: 0.2817 - val_loss: 2.0640 - val_categorical_accuracy: 0.2761\n",
      "Epoch 303/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0583 - categorical_accuracy: 0.2805 - val_loss: 2.0640 - val_categorical_accuracy: 0.2767\n",
      "Epoch 304/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0582 - categorical_accuracy: 0.2812 - val_loss: 2.0639 - val_categorical_accuracy: 0.2759\n",
      "Epoch 305/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0580 - categorical_accuracy: 0.2810 - val_loss: 2.0637 - val_categorical_accuracy: 0.2762\n",
      "Epoch 306/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0579 - categorical_accuracy: 0.2808 - val_loss: 2.0636 - val_categorical_accuracy: 0.2769\n",
      "Epoch 307/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0577 - categorical_accuracy: 0.2816 - val_loss: 2.0635 - val_categorical_accuracy: 0.2769\n",
      "Epoch 308/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0576 - categorical_accuracy: 0.2812 - val_loss: 2.0634 - val_categorical_accuracy: 0.2770\n",
      "Epoch 309/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0575 - categorical_accuracy: 0.2805 - val_loss: 2.0633 - val_categorical_accuracy: 0.2777\n",
      "Epoch 310/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0574 - categorical_accuracy: 0.2817 - val_loss: 2.0632 - val_categorical_accuracy: 0.2773\n",
      "Epoch 311/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0573 - categorical_accuracy: 0.2814 - val_loss: 2.0631 - val_categorical_accuracy: 0.2777\n",
      "Epoch 312/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0571 - categorical_accuracy: 0.2812 - val_loss: 2.0630 - val_categorical_accuracy: 0.2781\n",
      "Epoch 313/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0570 - categorical_accuracy: 0.2809 - val_loss: 2.0630 - val_categorical_accuracy: 0.2774\n",
      "Epoch 314/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0569 - categorical_accuracy: 0.2821 - val_loss: 2.0628 - val_categorical_accuracy: 0.2781\n",
      "Epoch 315/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0568 - categorical_accuracy: 0.2818 - val_loss: 2.0627 - val_categorical_accuracy: 0.2787\n",
      "Epoch 316/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0567 - categorical_accuracy: 0.2819 - val_loss: 2.0626 - val_categorical_accuracy: 0.2780\n",
      "Epoch 317/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0565 - categorical_accuracy: 0.2816 - val_loss: 2.0625 - val_categorical_accuracy: 0.2784\n",
      "Epoch 318/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0564 - categorical_accuracy: 0.2813 - val_loss: 2.0625 - val_categorical_accuracy: 0.2783\n",
      "Epoch 319/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0563 - categorical_accuracy: 0.2825 - val_loss: 2.0623 - val_categorical_accuracy: 0.2787\n",
      "Epoch 320/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0562 - categorical_accuracy: 0.2819 - val_loss: 2.0623 - val_categorical_accuracy: 0.2793\n",
      "Epoch 321/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0561 - categorical_accuracy: 0.2816 - val_loss: 2.0622 - val_categorical_accuracy: 0.2790\n",
      "Epoch 322/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0560 - categorical_accuracy: 0.2818 - val_loss: 2.0621 - val_categorical_accuracy: 0.2787\n",
      "Epoch 323/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0559 - categorical_accuracy: 0.2827 - val_loss: 2.0619 - val_categorical_accuracy: 0.2790\n",
      "Epoch 324/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0558 - categorical_accuracy: 0.2823 - val_loss: 2.0619 - val_categorical_accuracy: 0.2786\n",
      "Epoch 325/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0557 - categorical_accuracy: 0.2822 - val_loss: 2.0617 - val_categorical_accuracy: 0.2791\n",
      "Epoch 326/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0556 - categorical_accuracy: 0.2823 - val_loss: 2.0616 - val_categorical_accuracy: 0.2786\n",
      "Epoch 327/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0555 - categorical_accuracy: 0.2824 - val_loss: 2.0615 - val_categorical_accuracy: 0.2793\n",
      "Epoch 328/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0554 - categorical_accuracy: 0.2825 - val_loss: 2.0614 - val_categorical_accuracy: 0.2797\n",
      "Epoch 329/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0553 - categorical_accuracy: 0.2810 - val_loss: 2.0614 - val_categorical_accuracy: 0.2792\n",
      "Epoch 330/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0551 - categorical_accuracy: 0.2822 - val_loss: 2.0613 - val_categorical_accuracy: 0.2795\n",
      "Epoch 331/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0550 - categorical_accuracy: 0.2823 - val_loss: 2.0612 - val_categorical_accuracy: 0.2793\n",
      "Epoch 332/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0550 - categorical_accuracy: 0.2824 - val_loss: 2.0611 - val_categorical_accuracy: 0.2791\n",
      "Epoch 333/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0548 - categorical_accuracy: 0.2827 - val_loss: 2.0610 - val_categorical_accuracy: 0.2789\n",
      "Epoch 334/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0547 - categorical_accuracy: 0.2828 - val_loss: 2.0609 - val_categorical_accuracy: 0.2799\n",
      "Epoch 335/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0546 - categorical_accuracy: 0.2819 - val_loss: 2.0608 - val_categorical_accuracy: 0.2796\n",
      "Epoch 336/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0545 - categorical_accuracy: 0.2822 - val_loss: 2.0607 - val_categorical_accuracy: 0.2803\n",
      "Epoch 337/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0544 - categorical_accuracy: 0.2831 - val_loss: 2.0606 - val_categorical_accuracy: 0.2800\n",
      "Epoch 338/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0543 - categorical_accuracy: 0.2830 - val_loss: 2.0605 - val_categorical_accuracy: 0.2795\n",
      "Epoch 339/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0542 - categorical_accuracy: 0.2823 - val_loss: 2.0604 - val_categorical_accuracy: 0.2799\n",
      "Epoch 340/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0541 - categorical_accuracy: 0.2831 - val_loss: 2.0604 - val_categorical_accuracy: 0.2794\n",
      "Epoch 341/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0540 - categorical_accuracy: 0.2829 - val_loss: 2.0603 - val_categorical_accuracy: 0.2795\n",
      "Epoch 342/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0539 - categorical_accuracy: 0.2824 - val_loss: 2.0602 - val_categorical_accuracy: 0.2798\n",
      "Epoch 343/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0538 - categorical_accuracy: 0.2826 - val_loss: 2.0601 - val_categorical_accuracy: 0.2797\n",
      "Epoch 344/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0537 - categorical_accuracy: 0.2832 - val_loss: 2.0600 - val_categorical_accuracy: 0.2793\n",
      "Epoch 345/400\n",
      "40000/40000 [==============================] - 0s 8us/step - loss: 2.0536 - categorical_accuracy: 0.2824 - val_loss: 2.0600 - val_categorical_accuracy: 0.2800\n",
      "Epoch 346/400\n",
      "40000/40000 [==============================] - 0s 8us/step - loss: 2.0535 - categorical_accuracy: 0.2836 - val_loss: 2.0599 - val_categorical_accuracy: 0.2800\n",
      "Epoch 347/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0533 - categorical_accuracy: 0.2835 - val_loss: 2.0598 - val_categorical_accuracy: 0.2801\n",
      "Epoch 348/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0533 - categorical_accuracy: 0.2833 - val_loss: 2.0597 - val_categorical_accuracy: 0.2795\n",
      "Epoch 349/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0532 - categorical_accuracy: 0.2829 - val_loss: 2.0596 - val_categorical_accuracy: 0.2800\n",
      "Epoch 350/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0531 - categorical_accuracy: 0.2833 - val_loss: 2.0595 - val_categorical_accuracy: 0.2792\n",
      "Epoch 351/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0530 - categorical_accuracy: 0.2832 - val_loss: 2.0594 - val_categorical_accuracy: 0.2807\n",
      "Epoch 352/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0529 - categorical_accuracy: 0.2834 - val_loss: 2.0593 - val_categorical_accuracy: 0.2808\n",
      "Epoch 353/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0528 - categorical_accuracy: 0.2844 - val_loss: 2.0591 - val_categorical_accuracy: 0.2796\n",
      "Epoch 354/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0527 - categorical_accuracy: 0.2826 - val_loss: 2.0592 - val_categorical_accuracy: 0.2800\n",
      "Epoch 355/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0526 - categorical_accuracy: 0.2842 - val_loss: 2.0590 - val_categorical_accuracy: 0.2801\n",
      "Epoch 356/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0525 - categorical_accuracy: 0.2840 - val_loss: 2.0589 - val_categorical_accuracy: 0.2807\n",
      "Epoch 357/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0524 - categorical_accuracy: 0.2837 - val_loss: 2.0589 - val_categorical_accuracy: 0.2799\n",
      "Epoch 358/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0523 - categorical_accuracy: 0.2834 - val_loss: 2.0589 - val_categorical_accuracy: 0.2795\n",
      "Epoch 359/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0522 - categorical_accuracy: 0.2838 - val_loss: 2.0588 - val_categorical_accuracy: 0.2808\n",
      "Epoch 360/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0521 - categorical_accuracy: 0.2833 - val_loss: 2.0588 - val_categorical_accuracy: 0.2815\n",
      "Epoch 361/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0520 - categorical_accuracy: 0.2845 - val_loss: 2.0586 - val_categorical_accuracy: 0.2806\n",
      "Epoch 362/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0519 - categorical_accuracy: 0.2839 - val_loss: 2.0586 - val_categorical_accuracy: 0.2802\n",
      "Epoch 363/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0518 - categorical_accuracy: 0.2838 - val_loss: 2.0586 - val_categorical_accuracy: 0.2821\n",
      "Epoch 364/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0517 - categorical_accuracy: 0.2842 - val_loss: 2.0584 - val_categorical_accuracy: 0.2813\n",
      "Epoch 365/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0516 - categorical_accuracy: 0.2850 - val_loss: 2.0583 - val_categorical_accuracy: 0.2799\n",
      "Epoch 366/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0515 - categorical_accuracy: 0.2840 - val_loss: 2.0582 - val_categorical_accuracy: 0.2807\n",
      "Epoch 367/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0514 - categorical_accuracy: 0.2841 - val_loss: 2.0581 - val_categorical_accuracy: 0.2807\n",
      "Epoch 368/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0514 - categorical_accuracy: 0.2841 - val_loss: 2.0580 - val_categorical_accuracy: 0.2806\n",
      "Epoch 369/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0513 - categorical_accuracy: 0.2837 - val_loss: 2.0580 - val_categorical_accuracy: 0.2811\n",
      "Epoch 370/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0511 - categorical_accuracy: 0.2851 - val_loss: 2.0579 - val_categorical_accuracy: 0.2817\n",
      "Epoch 371/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0511 - categorical_accuracy: 0.2844 - val_loss: 2.0578 - val_categorical_accuracy: 0.2808\n",
      "Epoch 372/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0510 - categorical_accuracy: 0.2849 - val_loss: 2.0577 - val_categorical_accuracy: 0.2804\n",
      "Epoch 373/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0509 - categorical_accuracy: 0.2840 - val_loss: 2.0577 - val_categorical_accuracy: 0.2814\n",
      "Epoch 374/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0508 - categorical_accuracy: 0.2850 - val_loss: 2.0576 - val_categorical_accuracy: 0.2804\n",
      "Epoch 375/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0507 - categorical_accuracy: 0.2846 - val_loss: 2.0575 - val_categorical_accuracy: 0.2802\n",
      "Epoch 376/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0506 - categorical_accuracy: 0.2847 - val_loss: 2.0574 - val_categorical_accuracy: 0.2811\n",
      "Epoch 377/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0506 - categorical_accuracy: 0.2850 - val_loss: 2.0573 - val_categorical_accuracy: 0.2810\n",
      "Epoch 378/400\n",
      "40000/40000 [==============================] - 0s 8us/step - loss: 2.0504 - categorical_accuracy: 0.2841 - val_loss: 2.0573 - val_categorical_accuracy: 0.2810\n",
      "Epoch 379/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0504 - categorical_accuracy: 0.2845 - val_loss: 2.0572 - val_categorical_accuracy: 0.2823\n",
      "Epoch 380/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0503 - categorical_accuracy: 0.2848 - val_loss: 2.0572 - val_categorical_accuracy: 0.2825\n",
      "Epoch 381/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0502 - categorical_accuracy: 0.2844 - val_loss: 2.0571 - val_categorical_accuracy: 0.2815\n",
      "Epoch 382/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0501 - categorical_accuracy: 0.2849 - val_loss: 2.0570 - val_categorical_accuracy: 0.2814\n",
      "Epoch 383/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0500 - categorical_accuracy: 0.2846 - val_loss: 2.0569 - val_categorical_accuracy: 0.2810\n",
      "Epoch 384/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0500 - categorical_accuracy: 0.2854 - val_loss: 2.0568 - val_categorical_accuracy: 0.2821\n",
      "Epoch 385/400\n",
      "40000/40000 [==============================] - 0s 8us/step - loss: 2.0498 - categorical_accuracy: 0.2847 - val_loss: 2.0568 - val_categorical_accuracy: 0.2826\n",
      "Epoch 386/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0497 - categorical_accuracy: 0.2853 - val_loss: 2.0567 - val_categorical_accuracy: 0.2821\n",
      "Epoch 387/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0497 - categorical_accuracy: 0.2852 - val_loss: 2.0566 - val_categorical_accuracy: 0.2816\n",
      "Epoch 388/400\n",
      "40000/40000 [==============================] - 0s 8us/step - loss: 2.0495 - categorical_accuracy: 0.2851 - val_loss: 2.0565 - val_categorical_accuracy: 0.2818\n",
      "Epoch 389/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0495 - categorical_accuracy: 0.2859 - val_loss: 2.0564 - val_categorical_accuracy: 0.2823\n",
      "Epoch 390/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0494 - categorical_accuracy: 0.2851 - val_loss: 2.0564 - val_categorical_accuracy: 0.2812\n",
      "Epoch 391/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0494 - categorical_accuracy: 0.2849 - val_loss: 2.0563 - val_categorical_accuracy: 0.2817\n",
      "Epoch 392/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0492 - categorical_accuracy: 0.2851 - val_loss: 2.0563 - val_categorical_accuracy: 0.2830\n",
      "Epoch 393/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0491 - categorical_accuracy: 0.2853 - val_loss: 2.0562 - val_categorical_accuracy: 0.2825\n",
      "Epoch 394/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0490 - categorical_accuracy: 0.2849 - val_loss: 2.0562 - val_categorical_accuracy: 0.2829\n",
      "Epoch 395/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0490 - categorical_accuracy: 0.2859 - val_loss: 2.0561 - val_categorical_accuracy: 0.2828\n",
      "Epoch 396/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0489 - categorical_accuracy: 0.2853 - val_loss: 2.0560 - val_categorical_accuracy: 0.2822\n",
      "Epoch 397/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0488 - categorical_accuracy: 0.2851 - val_loss: 2.0559 - val_categorical_accuracy: 0.2823\n",
      "Epoch 398/400\n",
      "40000/40000 [==============================] - 0s 7us/step - loss: 2.0488 - categorical_accuracy: 0.2855 - val_loss: 2.0559 - val_categorical_accuracy: 0.2830\n",
      "Epoch 399/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0487 - categorical_accuracy: 0.2866 - val_loss: 2.0557 - val_categorical_accuracy: 0.2821\n",
      "Epoch 400/400\n",
      "40000/40000 [==============================] - 0s 6us/step - loss: 2.0486 - categorical_accuracy: 0.2855 - val_loss: 2.0557 - val_categorical_accuracy: 0.2823\n",
      "10000/10000 [==============================] - 0s 13us/step\n",
      "Test score: 2.0605357597351075\n",
      "Test accuracy: 0.2846\n"
     ]
    }
   ],
   "source": [
    "# BATCH SIZE = 10000, stopped epochs at 400 after seeing no improvement\n",
    "modelNN5 = Sequential()\n",
    "modelNN5.add(Dense(10, activation='softmax', input_shape=(1024,), kernel_initializer='random_uniform'))\n",
    "modelNN5.summary()\n",
    "\n",
    "epochs_SNN5 = 400\n",
    "batch_size_SNN5 = 10000\n",
    "\n",
    "modelNN5.compile(loss='categorical_crossentropy', optimizer=SGD(), metrics=['categorical_accuracy'])\n",
    "history = modelNN5.fit(x_trainNN, y_trainNN, batch_size=batch_size_SNN5, epochs=epochs_SNN5, verbose=1, validation_split=0.2)\n",
    "\n",
    "score = modelNN5.evaluate(x_testNN, y_testNN, verbose=1)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The first VERY simple neural network yielded predictably poor results, with max accuracy reaching ~0.30 and not improving any more. To see if I could improve this more, I created the following Deep Neural Network:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Network\n",
    "## >> Accuracy ~0.42%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 461,322\n",
      "Trainable params: 461,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "40000/40000 [==============================] - 8s 197us/step - loss: 2.0996 - categorical_accuracy: 0.2322 - val_loss: 1.9830 - val_categorical_accuracy: 0.2802\n",
      "Epoch 2/200\n",
      "40000/40000 [==============================] - 7s 168us/step - loss: 1.9395 - categorical_accuracy: 0.3014 - val_loss: 1.8903 - val_categorical_accuracy: 0.3181\n",
      "Epoch 3/200\n",
      "40000/40000 [==============================] - 7s 169us/step - loss: 1.8627 - categorical_accuracy: 0.3340 - val_loss: 1.8409 - val_categorical_accuracy: 0.3390\n",
      "Epoch 4/200\n",
      "40000/40000 [==============================] - 7s 172us/step - loss: 1.8119 - categorical_accuracy: 0.3547 - val_loss: 1.8316 - val_categorical_accuracy: 0.3419\n",
      "Epoch 5/200\n",
      "40000/40000 [==============================] - 6s 158us/step - loss: 1.7705 - categorical_accuracy: 0.3689 - val_loss: 1.7734 - val_categorical_accuracy: 0.3648\n",
      "Epoch 6/200\n",
      "40000/40000 [==============================] - 7s 164us/step - loss: 1.7387 - categorical_accuracy: 0.3822 - val_loss: 1.7439 - val_categorical_accuracy: 0.3835\n",
      "Epoch 7/200\n",
      "40000/40000 [==============================] - 7s 167us/step - loss: 1.7093 - categorical_accuracy: 0.3908 - val_loss: 1.7546 - val_categorical_accuracy: 0.3715\n",
      "Epoch 8/200\n",
      "40000/40000 [==============================] - 7s 166us/step - loss: 1.6828 - categorical_accuracy: 0.4022 - val_loss: 1.6991 - val_categorical_accuracy: 0.4026\n",
      "Epoch 9/200\n",
      "40000/40000 [==============================] - 6s 157us/step - loss: 1.6554 - categorical_accuracy: 0.4161 - val_loss: 1.6870 - val_categorical_accuracy: 0.4023\n",
      "Epoch 10/200\n",
      "40000/40000 [==============================] - 6s 152us/step - loss: 1.6312 - categorical_accuracy: 0.4204 - val_loss: 1.6958 - val_categorical_accuracy: 0.3979\n",
      "Epoch 11/200\n",
      "40000/40000 [==============================] - 6s 157us/step - loss: 1.6092 - categorical_accuracy: 0.4282 - val_loss: 1.6652 - val_categorical_accuracy: 0.4149\n",
      "Epoch 12/200\n",
      "40000/40000 [==============================] - 6s 158us/step - loss: 1.5850 - categorical_accuracy: 0.4384 - val_loss: 1.6787 - val_categorical_accuracy: 0.4074\n",
      "Epoch 13/200\n",
      "40000/40000 [==============================] - 6s 157us/step - loss: 1.5628 - categorical_accuracy: 0.4450 - val_loss: 1.6293 - val_categorical_accuracy: 0.4223\n",
      "Epoch 14/200\n",
      "40000/40000 [==============================] - 6s 157us/step - loss: 1.5402 - categorical_accuracy: 0.4539 - val_loss: 1.6487 - val_categorical_accuracy: 0.4132\n",
      "Epoch 15/200\n",
      "40000/40000 [==============================] - 6s 157us/step - loss: 1.5204 - categorical_accuracy: 0.4635 - val_loss: 1.6566 - val_categorical_accuracy: 0.4182\n",
      "Epoch 16/200\n",
      "40000/40000 [==============================] - 6s 157us/step - loss: 1.5006 - categorical_accuracy: 0.4677 - val_loss: 1.6191 - val_categorical_accuracy: 0.4288\n",
      "Epoch 17/200\n",
      "40000/40000 [==============================] - 6s 157us/step - loss: 1.4794 - categorical_accuracy: 0.4765 - val_loss: 1.6219 - val_categorical_accuracy: 0.4206\n",
      "Epoch 18/200\n",
      "40000/40000 [==============================] - 6s 157us/step - loss: 1.4629 - categorical_accuracy: 0.4822 - val_loss: 1.6424 - val_categorical_accuracy: 0.4185\n",
      "Epoch 19/200\n",
      "40000/40000 [==============================] - 6s 158us/step - loss: 1.4389 - categorical_accuracy: 0.4900 - val_loss: 1.6434 - val_categorical_accuracy: 0.4240\n",
      "Epoch 20/200\n",
      "40000/40000 [==============================] - 6s 157us/step - loss: 1.4232 - categorical_accuracy: 0.4947 - val_loss: 1.6041 - val_categorical_accuracy: 0.4345\n",
      "Epoch 21/200\n",
      "40000/40000 [==============================] - 6s 157us/step - loss: 1.3988 - categorical_accuracy: 0.5060 - val_loss: 1.6201 - val_categorical_accuracy: 0.4263\n",
      "Epoch 22/200\n",
      "40000/40000 [==============================] - 6s 157us/step - loss: 1.3845 - categorical_accuracy: 0.5122 - val_loss: 1.5918 - val_categorical_accuracy: 0.4388\n",
      "Epoch 23/200\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 1.3596 - categorical_accuracy: 0.5199 - val_loss: 1.6198 - val_categorical_accuracy: 0.4322\n",
      "Epoch 24/200\n",
      "40000/40000 [==============================] - 6s 158us/step - loss: 1.3415 - categorical_accuracy: 0.5260 - val_loss: 1.6738 - val_categorical_accuracy: 0.4261\n",
      "Epoch 25/200\n",
      "40000/40000 [==============================] - 6s 157us/step - loss: 1.3220 - categorical_accuracy: 0.5316 - val_loss: 1.6178 - val_categorical_accuracy: 0.4334\n",
      "Epoch 26/200\n",
      "40000/40000 [==============================] - 6s 157us/step - loss: 1.2992 - categorical_accuracy: 0.5418 - val_loss: 1.6412 - val_categorical_accuracy: 0.4331\n",
      "Epoch 27/200\n",
      "40000/40000 [==============================] - 6s 158us/step - loss: 1.2838 - categorical_accuracy: 0.5461 - val_loss: 1.6127 - val_categorical_accuracy: 0.4420\n",
      "Epoch 28/200\n",
      "40000/40000 [==============================] - 6s 158us/step - loss: 1.2575 - categorical_accuracy: 0.5562 - val_loss: 1.6970 - val_categorical_accuracy: 0.4235\n",
      "Epoch 29/200\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 1.2340 - categorical_accuracy: 0.5650 - val_loss: 1.6808 - val_categorical_accuracy: 0.4383\n",
      "Epoch 30/200\n",
      "40000/40000 [==============================] - 7s 179us/step - loss: 1.2158 - categorical_accuracy: 0.5683 - val_loss: 1.6291 - val_categorical_accuracy: 0.4437\n",
      "Epoch 31/200\n",
      "40000/40000 [==============================] - 7s 179us/step - loss: 1.1936 - categorical_accuracy: 0.5784 - val_loss: 1.6373 - val_categorical_accuracy: 0.4464\n",
      "Epoch 32/200\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 1.1695 - categorical_accuracy: 0.5877 - val_loss: 1.6874 - val_categorical_accuracy: 0.4409\n",
      "Epoch 33/200\n",
      "40000/40000 [==============================] - 7s 177us/step - loss: 1.1504 - categorical_accuracy: 0.5957 - val_loss: 1.6793 - val_categorical_accuracy: 0.4408\n",
      "Epoch 34/200\n",
      "40000/40000 [==============================] - 7s 187us/step - loss: 1.1242 - categorical_accuracy: 0.6047 - val_loss: 1.6790 - val_categorical_accuracy: 0.4431\n",
      "Epoch 35/200\n",
      "40000/40000 [==============================] - 12s 294us/step - loss: 1.0997 - categorical_accuracy: 0.6114 - val_loss: 1.7365 - val_categorical_accuracy: 0.4364\n",
      "Epoch 36/200\n",
      "40000/40000 [==============================] - 8s 197us/step - loss: 1.0788 - categorical_accuracy: 0.6200 - val_loss: 1.7118 - val_categorical_accuracy: 0.4403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/200\n",
      "40000/40000 [==============================] - 8s 200us/step - loss: 1.0538 - categorical_accuracy: 0.6291 - val_loss: 1.7427 - val_categorical_accuracy: 0.4350\n",
      "Epoch 38/200\n",
      "40000/40000 [==============================] - 8s 200us/step - loss: 1.0320 - categorical_accuracy: 0.6347 - val_loss: 1.7363 - val_categorical_accuracy: 0.4382\n",
      "Epoch 39/200\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 1.0043 - categorical_accuracy: 0.6451 - val_loss: 1.7916 - val_categorical_accuracy: 0.4383\n",
      "Epoch 40/200\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.9803 - categorical_accuracy: 0.6528 - val_loss: 1.7755 - val_categorical_accuracy: 0.4488\n",
      "Epoch 41/200\n",
      "40000/40000 [==============================] - 7s 179us/step - loss: 0.9561 - categorical_accuracy: 0.6631 - val_loss: 1.9131 - val_categorical_accuracy: 0.4241\n",
      "Epoch 42/200\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.9295 - categorical_accuracy: 0.6700 - val_loss: 1.8339 - val_categorical_accuracy: 0.4400\n",
      "Epoch 43/200\n",
      "40000/40000 [==============================] - 7s 163us/step - loss: 0.9001 - categorical_accuracy: 0.6833 - val_loss: 1.9038 - val_categorical_accuracy: 0.4326\n",
      "Epoch 44/200\n",
      "40000/40000 [==============================] - 6s 162us/step - loss: 0.8834 - categorical_accuracy: 0.6873 - val_loss: 1.8893 - val_categorical_accuracy: 0.4356\n",
      "Epoch 45/200\n",
      "40000/40000 [==============================] - 6s 162us/step - loss: 0.8532 - categorical_accuracy: 0.6993 - val_loss: 1.9616 - val_categorical_accuracy: 0.4325\n",
      "Epoch 46/200\n",
      "40000/40000 [==============================] - 7s 164us/step - loss: 0.8306 - categorical_accuracy: 0.7068 - val_loss: 1.9690 - val_categorical_accuracy: 0.4236\n",
      "Epoch 47/200\n",
      "40000/40000 [==============================] - 7s 168us/step - loss: 0.8036 - categorical_accuracy: 0.7149 - val_loss: 2.0152 - val_categorical_accuracy: 0.4298\n",
      "Epoch 48/200\n",
      "40000/40000 [==============================] - 6s 162us/step - loss: 0.7780 - categorical_accuracy: 0.7256 - val_loss: 2.0707 - val_categorical_accuracy: 0.4239\n",
      "Epoch 49/200\n",
      "40000/40000 [==============================] - 6s 162us/step - loss: 0.7545 - categorical_accuracy: 0.7334 - val_loss: 2.0566 - val_categorical_accuracy: 0.4323\n",
      "Epoch 50/200\n",
      "40000/40000 [==============================] - 7s 164us/step - loss: 0.7339 - categorical_accuracy: 0.7391 - val_loss: 2.2720 - val_categorical_accuracy: 0.4185\n",
      "Epoch 51/200\n",
      "40000/40000 [==============================] - 7s 164us/step - loss: 0.7015 - categorical_accuracy: 0.7530 - val_loss: 2.1620 - val_categorical_accuracy: 0.4284\n",
      "Epoch 52/200\n",
      "40000/40000 [==============================] - 7s 168us/step - loss: 0.6827 - categorical_accuracy: 0.7577 - val_loss: 2.1566 - val_categorical_accuracy: 0.4200\n",
      "Epoch 53/200\n",
      "40000/40000 [==============================] - 7s 164us/step - loss: 0.6569 - categorical_accuracy: 0.7674 - val_loss: 2.2919 - val_categorical_accuracy: 0.4167\n",
      "Epoch 54/200\n",
      "40000/40000 [==============================] - 6s 162us/step - loss: 0.6393 - categorical_accuracy: 0.7733 - val_loss: 2.3253 - val_categorical_accuracy: 0.4267\n",
      "Epoch 55/200\n",
      "40000/40000 [==============================] - 6s 161us/step - loss: 0.6113 - categorical_accuracy: 0.7824 - val_loss: 2.4150 - val_categorical_accuracy: 0.4093\n",
      "Epoch 56/200\n",
      "40000/40000 [==============================] - 6s 162us/step - loss: 0.5859 - categorical_accuracy: 0.7932 - val_loss: 2.4673 - val_categorical_accuracy: 0.4173\n",
      "Epoch 57/200\n",
      "40000/40000 [==============================] - 7s 170us/step - loss: 0.5735 - categorical_accuracy: 0.7957 - val_loss: 2.4416 - val_categorical_accuracy: 0.4131\n",
      "Epoch 58/200\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.5530 - categorical_accuracy: 0.8046 - val_loss: 2.4866 - val_categorical_accuracy: 0.4284\n",
      "Epoch 59/200\n",
      "40000/40000 [==============================] - 9s 231us/step - loss: 0.5217 - categorical_accuracy: 0.8151 - val_loss: 2.6169 - val_categorical_accuracy: 0.4104\n",
      "Epoch 60/200\n",
      "40000/40000 [==============================] - 8s 188us/step - loss: 0.5141 - categorical_accuracy: 0.8171 - val_loss: 2.6715 - val_categorical_accuracy: 0.4164\n",
      "Epoch 61/200\n",
      "40000/40000 [==============================] - 7s 176us/step - loss: 0.4934 - categorical_accuracy: 0.8241 - val_loss: 2.6296 - val_categorical_accuracy: 0.4174\n",
      "Epoch 62/200\n",
      "40000/40000 [==============================] - 7s 177us/step - loss: 0.4739 - categorical_accuracy: 0.8313 - val_loss: 2.8736 - val_categorical_accuracy: 0.3972\n",
      "Epoch 63/200\n",
      "40000/40000 [==============================] - 7s 177us/step - loss: 0.4582 - categorical_accuracy: 0.8369 - val_loss: 2.7323 - val_categorical_accuracy: 0.4153\n",
      "Epoch 64/200\n",
      "40000/40000 [==============================] - 7s 178us/step - loss: 0.4485 - categorical_accuracy: 0.8391 - val_loss: 2.8002 - val_categorical_accuracy: 0.4139\n",
      "Epoch 65/200\n",
      "40000/40000 [==============================] - 7s 176us/step - loss: 0.4218 - categorical_accuracy: 0.8498 - val_loss: 2.9704 - val_categorical_accuracy: 0.4125\n",
      "Epoch 66/200\n",
      "40000/40000 [==============================] - 7s 177us/step - loss: 0.4198 - categorical_accuracy: 0.8498 - val_loss: 2.9602 - val_categorical_accuracy: 0.4052\n",
      "Epoch 67/200\n",
      "40000/40000 [==============================] - 7s 178us/step - loss: 0.4008 - categorical_accuracy: 0.8577 - val_loss: 2.9482 - val_categorical_accuracy: 0.4164\n",
      "Epoch 68/200\n",
      "40000/40000 [==============================] - 7s 177us/step - loss: 0.3715 - categorical_accuracy: 0.8667 - val_loss: 3.1518 - val_categorical_accuracy: 0.4119\n",
      "Epoch 69/200\n",
      "40000/40000 [==============================] - 7s 177us/step - loss: 0.3662 - categorical_accuracy: 0.8676 - val_loss: 3.0775 - val_categorical_accuracy: 0.4189\n",
      "Epoch 70/200\n",
      "40000/40000 [==============================] - 7s 179us/step - loss: 0.3460 - categorical_accuracy: 0.8752 - val_loss: 3.1715 - val_categorical_accuracy: 0.4116\n",
      "Epoch 71/200\n",
      "40000/40000 [==============================] - 7s 178us/step - loss: 0.3570 - categorical_accuracy: 0.8732 - val_loss: 3.1608 - val_categorical_accuracy: 0.4205\n",
      "Epoch 72/200\n",
      "40000/40000 [==============================] - 7s 177us/step - loss: 0.3386 - categorical_accuracy: 0.8802 - val_loss: 3.4551 - val_categorical_accuracy: 0.4049\n",
      "Epoch 73/200\n",
      "40000/40000 [==============================] - 7s 178us/step - loss: 0.3248 - categorical_accuracy: 0.8847 - val_loss: 3.2916 - val_categorical_accuracy: 0.4295\n",
      "Epoch 74/200\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.3246 - categorical_accuracy: 0.8842 - val_loss: 3.4902 - val_categorical_accuracy: 0.4095\n",
      "Epoch 75/200\n",
      "40000/40000 [==============================] - 7s 178us/step - loss: 0.3025 - categorical_accuracy: 0.8925 - val_loss: 3.2356 - val_categorical_accuracy: 0.4205\n",
      "Epoch 76/200\n",
      "40000/40000 [==============================] - 7s 178us/step - loss: 0.3035 - categorical_accuracy: 0.8914 - val_loss: 3.3712 - val_categorical_accuracy: 0.4144\n",
      "Epoch 77/200\n",
      "40000/40000 [==============================] - 7s 179us/step - loss: 0.2752 - categorical_accuracy: 0.9042 - val_loss: 3.3836 - val_categorical_accuracy: 0.4161\n",
      "Epoch 78/200\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.2723 - categorical_accuracy: 0.9034 - val_loss: 3.5158 - val_categorical_accuracy: 0.4152\n",
      "Epoch 79/200\n",
      "40000/40000 [==============================] - 7s 178us/step - loss: 0.2780 - categorical_accuracy: 0.9006 - val_loss: 3.4977 - val_categorical_accuracy: 0.4167\n",
      "Epoch 80/200\n",
      "40000/40000 [==============================] - 7s 178us/step - loss: 0.2464 - categorical_accuracy: 0.9152 - val_loss: 3.4564 - val_categorical_accuracy: 0.4306\n",
      "Epoch 81/200\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.2620 - categorical_accuracy: 0.9080 - val_loss: 3.6188 - val_categorical_accuracy: 0.4214\n",
      "Epoch 82/200\n",
      "40000/40000 [==============================] - 7s 178us/step - loss: 0.2719 - categorical_accuracy: 0.9071 - val_loss: 3.7279 - val_categorical_accuracy: 0.4214\n",
      "Epoch 83/200\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.2365 - categorical_accuracy: 0.9170 - val_loss: 3.8617 - val_categorical_accuracy: 0.4102\n",
      "Epoch 84/200\n",
      "40000/40000 [==============================] - 7s 171us/step - loss: 0.2260 - categorical_accuracy: 0.9194 - val_loss: 3.6821 - val_categorical_accuracy: 0.4207\n",
      "Epoch 85/200\n",
      "40000/40000 [==============================] - 7s 171us/step - loss: 0.2104 - categorical_accuracy: 0.9269 - val_loss: 3.7516 - val_categorical_accuracy: 0.4198\n",
      "Epoch 86/200\n",
      "40000/40000 [==============================] - 7s 172us/step - loss: 0.2382 - categorical_accuracy: 0.9150 - val_loss: 3.7444 - val_categorical_accuracy: 0.4233\n",
      "Epoch 87/200\n",
      "40000/40000 [==============================] - 7s 172us/step - loss: 0.2180 - categorical_accuracy: 0.9243 - val_loss: 3.7907 - val_categorical_accuracy: 0.4108\n",
      "Epoch 88/200\n",
      "40000/40000 [==============================] - 7s 172us/step - loss: 0.1989 - categorical_accuracy: 0.9310 - val_loss: 3.9179 - val_categorical_accuracy: 0.4245\n",
      "Epoch 89/200\n",
      "40000/40000 [==============================] - 7s 172us/step - loss: 0.1999 - categorical_accuracy: 0.9307 - val_loss: 3.8545 - val_categorical_accuracy: 0.4224\n",
      "Epoch 90/200\n",
      "40000/40000 [==============================] - 7s 173us/step - loss: 0.1841 - categorical_accuracy: 0.9353 - val_loss: 3.9816 - val_categorical_accuracy: 0.4188\n",
      "Epoch 91/200\n",
      "40000/40000 [==============================] - 7s 176us/step - loss: 0.2228 - categorical_accuracy: 0.9221 - val_loss: 3.8492 - val_categorical_accuracy: 0.4105\n",
      "Epoch 92/200\n",
      "40000/40000 [==============================] - 7s 174us/step - loss: 0.1867 - categorical_accuracy: 0.9356 - val_loss: 3.9325 - val_categorical_accuracy: 0.4181\n",
      "Epoch 93/200\n",
      "40000/40000 [==============================] - 7s 175us/step - loss: 0.1586 - categorical_accuracy: 0.9455 - val_loss: 4.0284 - val_categorical_accuracy: 0.4143\n",
      "Epoch 94/200\n",
      "40000/40000 [==============================] - 7s 178us/step - loss: 0.1562 - categorical_accuracy: 0.9458 - val_loss: 4.0870 - val_categorical_accuracy: 0.4249\n",
      "Epoch 95/200\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.1602 - categorical_accuracy: 0.9448 - val_loss: 4.2236 - val_categorical_accuracy: 0.4194\n",
      "Epoch 96/200\n",
      "40000/40000 [==============================] - 7s 174us/step - loss: 0.1984 - categorical_accuracy: 0.9321 - val_loss: 4.0095 - val_categorical_accuracy: 0.4181\n",
      "Epoch 97/200\n",
      "40000/40000 [==============================] - 7s 173us/step - loss: 0.1337 - categorical_accuracy: 0.9548 - val_loss: 4.1551 - val_categorical_accuracy: 0.4232\n",
      "Epoch 98/200\n",
      "40000/40000 [==============================] - 7s 173us/step - loss: 0.2104 - categorical_accuracy: 0.9271 - val_loss: 4.0807 - val_categorical_accuracy: 0.4173\n",
      "Epoch 99/200\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.1455 - categorical_accuracy: 0.9500 - val_loss: 4.3047 - val_categorical_accuracy: 0.4167\n",
      "Epoch 100/200\n",
      "40000/40000 [==============================] - 7s 173us/step - loss: 0.1400 - categorical_accuracy: 0.9514 - val_loss: 4.1942 - val_categorical_accuracy: 0.4264\n",
      "Epoch 101/200\n",
      "40000/40000 [==============================] - 7s 173us/step - loss: 0.1646 - categorical_accuracy: 0.9431 - val_loss: 4.2726 - val_categorical_accuracy: 0.4123\n",
      "Epoch 102/200\n",
      "40000/40000 [==============================] - 7s 167us/step - loss: 0.1854 - categorical_accuracy: 0.9356 - val_loss: 4.1803 - val_categorical_accuracy: 0.4158\n",
      "Epoch 103/200\n",
      "40000/40000 [==============================] - 7s 163us/step - loss: 0.1492 - categorical_accuracy: 0.9492 - val_loss: 4.1975 - val_categorical_accuracy: 0.4215\n",
      "Epoch 104/200\n",
      "40000/40000 [==============================] - 6s 158us/step - loss: 0.1436 - categorical_accuracy: 0.9517 - val_loss: 4.3709 - val_categorical_accuracy: 0.4087\n",
      "Epoch 105/200\n",
      "40000/40000 [==============================] - 6s 158us/step - loss: 0.1532 - categorical_accuracy: 0.9481 - val_loss: 4.4035 - val_categorical_accuracy: 0.4102\n",
      "Epoch 106/200\n",
      "40000/40000 [==============================] - 6s 156us/step - loss: 0.1523 - categorical_accuracy: 0.9466 - val_loss: 4.3451 - val_categorical_accuracy: 0.4051\n",
      "Epoch 107/200\n",
      "40000/40000 [==============================] - 6s 158us/step - loss: 0.1344 - categorical_accuracy: 0.9541 - val_loss: 4.4902 - val_categorical_accuracy: 0.4155\n",
      "Epoch 108/200\n",
      "40000/40000 [==============================] - 6s 158us/step - loss: 0.1251 - categorical_accuracy: 0.9573 - val_loss: 4.3618 - val_categorical_accuracy: 0.4163\n",
      "Epoch 109/200\n",
      "40000/40000 [==============================] - 6s 161us/step - loss: 0.0823 - categorical_accuracy: 0.9724 - val_loss: 4.4568 - val_categorical_accuracy: 0.4239\n",
      "Epoch 110/200\n",
      "40000/40000 [==============================] - 6s 157us/step - loss: 0.0565 - categorical_accuracy: 0.9816 - val_loss: 4.7466 - val_categorical_accuracy: 0.4186\n",
      "Epoch 111/200\n",
      "40000/40000 [==============================] - 6s 159us/step - loss: 0.1356 - categorical_accuracy: 0.9541 - val_loss: 4.4995 - val_categorical_accuracy: 0.4157\n",
      "Epoch 112/200\n",
      "40000/40000 [==============================] - 6s 159us/step - loss: 0.1553 - categorical_accuracy: 0.9462 - val_loss: 4.3670 - val_categorical_accuracy: 0.4196\n",
      "Epoch 113/200\n",
      "40000/40000 [==============================] - 6s 158us/step - loss: 0.1416 - categorical_accuracy: 0.9521 - val_loss: 4.4479 - val_categorical_accuracy: 0.4144\n",
      "Epoch 114/200\n",
      "40000/40000 [==============================] - 6s 157us/step - loss: 0.0916 - categorical_accuracy: 0.9704 - val_loss: 4.7774 - val_categorical_accuracy: 0.3998\n",
      "Epoch 115/200\n",
      "40000/40000 [==============================] - 6s 156us/step - loss: 0.1029 - categorical_accuracy: 0.9661 - val_loss: 4.7641 - val_categorical_accuracy: 0.3979\n",
      "Epoch 116/200\n",
      "40000/40000 [==============================] - 6s 158us/step - loss: 0.1136 - categorical_accuracy: 0.9612 - val_loss: 4.6766 - val_categorical_accuracy: 0.4115\n",
      "Epoch 117/200\n",
      "40000/40000 [==============================] - 6s 157us/step - loss: 0.1473 - categorical_accuracy: 0.9510 - val_loss: 4.7130 - val_categorical_accuracy: 0.4033\n",
      "Epoch 118/200\n",
      "40000/40000 [==============================] - 6s 157us/step - loss: 0.0976 - categorical_accuracy: 0.9672 - val_loss: 4.7271 - val_categorical_accuracy: 0.4179\n",
      "Epoch 119/200\n",
      "40000/40000 [==============================] - 6s 158us/step - loss: 0.0585 - categorical_accuracy: 0.9808 - val_loss: 4.7323 - val_categorical_accuracy: 0.4145\n",
      "Epoch 120/200\n",
      "40000/40000 [==============================] - 6s 158us/step - loss: 0.0671 - categorical_accuracy: 0.9776 - val_loss: 4.8298 - val_categorical_accuracy: 0.4142\n",
      "Epoch 121/200\n",
      "40000/40000 [==============================] - 6s 159us/step - loss: 0.0643 - categorical_accuracy: 0.9789 - val_loss: 5.0376 - val_categorical_accuracy: 0.4105\n",
      "Epoch 122/200\n",
      "40000/40000 [==============================] - 6s 157us/step - loss: 0.1342 - categorical_accuracy: 0.9530 - val_loss: 4.6028 - val_categorical_accuracy: 0.4102\n",
      "Epoch 123/200\n",
      "40000/40000 [==============================] - 6s 158us/step - loss: 0.1677 - categorical_accuracy: 0.9437 - val_loss: 4.8067 - val_categorical_accuracy: 0.4037\n",
      "Epoch 124/200\n",
      "40000/40000 [==============================] - 6s 159us/step - loss: 0.1104 - categorical_accuracy: 0.9624 - val_loss: 4.7654 - val_categorical_accuracy: 0.4180\n",
      "Epoch 125/200\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 0.0933 - categorical_accuracy: 0.9692 - val_loss: 4.9182 - val_categorical_accuracy: 0.3931\n",
      "Epoch 126/200\n",
      "40000/40000 [==============================] - 6s 159us/step - loss: 0.1294 - categorical_accuracy: 0.9565 - val_loss: 4.7338 - val_categorical_accuracy: 0.4096\n",
      "Epoch 127/200\n",
      "40000/40000 [==============================] - 6s 159us/step - loss: 0.1236 - categorical_accuracy: 0.9575 - val_loss: 4.7129 - val_categorical_accuracy: 0.4201\n",
      "Epoch 128/200\n",
      "40000/40000 [==============================] - 7s 163us/step - loss: 0.0898 - categorical_accuracy: 0.9697 - val_loss: 4.7870 - val_categorical_accuracy: 0.4274\n",
      "Epoch 129/200\n",
      "40000/40000 [==============================] - 6s 161us/step - loss: 0.0439 - categorical_accuracy: 0.9863 - val_loss: 5.0893 - val_categorical_accuracy: 0.4087\n",
      "Epoch 130/200\n",
      "40000/40000 [==============================] - 6s 161us/step - loss: 0.1059 - categorical_accuracy: 0.9659 - val_loss: 4.9197 - val_categorical_accuracy: 0.4142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/200\n",
      "40000/40000 [==============================] - 6s 158us/step - loss: 0.0758 - categorical_accuracy: 0.9755 - val_loss: 4.9173 - val_categorical_accuracy: 0.4166\n",
      "Epoch 132/200\n",
      "40000/40000 [==============================] - 6s 158us/step - loss: 0.0736 - categorical_accuracy: 0.9751 - val_loss: 5.0224 - val_categorical_accuracy: 0.4217\n",
      "Epoch 133/200\n",
      "40000/40000 [==============================] - 6s 157us/step - loss: 0.0577 - categorical_accuracy: 0.9804 - val_loss: 4.9575 - val_categorical_accuracy: 0.4176\n",
      "Epoch 134/200\n",
      "40000/40000 [==============================] - 6s 157us/step - loss: 0.0654 - categorical_accuracy: 0.9779 - val_loss: 5.0218 - val_categorical_accuracy: 0.4186\n",
      "Epoch 135/200\n",
      "40000/40000 [==============================] - 6s 162us/step - loss: 0.1107 - categorical_accuracy: 0.9638 - val_loss: 4.8051 - val_categorical_accuracy: 0.4221\n",
      "Epoch 136/200\n",
      "40000/40000 [==============================] - 6s 159us/step - loss: 0.1020 - categorical_accuracy: 0.9663 - val_loss: 4.8647 - val_categorical_accuracy: 0.4119\n",
      "Epoch 137/200\n",
      "40000/40000 [==============================] - 6s 158us/step - loss: 0.1002 - categorical_accuracy: 0.9671 - val_loss: 4.9693 - val_categorical_accuracy: 0.4139\n",
      "Epoch 138/200\n",
      "40000/40000 [==============================] - 6s 158us/step - loss: 0.1049 - categorical_accuracy: 0.9652 - val_loss: 4.9345 - val_categorical_accuracy: 0.4129\n",
      "Epoch 139/200\n",
      "40000/40000 [==============================] - 6s 158us/step - loss: 0.1015 - categorical_accuracy: 0.9663 - val_loss: 4.9745 - val_categorical_accuracy: 0.4098\n",
      "Epoch 140/200\n",
      "40000/40000 [==============================] - 6s 157us/step - loss: 0.0543 - categorical_accuracy: 0.9820 - val_loss: 4.9442 - val_categorical_accuracy: 0.4216\n",
      "Epoch 141/200\n",
      "40000/40000 [==============================] - 6s 161us/step - loss: 0.0100 - categorical_accuracy: 0.9976 - val_loss: 4.9949 - val_categorical_accuracy: 0.4325\n",
      "Epoch 142/200\n",
      "40000/40000 [==============================] - 6s 159us/step - loss: 0.0030 - categorical_accuracy: 0.9997 - val_loss: 5.0667 - val_categorical_accuracy: 0.4363\n",
      "Epoch 143/200\n",
      "40000/40000 [==============================] - 6s 158us/step - loss: 0.0015 - categorical_accuracy: 0.9998 - val_loss: 5.1129 - val_categorical_accuracy: 0.4363\n",
      "Epoch 144/200\n",
      "40000/40000 [==============================] - 6s 159us/step - loss: 0.0012 - categorical_accuracy: 0.9999 - val_loss: 5.1516 - val_categorical_accuracy: 0.4371\n",
      "Epoch 145/200\n",
      "40000/40000 [==============================] - 6s 159us/step - loss: 9.2314e-04 - categorical_accuracy: 1.0000 - val_loss: 5.1831 - val_categorical_accuracy: 0.4373\n",
      "Epoch 146/200\n",
      "40000/40000 [==============================] - 6s 159us/step - loss: 7.9164e-04 - categorical_accuracy: 1.0000 - val_loss: 5.2075 - val_categorical_accuracy: 0.4390\n",
      "Epoch 147/200\n",
      "40000/40000 [==============================] - 6s 161us/step - loss: 6.7738e-04 - categorical_accuracy: 1.0000 - val_loss: 5.2307 - val_categorical_accuracy: 0.4385\n",
      "Epoch 148/200\n",
      "40000/40000 [==============================] - 6s 158us/step - loss: 5.9684e-04 - categorical_accuracy: 1.0000 - val_loss: 5.2481 - val_categorical_accuracy: 0.4383\n",
      "Epoch 149/200\n",
      "40000/40000 [==============================] - 6s 159us/step - loss: 5.3642e-04 - categorical_accuracy: 1.0000 - val_loss: 5.2665 - val_categorical_accuracy: 0.4391\n",
      "Epoch 150/200\n",
      "40000/40000 [==============================] - 6s 159us/step - loss: 4.9511e-04 - categorical_accuracy: 1.0000 - val_loss: 5.2892 - val_categorical_accuracy: 0.4375\n",
      "Epoch 151/200\n",
      "40000/40000 [==============================] - 6s 158us/step - loss: 4.6006e-04 - categorical_accuracy: 1.0000 - val_loss: 5.3006 - val_categorical_accuracy: 0.4383\n",
      "Epoch 152/200\n",
      "40000/40000 [==============================] - 6s 157us/step - loss: 4.2531e-04 - categorical_accuracy: 1.0000 - val_loss: 5.3113 - val_categorical_accuracy: 0.4376\n",
      "Epoch 153/200\n",
      "40000/40000 [==============================] - 6s 158us/step - loss: 3.9889e-04 - categorical_accuracy: 1.0000 - val_loss: 5.3272 - val_categorical_accuracy: 0.4382\n",
      "Epoch 154/200\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 3.7423e-04 - categorical_accuracy: 1.0000 - val_loss: 5.3375 - val_categorical_accuracy: 0.4379\n",
      "Epoch 155/200\n",
      "40000/40000 [==============================] - 6s 159us/step - loss: 3.5687e-04 - categorical_accuracy: 1.0000 - val_loss: 5.3497 - val_categorical_accuracy: 0.4383\n",
      "Epoch 156/200\n",
      "40000/40000 [==============================] - 6s 158us/step - loss: 3.3810e-04 - categorical_accuracy: 1.0000 - val_loss: 5.3595 - val_categorical_accuracy: 0.4374\n",
      "Epoch 157/200\n",
      "40000/40000 [==============================] - 6s 159us/step - loss: 3.2138e-04 - categorical_accuracy: 1.0000 - val_loss: 5.3733 - val_categorical_accuracy: 0.4380\n",
      "Epoch 158/200\n",
      "40000/40000 [==============================] - 6s 158us/step - loss: 3.0754e-04 - categorical_accuracy: 1.0000 - val_loss: 5.3777 - val_categorical_accuracy: 0.4373\n",
      "Epoch 159/200\n",
      "40000/40000 [==============================] - 6s 158us/step - loss: 2.9501e-04 - categorical_accuracy: 1.0000 - val_loss: 5.3879 - val_categorical_accuracy: 0.4376\n",
      "Epoch 160/200\n",
      "40000/40000 [==============================] - 6s 157us/step - loss: 2.8384e-04 - categorical_accuracy: 1.0000 - val_loss: 5.3965 - val_categorical_accuracy: 0.4376\n",
      "Epoch 161/200\n",
      "40000/40000 [==============================] - 6s 159us/step - loss: 2.7042e-04 - categorical_accuracy: 1.0000 - val_loss: 5.4087 - val_categorical_accuracy: 0.4377\n",
      "Epoch 162/200\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 2.5999e-04 - categorical_accuracy: 1.0000 - val_loss: 5.4109 - val_categorical_accuracy: 0.4385\n",
      "Epoch 163/200\n",
      "40000/40000 [==============================] - 6s 162us/step - loss: 2.5144e-04 - categorical_accuracy: 1.0000 - val_loss: 5.4201 - val_categorical_accuracy: 0.4382\n",
      "Epoch 164/200\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 2.4439e-04 - categorical_accuracy: 1.0000 - val_loss: 5.4285 - val_categorical_accuracy: 0.4386\n",
      "Epoch 165/200\n",
      "40000/40000 [==============================] - 6s 161us/step - loss: 2.3607e-04 - categorical_accuracy: 1.0000 - val_loss: 5.4342 - val_categorical_accuracy: 0.4385\n",
      "Epoch 166/200\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 2.2841e-04 - categorical_accuracy: 1.0000 - val_loss: 5.4414 - val_categorical_accuracy: 0.4389\n",
      "Epoch 167/200\n",
      "40000/40000 [==============================] - 6s 162us/step - loss: 2.2114e-04 - categorical_accuracy: 1.0000 - val_loss: 5.4447 - val_categorical_accuracy: 0.4385\n",
      "Epoch 168/200\n",
      "40000/40000 [==============================] - 6s 159us/step - loss: 2.1564e-04 - categorical_accuracy: 1.0000 - val_loss: 5.4497 - val_categorical_accuracy: 0.4389\n",
      "Epoch 169/200\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 2.0876e-04 - categorical_accuracy: 1.0000 - val_loss: 5.4586 - val_categorical_accuracy: 0.4390\n",
      "Epoch 170/200\n",
      "40000/40000 [==============================] - 6s 158us/step - loss: 2.0409e-04 - categorical_accuracy: 1.0000 - val_loss: 5.4639 - val_categorical_accuracy: 0.4386\n",
      "Epoch 171/200\n",
      "40000/40000 [==============================] - 6s 161us/step - loss: 1.9842e-04 - categorical_accuracy: 1.0000 - val_loss: 5.4706 - val_categorical_accuracy: 0.4390\n",
      "Epoch 172/200\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 1.9361e-04 - categorical_accuracy: 1.0000 - val_loss: 5.4757 - val_categorical_accuracy: 0.4389\n",
      "Epoch 173/200\n",
      "40000/40000 [==============================] - 7s 187us/step - loss: 1.8865e-04 - categorical_accuracy: 1.0000 - val_loss: 5.4807 - val_categorical_accuracy: 0.4390\n",
      "Epoch 174/200\n",
      "40000/40000 [==============================] - 7s 167us/step - loss: 1.8399e-04 - categorical_accuracy: 1.0000 - val_loss: 5.4844 - val_categorical_accuracy: 0.4388\n",
      "Epoch 175/200\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 1.7976e-04 - categorical_accuracy: 1.0000 - val_loss: 5.4889 - val_categorical_accuracy: 0.4386\n",
      "Epoch 176/200\n",
      "40000/40000 [==============================] - 6s 161us/step - loss: 1.7536e-04 - categorical_accuracy: 1.0000 - val_loss: 5.4952 - val_categorical_accuracy: 0.4390\n",
      "Epoch 177/200\n",
      "40000/40000 [==============================] - 6s 156us/step - loss: 1.7145e-04 - categorical_accuracy: 1.0000 - val_loss: 5.4989 - val_categorical_accuracy: 0.4387\n",
      "Epoch 178/200\n",
      "40000/40000 [==============================] - 6s 158us/step - loss: 1.6786e-04 - categorical_accuracy: 1.0000 - val_loss: 5.5045 - val_categorical_accuracy: 0.4393\n",
      "Epoch 179/200\n",
      "40000/40000 [==============================] - 6s 157us/step - loss: 1.6440e-04 - categorical_accuracy: 1.0000 - val_loss: 5.5079 - val_categorical_accuracy: 0.4385\n",
      "Epoch 180/200\n",
      "40000/40000 [==============================] - 6s 158us/step - loss: 1.6056e-04 - categorical_accuracy: 1.0000 - val_loss: 5.5145 - val_categorical_accuracy: 0.4389\n",
      "Epoch 181/200\n",
      "40000/40000 [==============================] - 6s 157us/step - loss: 1.5776e-04 - categorical_accuracy: 1.0000 - val_loss: 5.5176 - val_categorical_accuracy: 0.4404\n",
      "Epoch 182/200\n",
      "40000/40000 [==============================] - 6s 158us/step - loss: 1.5444e-04 - categorical_accuracy: 1.0000 - val_loss: 5.5211 - val_categorical_accuracy: 0.4395\n",
      "Epoch 183/200\n",
      "40000/40000 [==============================] - 6s 157us/step - loss: 1.5109e-04 - categorical_accuracy: 1.0000 - val_loss: 5.5253 - val_categorical_accuracy: 0.4394\n",
      "Epoch 184/200\n",
      "40000/40000 [==============================] - 6s 159us/step - loss: 1.4814e-04 - categorical_accuracy: 1.0000 - val_loss: 5.5273 - val_categorical_accuracy: 0.4393\n",
      "Epoch 185/200\n",
      "40000/40000 [==============================] - 6s 157us/step - loss: 1.4602e-04 - categorical_accuracy: 1.0000 - val_loss: 5.5342 - val_categorical_accuracy: 0.4401\n",
      "Epoch 186/200\n",
      "40000/40000 [==============================] - 7s 164us/step - loss: 1.4304e-04 - categorical_accuracy: 1.0000 - val_loss: 5.5364 - val_categorical_accuracy: 0.4391\n",
      "Epoch 187/200\n",
      "40000/40000 [==============================] - 6s 157us/step - loss: 1.4087e-04 - categorical_accuracy: 1.0000 - val_loss: 5.5394 - val_categorical_accuracy: 0.4397\n",
      "Epoch 188/200\n",
      "40000/40000 [==============================] - 7s 163us/step - loss: 1.3798e-04 - categorical_accuracy: 1.0000 - val_loss: 5.5447 - val_categorical_accuracy: 0.4396\n",
      "Epoch 189/200\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 1.3557e-04 - categorical_accuracy: 1.0000 - val_loss: 5.5468 - val_categorical_accuracy: 0.4399\n",
      "Epoch 190/200\n",
      "40000/40000 [==============================] - 6s 158us/step - loss: 1.3336e-04 - categorical_accuracy: 1.0000 - val_loss: 5.5517 - val_categorical_accuracy: 0.4396\n",
      "Epoch 191/200\n",
      "40000/40000 [==============================] - 6s 159us/step - loss: 1.3122e-04 - categorical_accuracy: 1.0000 - val_loss: 5.5545 - val_categorical_accuracy: 0.4389\n",
      "Epoch 192/200\n",
      "40000/40000 [==============================] - 6s 159us/step - loss: 1.2922e-04 - categorical_accuracy: 1.0000 - val_loss: 5.5588 - val_categorical_accuracy: 0.4393\n",
      "Epoch 193/200\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 1.2675e-04 - categorical_accuracy: 1.0000 - val_loss: 5.5615 - val_categorical_accuracy: 0.4392\n",
      "Epoch 194/200\n",
      "40000/40000 [==============================] - 6s 159us/step - loss: 1.2509e-04 - categorical_accuracy: 1.0000 - val_loss: 5.5633 - val_categorical_accuracy: 0.4391\n",
      "Epoch 195/200\n",
      "40000/40000 [==============================] - 6s 158us/step - loss: 1.2304e-04 - categorical_accuracy: 1.0000 - val_loss: 5.5665 - val_categorical_accuracy: 0.4404\n",
      "Epoch 196/200\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 1.2109e-04 - categorical_accuracy: 1.0000 - val_loss: 5.5711 - val_categorical_accuracy: 0.4403\n",
      "Epoch 197/200\n",
      "40000/40000 [==============================] - 6s 157us/step - loss: 1.1941e-04 - categorical_accuracy: 1.0000 - val_loss: 5.5730 - val_categorical_accuracy: 0.4406\n",
      "Epoch 198/200\n",
      "40000/40000 [==============================] - 6s 159us/step - loss: 1.1736e-04 - categorical_accuracy: 1.0000 - val_loss: 5.5766 - val_categorical_accuracy: 0.4399\n",
      "Epoch 199/200\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 1.1583e-04 - categorical_accuracy: 1.0000 - val_loss: 5.5806 - val_categorical_accuracy: 0.4398\n",
      "Epoch 200/200\n",
      "40000/40000 [==============================] - 6s 159us/step - loss: 1.1441e-04 - categorical_accuracy: 1.0000 - val_loss: 5.5813 - val_categorical_accuracy: 0.4397\n",
      "10000/10000 [==============================] - 0s 39us/step\n",
      "Test score: 5.68238842086792\n",
      "Test accuracy: 0.4358\n"
     ]
    }
   ],
   "source": [
    "modelDNN = Sequential()\n",
    "modelDNN.add(Dense(128, input_shape=(1024,)))\n",
    "modelDNN.add(Activation('relu'))\n",
    "modelDNN.add(Dense(256))\n",
    "modelDNN.add(Activation('relu'))\n",
    "modelDNN.add(Dense(512))\n",
    "modelDNN.add(Activation('relu'))\n",
    "modelDNN.add(Dense(256))\n",
    "modelDNN.add(Activation('relu'))\n",
    "modelDNN.add(Dense(128))\n",
    "modelDNN.add(Activation('relu'))\n",
    "modelDNN.add(Dense(10))\n",
    "modelDNN.add(Activation('softmax'))\n",
    "modelDNN.summary()\n",
    "modelDNN.compile(loss='categorical_crossentropy', optimizer=SGD(), metrics=['categorical_accuracy'])\n",
    "\n",
    "from keras.utils import plot_model\n",
    "plot_model(modelDNN, show_shapes='true', to_file='figs/model.png')\n",
    "\n",
    "epochs_DNN = 200\n",
    "batch_size_DNN = 25\n",
    "\n",
    "history_DNN = modelDNN.fit(x_trainNN, y_trainNN,\n",
    "batch_size=batch_size_DNN, epochs=epochs_DNN,\n",
    "verbose=1, validation_split=0.2)\n",
    "\n",
    "score = modelDNN.evaluate(x_testNN, y_testNN, verbose=1)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN MODELS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model 1: Color Images\n",
    "##      >> Accuracy is at .57 after 5 epochs\n",
    "#### Much of code adapted from https://keras.io/examples/cifar10_cnn/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After browsing around the internet, it seemed like most people recommend a batch size of 25 to 32. Going with the batch size of 25, I ran 5 epochs of a color RGB  image and 5 epochs of an grayscale image to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "WARNING:tensorflow:From C:\\Users\\Adam\\Anaconda\\envs\\DeepLearningEnv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Adam\\Anaconda\\envs\\DeepLearningEnv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "from math import ceil\n",
    "\n",
    "###########################################\n",
    "batch_size = 25\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "###########################################\n",
    "\n",
    "# The data, split between train and test sets:\n",
    "(x_trainCNN1, y_trainCNN1), (x_testCNN1, y_testCNN1) = cifar10.load_data()\n",
    "print('x_train shape:', x_trainCNN1.shape)\n",
    "print(x_trainCNN1.shape[0], 'train samples')\n",
    "print(x_testCNN1.shape[0], 'test samples')\n",
    "x_trainCNN1 = x_trainCNN1.astype('float32')\n",
    "x_testCNN1 = x_testCNN1.astype('float32')\n",
    "x_trainCNN1 /= 255\n",
    "x_testCNN1 /= 255\n",
    "y_trainCNN1 = keras.utils.to_categorical(y_trainCNN1, num_classes)\n",
    "y_testCNN1 = keras.utils.to_categorical(y_testCNN1, num_classes)\n",
    "n_points = len(x_trainCNN1)\n",
    "steps_per_epoch = ceil(n_points / batch_size)\n",
    "\n",
    "modelCNN1 = Sequential()\n",
    "modelCNN1.add(Conv2D(32, (3, 3), padding='same',input_shape=x_trainCNN1.shape[1:]))\n",
    "modelCNN1.add(Activation('relu'))\n",
    "modelCNN1.add(Conv2D(32, (3, 3)))\n",
    "modelCNN1.add(Activation('relu'))\n",
    "modelCNN1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "modelCNN1.add(Dropout(0.25))\n",
    "\n",
    "modelCNN1.add(Conv2D(64, (3, 3), padding='same'))\n",
    "modelCNN1.add(Activation('relu'))\n",
    "modelCNN1.add(Conv2D(64, (3, 3)))\n",
    "modelCNN1.add(Activation('relu'))\n",
    "modelCNN1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "modelCNN1.add(Dropout(0.25))\n",
    "\n",
    "modelCNN1.add(Flatten())\n",
    "modelCNN1.add(Dense(512))\n",
    "modelCNN1.add(Activation('relu'))\n",
    "modelCNN1.add(Dropout(0.5))\n",
    "modelCNN1.add(Dense(num_classes))\n",
    "modelCNN1.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "modelCNN1.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 321s 161ms/step - loss: 1.8604 - acc: 0.3132 - val_loss: 1.6037 - val_acc: 0.4151\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 204s 102ms/step - loss: 1.5448 - acc: 0.4395 - val_loss: 1.3353 - val_acc: 0.5180\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 204s 102ms/step - loss: 1.4219 - acc: 0.4875 - val_loss: 1.4169 - val_acc: 0.4967\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 189s 95ms/step - loss: 1.3402 - acc: 0.5208 - val_loss: 1.2366 - val_acc: 0.5550\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 188s 94ms/step - loss: 1.2732 - acc: 0.5464 - val_loss: 1.2101 - val_acc: 0.5727\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 188s 94ms/step - loss: 1.2157 - acc: 0.5698 - val_loss: 1.0493 - val_acc: 0.6289\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 1045s 522ms/step - loss: 1.1794 - acc: 0.5839 - val_loss: 1.0919 - val_acc: 0.6100\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 205s 102ms/step - loss: 1.1324 - acc: 0.6003 - val_loss: 1.0767 - val_acc: 0.6244\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 204s 102ms/step - loss: 1.0953 - acc: 0.6131 - val_loss: 0.9390 - val_acc: 0.6683\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 204s 102ms/step - loss: 1.0667 - acc: 0.6255 - val_loss: 0.9604 - val_acc: 0.6646\n",
      "10000/10000 [==============================] - 8s 753us/step\n",
      "Test loss: 0.9603808615684509\n",
      "Test accuracy: 0.6646\n"
     ]
    }
   ],
   "source": [
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    modelCNN1.fit(x_trainCNN1, y_trainCNN1,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_testCNN1, y_testCNN1),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        # randomly shift images horizontally (fraction of total width)\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically (fraction of total height)\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.,  # set range for random shear\n",
    "        zoom_range=0.,  # set range for random zoom\n",
    "        channel_shift_range=0.,  # set range for random channel shifts\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,  # value used for fill_mode = \"constant\"\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,  # randomly flip images\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_trainCNN1)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    modelCNN1.fit_generator(datagen.flow(x_trainCNN1, y_trainCNN1,\n",
    "                                     batch_size=batch_size),\n",
    "                        epochs=epochs, steps_per_epoch=steps_per_epoch,\n",
    "                        validation_data=(x_testCNN1, y_testCNN1),\n",
    "                        workers=4)\n",
    "\n",
    "    # Score trained model.\n",
    "scores = modelCNN1.evaluate(x_testCNN1, y_testCNN1, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model 2: Grayscale Images\n",
    "##      >> Accuracy maxes out at ~0.71 with a batch size of 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grayscale seemed to hold the most promise for improving accuracy the fastest, so I proceded to run a model like we did in class for 30 epochs and a batch size of 50, just to experiment. It seems like the batch size of 25 is inded the correct way to go as it increases accuracy faster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "from math import ceil\n",
    "\n",
    "###########################################\n",
    "batch_size = 25\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "input_shape_CNN2 = (32, 32, 1)\n",
    "###########################################\n",
    "\n",
    "# The data, split between train and test sets:\n",
    "(x_trainCNN2, y_trainCNN2), (x_testCNN2, y_testCNN2) = cifar10.load_data()\n",
    "x_trainCNN2 = rgb2gray(x_trainCNN2)\n",
    "x_testCNN2 = rgb2gray(x_testCNN2)\n",
    "print('x_train shape:', x_trainCNN2.shape)\n",
    "print(x_trainCNN2.shape[0], 'train samples')\n",
    "print(x_testCNN2.shape[0], 'test samples')\n",
    "x_trainCNN2 = x_trainCNN2.astype('float32')\n",
    "x_testCNN2 = x_testCNN2.astype('float32')\n",
    "x_trainCNN2 = x_trainCNN2[:, :, :, np.newaxis]\n",
    "x_testCNN2 = x_testCNN2[:, :, :, np.newaxis]\n",
    "\n",
    "#x_trainCNN2 /= 255  #######already normalized grayscale\n",
    "#x_testCNN2 /= 255  #######already normalized grayscale\n",
    "\n",
    "y_trainCNN2 = keras.utils.to_categorical(y_trainCNN2, num_classes)\n",
    "y_testCNN2 = keras.utils.to_categorical(y_testCNN2, num_classes)\n",
    "n_points = len(x_trainCNN2)\n",
    "steps_per_epoch = ceil(n_points / batch_size)\n",
    "\n",
    "modelCNN2 = Sequential()\n",
    "modelCNN2.add(Conv2D(32, (3, 3), padding='same', input_shape = input_shape_CNN2))\n",
    "modelCNN2.add(Activation('relu'))\n",
    "modelCNN2.add(Conv2D(32, (3, 3)))\n",
    "modelCNN2.add(Activation('relu'))\n",
    "modelCNN2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "modelCNN2.add(Dropout(0.25))\n",
    "\n",
    "modelCNN2.add(Conv2D(64, (3, 3), padding='same'))\n",
    "modelCNN2.add(Activation('relu'))\n",
    "modelCNN2.add(Conv2D(64, (3, 3)))\n",
    "modelCNN2.add(Activation('relu'))\n",
    "modelCNN2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "modelCNN2.add(Dropout(0.25))\n",
    "\n",
    "modelCNN2.add(Flatten())\n",
    "modelCNN2.add(Dense(512))\n",
    "modelCNN2.add(Activation('relu'))\n",
    "modelCNN2.add(Dropout(0.5))\n",
    "modelCNN2.add(Dense(num_classes))\n",
    "modelCNN2.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "modelCNN2.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 186s 93ms/step - loss: 1.3888 - acc: 0.5125 - val_loss: 1.2445 - val_acc: 0.5608\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 195s 97ms/step - loss: 1.3358 - acc: 0.5337 - val_loss: 1.2217 - val_acc: 0.5721\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 195s 98ms/step - loss: 1.2856 - acc: 0.5536 - val_loss: 1.1817 - val_acc: 0.5840\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 196s 98ms/step - loss: 1.2420 - acc: 0.5652 - val_loss: 1.1079 - val_acc: 0.6073\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 199s 100ms/step - loss: 1.2025 - acc: 0.5785 - val_loss: 1.0892 - val_acc: 0.6152\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 198s 99ms/step - loss: 1.1741 - acc: 0.5927 - val_loss: 1.0627 - val_acc: 0.6270\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 200s 100ms/step - loss: 1.1481 - acc: 0.6034 - val_loss: 1.0122 - val_acc: 0.6462\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 192s 96ms/step - loss: 1.1257 - acc: 0.6104 - val_loss: 1.0006 - val_acc: 0.6493\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 201s 101ms/step - loss: 1.1037 - acc: 0.6171 - val_loss: 1.0008 - val_acc: 0.6474\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 195s 98ms/step - loss: 1.0820 - acc: 0.6267 - val_loss: 0.9749 - val_acc: 0.6630\n",
      "10000/10000 [==============================] - 7s 712us/step\n",
      "Test loss: 0.9748614967346192\n",
      "Test accuracy: 0.663\n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "batch_size = 25\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "n_points = len(x_trainCNN2)\n",
    "steps_per_epoch = ceil(n_points / batch_size)\n",
    "###########################################\n",
    "\n",
    "# Grayscale Option 2\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    modelCNN2.fit(x_trainCNN2, y_trainCNN2,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_testCNN2, y_testCNN2),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        # randomly shift images horizontally (fraction of total width)\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically (fraction of total height)\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.,  # set range for random shear\n",
    "        zoom_range=0.,  # set range for random zoom\n",
    "        channel_shift_range=0.,  # set range for random channel shifts\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,  # value used for fill_mode = \"constant\"\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,  # randomly flip images\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_trainCNN2)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    modelCNN2.fit_generator(datagen.flow(x_trainCNN2, y_trainCNN2,\n",
    "                                     batch_size=batch_size),\n",
    "                        epochs=epochs, steps_per_epoch=steps_per_epoch,\n",
    "                        validation_data=(x_testCNN2, y_testCNN2),\n",
    "                        workers=4)\n",
    "\n",
    "# Score trained model.\n",
    "scores = modelCNN2.evaluate(x_testCNN2, y_testCNN2, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After the results from the RGB and grayscale image adapted from Kera's code, I decided to run a model with 10 epochs as we had constructed from class. On initial testing, this model ran significantly faster than Keras's provided model (145 sec/epoch compared to 190 sec/epoch, respectively), so I ran 10 epochs to compare the accuracy. The accuracy was 0.676, beating out the Keras model by 1%. That's nothing to write home about, but since our model was so much faster, I followed these 10 epochs by an additional run of 30 epochs to see how much the model could improve. After these 30 epochs, the modle improved to an accuracy of  ~0.757 on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "from math import ceil\n",
    "\n",
    "###########################################\n",
    "batch_size = 25\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "###########################################\n",
    "\n",
    "# The data, split between train and test sets:\n",
    "(x_trainCNN1, y_trainCNN1), (x_testCNN1, y_testCNN1) = cifar10.load_data()\n",
    "print('x_train shape:', x_trainCNN1.shape)\n",
    "print(x_trainCNN1.shape[0], 'train samples')\n",
    "print(x_testCNN1.shape[0], 'test samples')\n",
    "x_trainCNN1 = x_trainCNN1.astype('float32')\n",
    "x_testCNN1 = x_testCNN1.astype('float32')\n",
    "x_trainCNN1 /= 255\n",
    "x_testCNN1 /= 255\n",
    "y_trainCNN1 = keras.utils.to_categorical(y_trainCNN1, num_classes)\n",
    "y_testCNN1 = keras.utils.to_categorical(y_testCNN1, num_classes)\n",
    "n_points = len(x_trainCNN1)\n",
    "steps_per_epoch = ceil(n_points / batch_size)\n",
    "\n",
    "modelCNN3 = Sequential()\n",
    "modelCNN3.add(Conv2D(32, (3, 3), padding='same',input_shape=x_trainCNN1.shape[1:]))\n",
    "modelCNN3.add(Activation('relu'))\n",
    "modelCNN3.add(Conv2D(32, (3, 3)))\n",
    "modelCNN3.add(Activation('relu'))\n",
    "modelCNN3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "modelCNN3.add(Dropout(0.25))\n",
    "\n",
    "modelCNN3.add(Conv2D(64, (3, 3), padding='same'))\n",
    "modelCNN3.add(Activation('relu'))\n",
    "modelCNN3.add(Conv2D(64, (3, 3)))\n",
    "modelCNN3.add(Activation('relu'))\n",
    "modelCNN3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "modelCNN3.add(Dropout(0.25))\n",
    "\n",
    "modelCNN3.add(Flatten())\n",
    "modelCNN3.add(Dense(512))\n",
    "modelCNN3.add(Activation('relu'))\n",
    "modelCNN3.add(Dropout(0.5))\n",
    "modelCNN3.add(Dense(num_classes))\n",
    "modelCNN3.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "modelCNN3.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "40000/40000 [==============================] - 146s 4ms/step - loss: 1.8303 - acc: 0.3250 - val_loss: 1.5724 - val_acc: 0.4360\n",
      "Epoch 2/10\n",
      "40000/40000 [==============================] - 151s 4ms/step - loss: 1.5100 - acc: 0.4538 - val_loss: 1.4013 - val_acc: 0.4932\n",
      "Epoch 3/10\n",
      "40000/40000 [==============================] - 144s 4ms/step - loss: 1.3700 - acc: 0.5091 - val_loss: 1.2652 - val_acc: 0.5533\n",
      "Epoch 4/10\n",
      "40000/40000 [==============================] - 148s 4ms/step - loss: 1.2702 - acc: 0.5478 - val_loss: 1.2031 - val_acc: 0.5779\n",
      "Epoch 5/10\n",
      "40000/40000 [==============================] - 153s 4ms/step - loss: 1.1921 - acc: 0.5788 - val_loss: 1.1201 - val_acc: 0.6055\n",
      "Epoch 6/10\n",
      "40000/40000 [==============================] - 143s 4ms/step - loss: 1.1319 - acc: 0.5996 - val_loss: 1.0397 - val_acc: 0.6338\n",
      "Epoch 7/10\n",
      "40000/40000 [==============================] - 148s 4ms/step - loss: 1.0814 - acc: 0.6194 - val_loss: 1.0197 - val_acc: 0.6414\n",
      "Epoch 8/10\n",
      "40000/40000 [==============================] - 144s 4ms/step - loss: 1.0422 - acc: 0.6345 - val_loss: 0.9622 - val_acc: 0.6637\n",
      "Epoch 9/10\n",
      "40000/40000 [==============================] - 144s 4ms/step - loss: 1.0045 - acc: 0.6481 - val_loss: 0.9257 - val_acc: 0.6755\n",
      "Epoch 10/10\n",
      "40000/40000 [==============================] - 154s 4ms/step - loss: 0.9767 - acc: 0.6565 - val_loss: 0.9140 - val_acc: 0.6818\n",
      "10000/10000 [==============================] - 8s 772us/step\n",
      "Test loss: 0.9218592031478882\n",
      "Test accuracy: 0.6759\n"
     ]
    }
   ],
   "source": [
    "history = modelCNN3.fit(x_trainCNN1, y_trainCNN1, batch_size=25, epochs=10,verbose=1, validation_split=0.2)\n",
    "\n",
    "# Score trained model.\n",
    "scores = modelCNN3.evaluate(x_testCNN1, y_testCNN1, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelCNN4 = Sequential()\n",
    "modelCNN4.add(Conv2D(32, (3, 3), padding='same',input_shape=x_trainCNN1.shape[1:]))\n",
    "modelCNN4.add(Activation('relu'))\n",
    "modelCNN4.add(Conv2D(32, (3, 3)))\n",
    "modelCNN4.add(Activation('relu'))\n",
    "modelCNN4.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "modelCNN4.add(Dropout(0.25))\n",
    "\n",
    "modelCNN4.add(Conv2D(64, (3, 3), padding='same'))\n",
    "modelCNN4.add(Activation('relu'))\n",
    "modelCNN4.add(Conv2D(64, (3, 3)))\n",
    "modelCNN4.add(Activation('relu'))\n",
    "modelCNN4.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "modelCNN4.add(Dropout(0.25))\n",
    "\n",
    "modelCNN4.add(Flatten())\n",
    "modelCNN4.add(Dense(512))\n",
    "modelCNN4.add(Activation('relu'))\n",
    "modelCNN4.add(Dropout(0.5))\n",
    "modelCNN4.add(Dense(num_classes))\n",
    "modelCNN4.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "modelCNN4.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 147s 4ms/step - loss: 1.8389 - acc: 0.3293 - val_loss: 1.6203 - val_acc: 0.4145\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 161s 4ms/step - loss: 1.5235 - acc: 0.4518 - val_loss: 1.3761 - val_acc: 0.5130\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 175s 4ms/step - loss: 1.3852 - acc: 0.5064 - val_loss: 1.2700 - val_acc: 0.5575\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 159s 4ms/step - loss: 1.2845 - acc: 0.5450 - val_loss: 1.1872 - val_acc: 0.5811\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 158s 4ms/step - loss: 1.2019 - acc: 0.5742 - val_loss: 1.1263 - val_acc: 0.6048\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 156s 4ms/step - loss: 1.1371 - acc: 0.5986 - val_loss: 1.1010 - val_acc: 0.6088\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 153s 4ms/step - loss: 1.0770 - acc: 0.6192 - val_loss: 1.0318 - val_acc: 0.6317\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 157s 4ms/step - loss: 1.0315 - acc: 0.6397 - val_loss: 0.9699 - val_acc: 0.6578\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 154s 4ms/step - loss: 0.9924 - acc: 0.6525 - val_loss: 0.9391 - val_acc: 0.6726\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 144s 4ms/step - loss: 0.9575 - acc: 0.6678 - val_loss: 0.9018 - val_acc: 0.6767\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 147s 4ms/step - loss: 0.9256 - acc: 0.6765 - val_loss: 0.8589 - val_acc: 0.6990\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 145s 4ms/step - loss: 0.8984 - acc: 0.6874 - val_loss: 0.8539 - val_acc: 0.6981\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 149s 4ms/step - loss: 0.8755 - acc: 0.6986 - val_loss: 0.8734 - val_acc: 0.6977\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 153s 4ms/step - loss: 0.8561 - acc: 0.7038 - val_loss: 0.8035 - val_acc: 0.7220\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 143s 4ms/step - loss: 0.8347 - acc: 0.7092 - val_loss: 0.8148 - val_acc: 0.7199\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 145s 4ms/step - loss: 0.8191 - acc: 0.7178 - val_loss: 0.7920 - val_acc: 0.7232\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 149s 4ms/step - loss: 0.8091 - acc: 0.7220 - val_loss: 0.7651 - val_acc: 0.7361\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 157s 4ms/step - loss: 0.7917 - acc: 0.7271 - val_loss: 0.8026 - val_acc: 0.7211\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 147s 4ms/step - loss: 0.7813 - acc: 0.7324 - val_loss: 0.7442 - val_acc: 0.7406\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 145s 4ms/step - loss: 0.7699 - acc: 0.7363 - val_loss: 0.7816 - val_acc: 0.7290\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 147s 4ms/step - loss: 0.7592 - acc: 0.7382 - val_loss: 0.7257 - val_acc: 0.7483\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 150s 4ms/step - loss: 0.7556 - acc: 0.7404 - val_loss: 0.7392 - val_acc: 0.7443\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 147s 4ms/step - loss: 0.7420 - acc: 0.7470 - val_loss: 0.7456 - val_acc: 0.7442\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 163s 4ms/step - loss: 0.7373 - acc: 0.7464 - val_loss: 0.7144 - val_acc: 0.7509\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 159s 4ms/step - loss: 0.7303 - acc: 0.7510 - val_loss: 0.7276 - val_acc: 0.7536\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 165s 4ms/step - loss: 0.7240 - acc: 0.7515 - val_loss: 0.7428 - val_acc: 0.7548\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 167s 4ms/step - loss: 0.7165 - acc: 0.7568 - val_loss: 0.7218 - val_acc: 0.7594\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 154s 4ms/step - loss: 0.7151 - acc: 0.7576 - val_loss: 0.7037 - val_acc: 0.7564\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 148s 4ms/step - loss: 0.7104 - acc: 0.7589 - val_loss: 0.6972 - val_acc: 0.7640\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 147s 4ms/step - loss: 0.7073 - acc: 0.7586 - val_loss: 0.7016 - val_acc: 0.7603\n",
      "10000/10000 [==============================] - 8s 764us/step\n",
      "Test loss: 0.7161954689979553\n",
      "Test accuracy: 0.7567\n"
     ]
    }
   ],
   "source": [
    "history = modelCNN4.fit(x_trainCNN1, y_trainCNN1, batch_size=25, epochs=30,verbose=1, validation_split=0.2)\n",
    "\n",
    "# Score trained model.\n",
    "scores = modelCNN4.evaluate(x_testCNN1, y_testCNN1, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
