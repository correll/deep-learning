{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beyond Images: Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have almost exclusively used images. We have classified them and we have generated them. How about text? At the end, a text is a time-series of ASCII characters, and we could surely train pattern detectors and generators on them. Grammar is a lot less forgiving then graphics, however, and a slightly different shade of gray that might go unobserved in an image, might make a text unreafable (unreadable). In some applications such as translation, text understanding or generation it might therefore make sense to rely on words, not characters, as the smallest digestible unit. A naive approach would be to create a dictionary in which words are represented by integer values. These in turn can be represented by one-hot encoding:\n",
    "\n",
    "- the   1 00000001\n",
    "- quick 2 00000010\n",
    "- brown 3 00000100\n",
    "- fox   4 00001000\n",
    "- jumps 5 00010000\n",
    "- over  6 00100000\n",
    "- lazy  7 01000000\n",
    "- dog   8 10000000\n",
    "\n",
    "This is costly, as vectors get very long. (Remember, softmax activation requires to sum over all outputs, e.g.) In particular, $N$-dimensional integers are turned into $N$ dimensional vector space.  \n",
    "\n",
    "One way to reduce the dimensionality of one-hot encoding would be to project data into a lower dimensional vector space. This is known as <i>embedding</i> and is a standard layer in Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embeddings\n",
    "\n",
    "In its most simplest form, embedding $N$ values into $M$-dimensional vectors could be done by generating $N$ random $M$-dimensional vectors. The embedding layer would simply serve as a look-up table. This can be seen in the keras code below. In our example, $N=8$ and $M=3$ would generate a 3-dimensional embedding. Here <code>input_length</code> refers to the number of integers that will be provided to the embedding layer at a time, here one integer results in three values, two integers into six and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding\n",
    "import numpy as np\n",
    "\n",
    "model = Sequential()\n",
    "embedding_layer = Embedding(input_dim=8, output_dim=3, input_length=1)\n",
    "model.add(embedding_layer)\n",
    "model.compile('adam', 'mse') # will need to provide an optimizer and loss, even though not used here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.03080323 -0.00436597 -0.03693813]]]\n",
      "[[[ 0.03868173 -0.04781219 -0.034648  ]]]\n",
      "[[[ 0.04200144 -0.04283803  0.00865404]]]\n",
      "[[[ 0.02593631 -0.02306879  0.02608968]]]\n",
      "[[[ 0.00375088 -0.01421449 -0.01163588]]]\n",
      "[[[-0.02737376 -0.00066825  0.02329269]]]\n",
      "[[[ 0.03849734  0.01492298 -0.01914817]]]\n",
      "[[[ 0.02770283 -0.03706833  0.02405379]]]\n"
     ]
    }
   ],
   "source": [
    "def print_embedding_weights():\n",
    "    for I in range(8):\n",
    "        input_data = np.array(I).reshape(1,1) # turn into one sample with one data point\n",
    "        #input_data = np.array([1,2]).reshape(1,2) # example for input length two\n",
    "\n",
    "        pred = model.predict(input_data)\n",
    "        print(pred)\n",
    "\n",
    "print_embedding_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that \"one-hot\" encoding can also be an embedding, allowing us to integrate the preprocessing step into the network itself. This can be seen when manually defining the weights of the embedding layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1. 0. 0. 0. 0. 0. 0. 0.]]]\n",
      "[[[0. 1. 0. 0. 0. 0. 0. 0.]]]\n",
      "[[[0. 0. 1. 0. 0. 0. 0. 0.]]]\n",
      "[[[0. 0. 0. 1. 0. 0. 0. 0.]]]\n",
      "[[[0. 0. 0. 0. 1. 0. 0. 0.]]]\n",
      "[[[0. 0. 0. 0. 0. 1. 0. 0.]]]\n",
      "[[[0. 0. 0. 0. 0. 0. 1. 0.]]]\n",
      "[[[0. 0. 0. 0. 0. 0. 0. 1.]]]\n"
     ]
    }
   ],
   "source": [
    "embedding_lookup = np.array([\n",
    "    [1,0,0,0,0,0,0,0],\n",
    "    [0,1,0,0,0,0,0,0],\n",
    "    [0,0,1,0,0,0,0,0],\n",
    "    [0,0,0,1,0,0,0,0],\n",
    "    [0,0,0,0,1,0,0,0],\n",
    "    [0,0,0,0,0,1,0,0],\n",
    "    [0,0,0,0,0,0,1,0],\n",
    "    [0,0,0,0,0,0,0,1],\n",
    "])\n",
    "\n",
    "model = Sequential()\n",
    "embedding_layer = Embedding(input_dim=8, output_dim=8, input_length=1)\n",
    "model.add(embedding_layer)\n",
    "model.compile('adam', 'mse')\n",
    "\n",
    "embedding_layer.set_weights([embedding_lookup])\n",
    "\n",
    "print_embedding_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear now how an array of words can be mapped to an integer number (the index into the array). We can also see how to find the index of any given vector. When using one-hot encoding, we use a softmax activation layer and then find the index that yields the highest entry in the softmax vector (arg max). When searching over vectors consisting of random numbers, this step is a little more involved, requiring us to find the vector with the least distance, for example using the cosine distance (dot product), given by\n",
    "\n",
    "$$  \\cos(\\theta)=\\frac{AB}{\\|A\\|\\|B\\|} $$\n",
    "\n",
    "for the vectors $A$ and $B$. When vectors are the same, the angle inbetween them is zero. If they are orthogonal, the angle is 90 degrees and they are very dissimilar. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vec\n",
    "\n",
    "Assuming we have a neural network that is able to generate words, the cosine distance will allow us finding the closest word in the dictionary. It would therefore be advantagous if the entire embedding would be organized so that closely related words would have similar distances. Having such a corpus would not allow representing texts in a lower dimensional space that can be processed by a standard neural network architecture, but also provide a natural way to capture different expressions that mean the same thing. Here, we can take advantage of the fact that embeddings can also be trained to minimize a loss function that is added to the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A technique that does this, is known as <i>word2vec</i>. Instead of manually annotating similarities between words and thinking up a coding scheme, we smartly design a neural network that generates the desired result - a $M$-dimensional vector that represents each one of $N$ words - as a side-effect of training an appropriate problem. In other words, we take advantage of the fact that dense neural networks automatically create internal representations that we can literally scoop off.\n",
    "\n",
    "One such a network, known as the <i>skip-gram</i> word2vec model, is a model that predicts words that could, or often are, surrounding another word. For example, the sentence\n",
    "\n",
    "<i>The quick brown fox jumps over the lazy dog</i>\n",
    "\n",
    "creates the following associations\n",
    "\n",
    "- the <-> quick\n",
    "- quick <-> brown\n",
    "- brown <-> fox\n",
    "- fox <-> jumps\n",
    "\n",
    "and so on. We can also train a classifier, that would tell us, whether one word is likely to be next to another by creating the following training set\n",
    "\n",
    "- ((The, quick),1)\n",
    "- ((quick, brown),1)\n",
    "- ((brown, fox),1)\n",
    "\n",
    "We would also need to create negative examples, for example by adding random words from this or another corpus:\n",
    "\n",
    "- ((quick, dog),0)\n",
    "- ((brown, dog), 0)\n",
    "- ((quick, zebra), 0)\n",
    "\n",
    "The goal is now to train a network so that words that are likely to follow each other get a high score (1), and words that are never in the same context get a very low score (0). One way to accomplish tis is to design a network that uses the <i>same</i> embedding to encode both word and context word. Words (word and context) are embedded into a 300-dimensional row vector and reshaped into a 300-dimensional column vector in parallel. A so-called <a href=\"https://keras.io/layers/merge/\">merge layer</a>, here the dot product, then normalizes the two data streams and combines them into a single scalar. The result is that the dot-product layer effectively compares input and context word.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_19 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_20 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1, 3)         30          input_19[0][0]                   \n",
      "                                                                 input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_23 (Reshape)            (None, 3, 1)         0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_24 (Reshape)            (None, 3, 1)         0           embedding[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_9 (Dot)                     (None, 1, 1)         0           reshape_23[0][0]                 \n",
      "                                                                 reshape_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_25 (Reshape)            (None, 1)            0           dot_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            2           reshape_25[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 32\n",
      "Trainable params: 32\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"611pt\" viewBox=\"0.00 0.00 433.51 458.00\" width=\"578pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1.3333 1.3333) rotate(0) translate(4 454)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-454 429.5107,-454 429.5107,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 5544422648 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>5544422648</title>\n",
       "<polygon fill=\"none\" points=\"0,-405.5 0,-449.5 203.5107,-449.5 203.5107,-405.5 0,-405.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"39.0967\" y=\"-423.3\">InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"78.1934,-405.5 78.1934,-449.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"106.0278\" y=\"-434.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"78.1934,-427.5 133.8623,-427.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"106.0278\" y=\"-412.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"133.8623,-405.5 133.8623,-449.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"168.6865\" y=\"-434.3\">(None, 1)</text>\n",
       "<polyline fill=\"none\" points=\"133.8623,-427.5 203.5107,-427.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"168.6865\" y=\"-412.3\">(None, 1)</text>\n",
       "</g>\n",
       "<!-- 5544422704 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>5544422704</title>\n",
       "<polygon fill=\"none\" points=\"102.8242,-324.5 102.8242,-368.5 322.6865,-368.5 322.6865,-324.5 102.8242,-324.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"143.0967\" y=\"-342.3\">Embedding</text>\n",
       "<polyline fill=\"none\" points=\"183.3691,-324.5 183.3691,-368.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211.2036\" y=\"-353.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"183.3691,-346.5 239.0381,-346.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211.2036\" y=\"-331.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"239.0381,-324.5 239.0381,-368.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"280.8623\" y=\"-353.3\">(None, 1)</text>\n",
       "<polyline fill=\"none\" points=\"239.0381,-346.5 322.6865,-346.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"280.8623\" y=\"-331.3\">(None, 1, 3)</text>\n",
       "</g>\n",
       "<!-- 5544422648&#45;&gt;5544422704 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>5544422648-&gt;5544422704</title>\n",
       "<path d=\"M132.0866,-405.3664C145.0569,-395.9016 160.3539,-384.7389 174.121,-374.6926\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"176.446,-377.3288 182.4608,-368.6068 172.3197,-371.6743 176.446,-377.3288\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5544422592 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>5544422592</title>\n",
       "<polygon fill=\"none\" points=\"222,-405.5 222,-449.5 425.5107,-449.5 425.5107,-405.5 222,-405.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"261.0967\" y=\"-423.3\">InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"300.1934,-405.5 300.1934,-449.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"328.0278\" y=\"-434.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"300.1934,-427.5 355.8623,-427.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"328.0278\" y=\"-412.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"355.8623,-405.5 355.8623,-449.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"390.6865\" y=\"-434.3\">(None, 1)</text>\n",
       "<polyline fill=\"none\" points=\"355.8623,-427.5 425.5107,-427.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"390.6865\" y=\"-412.3\">(None, 1)</text>\n",
       "</g>\n",
       "<!-- 5544422592&#45;&gt;5544422704 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>5544422592-&gt;5544422704</title>\n",
       "<path d=\"M293.4241,-405.3664C280.4538,-395.9016 265.1568,-384.7389 251.3897,-374.6926\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"253.191,-371.6743 243.0499,-368.6068 249.0647,-377.3288 253.191,-371.6743\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5544423152 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>5544423152</title>\n",
       "<polygon fill=\"none\" points=\"1.3828,-243.5 1.3828,-287.5 204.1279,-287.5 204.1279,-243.5 1.3828,-243.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"33.0967\" y=\"-261.3\">Reshape</text>\n",
       "<polyline fill=\"none\" points=\"64.8105,-243.5 64.8105,-287.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"92.645\" y=\"-272.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"64.8105,-265.5 120.4795,-265.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"92.645\" y=\"-250.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"120.4795,-243.5 120.4795,-287.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"162.3037\" y=\"-272.3\">(None, 1, 3)</text>\n",
       "<polyline fill=\"none\" points=\"120.4795,-265.5 204.1279,-265.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"162.3037\" y=\"-250.3\">(None, 3, 1)</text>\n",
       "</g>\n",
       "<!-- 5544422704&#45;&gt;5544423152 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>5544422704-&gt;5544423152</title>\n",
       "<path d=\"M182.6974,-324.3664C169.8439,-314.9016 154.6847,-303.7389 141.0417,-293.6926\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"142.9048,-290.718 132.777,-287.6068 138.7541,-296.3547 142.9048,-290.718\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5544423264 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>5544423264</title>\n",
       "<polygon fill=\"none\" points=\"222.3828,-243.5 222.3828,-287.5 425.1279,-287.5 425.1279,-243.5 222.3828,-243.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"254.0967\" y=\"-261.3\">Reshape</text>\n",
       "<polyline fill=\"none\" points=\"285.8105,-243.5 285.8105,-287.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"313.645\" y=\"-272.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"285.8105,-265.5 341.4795,-265.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"313.645\" y=\"-250.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"341.4795,-243.5 341.4795,-287.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"383.3037\" y=\"-272.3\">(None, 1, 3)</text>\n",
       "<polyline fill=\"none\" points=\"341.4795,-265.5 425.1279,-265.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"383.3037\" y=\"-250.3\">(None, 3, 1)</text>\n",
       "</g>\n",
       "<!-- 5544422704&#45;&gt;5544423264 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>5544422704-&gt;5544423264</title>\n",
       "<path d=\"M243.0866,-324.3664C256.0569,-314.9016 271.3539,-303.7389 285.121,-293.6926\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"287.446,-296.3288 293.4608,-287.6068 283.3197,-290.6743 287.446,-296.3288\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5544422872 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>5544422872</title>\n",
       "<polygon fill=\"none\" points=\"82.6104,-162.5 82.6104,-206.5 342.9004,-206.5 342.9004,-162.5 82.6104,-162.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"101.1104\" y=\"-180.3\">Dot</text>\n",
       "<polyline fill=\"none\" points=\"119.6104,-162.5 119.6104,-206.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"147.4448\" y=\"-191.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"119.6104,-184.5 175.2793,-184.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"147.4448\" y=\"-169.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"175.2793,-162.5 175.2793,-206.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"259.0898\" y=\"-191.3\">[(None, 3, 1), (None, 3, 1)]</text>\n",
       "<polyline fill=\"none\" points=\"175.2793,-184.5 342.9004,-184.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"258.6035\" y=\"-169.3\">(None, 1, 1)</text>\n",
       "</g>\n",
       "<!-- 5544423152&#45;&gt;5544422872 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>5544423152-&gt;5544422872</title>\n",
       "<path d=\"M132.8134,-243.3664C145.6668,-233.9016 160.826,-222.7389 174.4691,-212.6926\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"176.7567,-215.3547 182.7337,-206.6068 172.606,-209.718 176.7567,-215.3547\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5544423264&#45;&gt;5544422872 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>5544423264-&gt;5544422872</title>\n",
       "<path d=\"M293.4241,-243.3664C280.4538,-233.9016 265.1568,-222.7389 251.3897,-212.6926\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"253.191,-209.6743 243.0499,-206.6068 249.0647,-215.3288 253.191,-209.6743\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5544423040 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>5544423040</title>\n",
       "<polygon fill=\"none\" points=\"111.3828,-81.5 111.3828,-125.5 314.1279,-125.5 314.1279,-81.5 111.3828,-81.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"143.0967\" y=\"-99.3\">Reshape</text>\n",
       "<polyline fill=\"none\" points=\"174.8105,-81.5 174.8105,-125.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"202.645\" y=\"-110.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"174.8105,-103.5 230.4795,-103.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"202.645\" y=\"-88.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"230.4795,-81.5 230.4795,-125.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"272.3037\" y=\"-110.3\">(None, 1, 1)</text>\n",
       "<polyline fill=\"none\" points=\"230.4795,-103.5 314.1279,-103.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"272.3037\" y=\"-88.3\">(None, 1)</text>\n",
       "</g>\n",
       "<!-- 5544422872&#45;&gt;5544423040 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>5544422872-&gt;5544423040</title>\n",
       "<path d=\"M212.7554,-162.3664C212.7554,-154.1516 212.7554,-144.6579 212.7554,-135.7252\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"216.2555,-135.6068 212.7554,-125.6068 209.2555,-135.6069 216.2555,-135.6068\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5544423320 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>5544423320</title>\n",
       "<polygon fill=\"none\" points=\"124.6035,-.5 124.6035,-44.5 300.9072,-44.5 300.9072,-.5 124.6035,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"150.0967\" y=\"-18.3\">Dense</text>\n",
       "<polyline fill=\"none\" points=\"175.5898,-.5 175.5898,-44.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"203.4243\" y=\"-29.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"175.5898,-22.5 231.2588,-22.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"203.4243\" y=\"-7.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"231.2588,-.5 231.2588,-44.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"266.083\" y=\"-29.3\">(None, 1)</text>\n",
       "<polyline fill=\"none\" points=\"231.2588,-22.5 300.9072,-22.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"266.083\" y=\"-7.3\">(None, 1)</text>\n",
       "</g>\n",
       "<!-- 5544423040&#45;&gt;5544423320 -->\n",
       "<g class=\"edge\" id=\"edge8\">\n",
       "<title>5544423040-&gt;5544423320</title>\n",
       "<path d=\"M212.7554,-81.3664C212.7554,-73.1516 212.7554,-63.6579 212.7554,-54.7252\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"216.2555,-54.6068 212.7554,-44.6068 209.2555,-54.6069 216.2555,-54.6068\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 10\n",
    "embed_size = 3\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.core import Dense, Reshape\n",
    "from keras.layers import dot\n",
    "\n",
    "input_target = Input((1,))\n",
    "input_context = Input((1,))\n",
    "\n",
    "embedding = Embedding(vocab_size, embed_size, input_length=1, name='embedding') # Define Embedding() only once so that both word and context are using the same embedding. \n",
    "\n",
    "word_embedding = embedding(input_target)\n",
    "word_embedding = Reshape((embed_size, 1))(word_embedding)\n",
    "context_embedding = embedding(input_context)\n",
    "context_embedding = Reshape((embed_size, 1))(context_embedding)\n",
    "\n",
    "# now perform the dot product operation  \n",
    "dot_product = dot([word_embedding, context_embedding], axes=1, normalize=True)\n",
    "dot_product = Reshape((1,))(dot_product)\n",
    "\n",
    "# add the sigmoid output layer\n",
    "output = Dense(1, activation='sigmoid')(dot_product)\n",
    "\n",
    "model = Model(input=[input_target, input_context], output=output)\n",
    "model.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
    "\n",
    "# view model summary\n",
    "print(model.summary())\n",
    "\n",
    "# visualize model structure\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model, show_shapes=True, show_layer_names=False, \n",
    "                 rankdir='TB').create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model above will find an embedding in which words that are appearing next to another in a text are represented by vectors that have a smaller distance than vectors of words that never appear next to each other. In order to train such a model, we have to generate appropriate skipgrams for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pairs:  32\n",
      "(over (6), jumps (5)) -> 1\n",
      "(dog (8), lazy (7)) -> 1\n",
      "(brown (3), quick (2)) -> 1\n",
      "(lazy (7), dog (8)) -> 1\n",
      "(the (1), over (6)) -> 1\n",
      "(the (1), quick (2)) -> 0\n",
      "(over (6), brown (3)) -> 0\n",
      "(quick (2), brown (3)) -> 1\n",
      "(fox (4), jumps (5)) -> 1\n",
      "(the (1), lazy (7)) -> 1\n",
      "(jumps (5), over (6)) -> 1\n",
      "(the (1), lazy (7)) -> 0\n",
      "(jumps (5), over (6)) -> 0\n",
      "(the (1), lazy (7)) -> 0\n",
      "(quick (2), quick (2)) -> 0\n",
      "(lazy (7), the (1)) -> 1\n",
      "(brown (3), fox (4)) -> 1\n",
      "(fox (4), brown (3)) -> 0\n",
      "(quick (2), over (6)) -> 0\n",
      "(brown (3), over (6)) -> 0\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import *\n",
    "from keras.preprocessing.sequence import skipgrams\n",
    "\n",
    "text = \"The quick brown fox jumps over the lazy dog\"\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "\n",
    "word2id = tokenizer.word_index\n",
    "id2word = {v:k for k, v in word2id.items()}\n",
    "\n",
    "wids = [word2id[w] for w in text_to_word_sequence(text)]\n",
    "pairs, labels = skipgrams(wids, len(word2id), window_size=1)\n",
    "print(\"Number of pairs: \",len(pairs))\n",
    "for i in range(20):\n",
    "    print(\"({:s} ({:d}), {:s} ({:d})) -> {:d}\".format(\n",
    "          id2word[pairs[i][0]], pairs[i][0], \n",
    "          id2word[pairs[i][1]], pairs[i][1], \n",
    "          labels[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11477307975292206"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import asarray\n",
    "history=model.fit([asarray(pairs)[:,0], asarray(pairs)[:,1]],labels,epochs=200,verbose=0)\n",
    "model.evaluate([asarray(pairs)[:,0], asarray(pairs)[:,1]],labels, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.03853421, -0.01923045, -0.03822639],\n",
       "        [-0.00731206, -0.13755003,  0.12676875],\n",
       "        [-0.01641215,  0.12862098,  0.06812601],\n",
       "        [-0.09955261,  0.0113467 , -0.2285318 ],\n",
       "        [-0.00181953,  0.14252363,  0.06642576],\n",
       "        [-0.08305285, -0.09567424, -0.07200117],\n",
       "        [ 0.03106353,  0.1278866 , -0.09797202],\n",
       "        [-0.17730547,  0.06396743, -0.0027189 ],\n",
       "        [ 0.1971729 ,  0.01422863, -0.05654199],\n",
       "        [-0.02735932, -0.00215567, -0.01546366]], dtype=float32)]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now store this embedding and later use it to encode words from a text. This is yet another application of transfer learning and good embeddings are costly to produce and tremendously useful. For example, google provides a word2vec embedding training on a large amount of news articles. A iPython notebook demonstrating this can be found here\n",
    "\n",
    "https://colab.research.google.com/github/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_11_02_word2vec.ipynb\n",
    "\n",
    "Why using a pre-trained embedding makes sense becomes more obvious when considering a task of classifying online ratings. While the meaning of individual words can surely be learned from a large enough corpus using a word2vec embedding will also allow us to deal with ratings that use novel words with similar meaning, e.g. For example, the most similar words to \"tasty\" in the google news dataset are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('delicious', 0.8730389475822449),\n",
       " ('scrumptious', 0.8007042407989502),\n",
       " ('yummy', 0.7856924533843994),\n",
       " ('flavorful', 0.7420164346694946),\n",
       " ('delectable', 0.7385421991348267),\n",
       " ('juicy_flavorful', 0.7114803791046143),\n",
       " ('appetizing', 0.7017217874526978),\n",
       " ('crunchy_salty', 0.7012300491333008),\n",
       " ('flavourful', 0.6912213563919067),\n",
       " ('flavoursome', 0.6857702732086182)]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[('delicious', 0.8730389475822449),\n",
    " ('scrumptious', 0.8007042407989502),\n",
    " ('yummy', 0.7856924533843994),\n",
    " ('flavorful', 0.7420164346694946),\n",
    " ('delectable', 0.7385421991348267),\n",
    " ('juicy_flavorful', 0.7114803791046143),\n",
    " ('appetizing', 0.7017217874526978),\n",
    " ('crunchy_salty', 0.7012300491333008),\n",
    " ('flavourful', 0.6912213563919067),\n",
    " ('flavoursome', 0.6857702732086182)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and it is likely that similar sentences with such a word instead of \"tasty\" will get very similar score just by the choice of the embedding. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfering an embedding (word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
      "1647050752/1647046227 [==============================] - 177s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import get_file\n",
    "\n",
    "path = get_file('GoogleNews-vectors-negative300.bin.gz', origin='https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "gmodel = gensim.models.KeyedVectors.load_word2vec_format(path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7118192911148071),\n",
       " ('monarch', 0.6189674139022827),\n",
       " ('princess', 0.5902431011199951),\n",
       " ('crown_prince', 0.5499460697174072),\n",
       " ('prince', 0.5377321243286133),\n",
       " ('kings', 0.5236844420433044),\n",
       " ('Queen_Consort', 0.5235945582389832),\n",
       " ('queens', 0.518113374710083),\n",
       " ('sultan', 0.5098593235015869),\n",
       " ('monarchy', 0.5087411999702454)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmodel.most_similar(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('delicious', 0.8730389475822449),\n",
       " ('scrumptious', 0.8007042407989502),\n",
       " ('yummy', 0.7856924533843994),\n",
       " ('flavorful', 0.7420164346694946),\n",
       " ('delectable', 0.7385421991348267),\n",
       " ('juicy_flavorful', 0.7114803791046143),\n",
       " ('appetizing', 0.7017217874526978),\n",
       " ('crunchy_salty', 0.7012300491333008),\n",
       " ('flavourful', 0.6912213563919067),\n",
       " ('flavoursome', 0.6857702732086182)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmodel.most_similar('tasty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding=gmodel.get_keras_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "embedding_17 (Embedding)     (None, 300, 300)          900000000 \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 300, 10)           3010      \n",
      "=================================================================\n",
      "Total params: 900,003,010\n",
      "Trainable params: 3,010\n",
      "Non-trainable params: 900,000,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.core import Dense, Reshape\n",
    "\n",
    "input= Input((embedding.output_dim,))\n",
    "embedding = gmodel.get_keras_embedding()\n",
    "word_embedding = embedding(input)\n",
    "#word_embedding = Reshape((embedding.output_dim, 1))(word_embedding)\n",
    "dense_layer = Dense(10, activation='relu')(word_embedding)\n",
    "output = Dense(1, activation='sigmoid')(dense_layer)\n",
    "\n",
    "model = Model(input=input, output=dense_layer)\n",
    "model.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
    "\n",
    "# view model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.17285156,  0.27929688,  0.10693359, -0.15820312, -0.08447266,\n",
       "         0.05908203,  0.04077148,  0.00254822,  0.25976562,  0.18066406,\n",
       "         0.09765625, -0.08105469, -0.01049805,  0.09814453,  0.00060272,\n",
       "         0.07080078, -0.015625  , -0.09521484, -0.08105469, -0.02868652,\n",
       "        -0.03320312,  0.16503906,  0.03979492, -0.03710938,  0.04101562,\n",
       "        -0.12695312, -0.12890625,  0.12353516,  0.04980469,  0.01257324,\n",
       "         0.05786133, -0.00830078, -0.02832031, -0.03320312,  0.16113281,\n",
       "         0.07519531, -0.25976562,  0.08935547,  0.13574219,  0.00460815,\n",
       "        -0.04418945,  0.02319336, -0.10449219, -0.05151367,  0.08349609,\n",
       "        -0.02050781, -0.02172852, -0.02734375,  0.16015625,  0.19042969,\n",
       "        -0.0324707 ,  0.06787109,  0.10302734, -0.25390625,  0.00634766,\n",
       "         0.20507812,  0.02111816, -0.21679688, -0.02441406,  0.17089844,\n",
       "        -0.21875   ,  0.10009766, -0.15527344, -0.12597656, -0.03833008,\n",
       "        -0.05419922,  0.19238281,  0.21777344,  0.12109375, -0.02648926,\n",
       "         0.05297852, -0.0201416 ,  0.0534668 ,  0.07666016,  0.0456543 ,\n",
       "         0.01977539,  0.12451172,  0.10205078,  0.15234375,  0.25195312,\n",
       "         0.04296875, -0.18554688, -0.07519531,  0.22753906, -0.13183594,\n",
       "        -0.27539062, -0.20117188,  0.12597656, -0.18652344, -0.13964844,\n",
       "        -0.12597656,  0.08007812, -0.03393555, -0.23730469, -0.00765991,\n",
       "         0.28320312, -0.01721191,  0.02722168, -0.234375  ,  0.12890625,\n",
       "         0.16796875, -0.01019287,  0.06542969, -0.1328125 ,  0.07763672,\n",
       "        -0.11669922,  0.01464844, -0.05297852, -0.12109375, -0.09912109,\n",
       "         0.0559082 , -0.04199219,  0.10742188,  0.09130859,  0.14746094,\n",
       "         0.10205078, -0.00139618,  0.20117188,  0.08447266,  0.07568359,\n",
       "        -0.24316406, -0.18945312, -0.07910156, -0.06640625,  0.12792969,\n",
       "         0.15039062, -0.16601562, -0.09521484,  0.09619141, -0.05029297,\n",
       "        -0.02502441, -0.04931641, -0.04370117, -0.0234375 ,  0.06640625,\n",
       "        -0.13378906, -0.25      , -0.2421875 , -0.11328125,  0.02636719,\n",
       "         0.13867188, -0.07080078, -0.22265625, -0.11279297, -0.01806641,\n",
       "        -0.19042969,  0.07421875, -0.16601562,  0.00628662,  0.1953125 ,\n",
       "        -0.00436401, -0.16699219,  0.14746094, -0.04882812,  0.1875    ,\n",
       "        -0.234375  ,  0.14453125,  0.00769043,  0.04101562, -0.06738281,\n",
       "        -0.01672363, -0.05029297,  0.08496094,  0.03662109,  0.13476562,\n",
       "         0.08056641, -0.04467773,  0.16601562, -0.22265625,  0.00933838,\n",
       "        -0.11962891, -0.06494141,  0.03344727, -0.09765625,  0.01464844,\n",
       "         0.12158203,  0.12353516, -0.13476562, -0.05297852, -0.27734375,\n",
       "        -0.0378418 , -0.07910156, -0.06884766,  0.05712891,  0.03112793,\n",
       "         0.07080078,  0.07958984,  0.00656128,  0.14257812, -0.08447266,\n",
       "         0.03125   , -0.03564453,  0.02307129, -0.01660156, -0.17285156,\n",
       "        -0.16113281, -0.10742188,  0.05566406, -0.09228516, -0.25585938,\n",
       "         0.03930664, -0.20410156,  0.08496094,  0.04614258,  0.01208496,\n",
       "        -0.01257324,  0.06396484,  0.2578125 ,  0.18457031, -0.0559082 ,\n",
       "         0.0234375 ,  0.10498047,  0.12011719,  0.00909424, -0.00567627,\n",
       "         0.11132812,  0.15136719,  0.0246582 , -0.03833008,  0.11572266,\n",
       "         0.171875  , -0.04125977,  0.10302734,  0.04467773, -0.01269531,\n",
       "        -0.08203125, -0.03491211,  0.00787354,  0.07910156, -0.00050354,\n",
       "         0.02246094, -0.16113281,  0.11621094,  0.25195312, -0.04663086,\n",
       "        -0.08007812, -0.09863281,  0.04760742, -0.06054688,  0.11865234,\n",
       "        -0.03393555, -0.06689453, -0.0007782 , -0.04882812, -0.01190186,\n",
       "        -0.08251953,  0.21777344, -0.00180817,  0.1484375 , -0.02050781,\n",
       "         0.26367188,  0.17089844, -0.04638672,  0.12792969,  0.0480957 ,\n",
       "        -0.03759766,  0.16699219, -0.19140625,  0.0390625 ,  0.07714844,\n",
       "        -0.01586914,  0.09912109, -0.15820312, -0.01379395,  0.01855469,\n",
       "         0.15527344, -0.18164062,  0.03369141, -0.0008049 ,  0.06689453,\n",
       "        -0.01843262,  0.14160156,  0.06445312, -0.00732422,  0.07958984,\n",
       "        -0.0279541 ,  0.125     , -0.23730469,  0.03637695, -0.046875  ,\n",
       "        -0.046875  ,  0.05493164,  0.07958984,  0.27148438,  0.22558594,\n",
       "        -0.20507812, -0.20507812, -0.06445312, -0.07763672, -0.06982422,\n",
       "        -0.0177002 , -0.12890625,  0.02197266,  0.01477051, -0.05297852,\n",
       "        -0.203125  ,  0.06176758,  0.12304688,  0.12988281, -0.18261719],\n",
       "       dtype=float32),\n",
       " array([-0.16699219,  0.06738281,  0.03149414,  0.33203125, -0.17285156,\n",
       "         0.19335938,  0.13574219,  0.0324707 ,  0.29101562, -0.09472656,\n",
       "         0.13867188,  0.36914062,  0.15820312, -0.21972656,  0.04858398,\n",
       "        -0.01556396, -0.06298828,  0.08740234, -0.05371094,  0.09423828,\n",
       "         0.10595703, -0.15234375,  0.25976562, -0.00750732,  0.09521484,\n",
       "        -0.00494385, -0.00799561,  0.41015625,  0.21777344,  0.13378906,\n",
       "        -0.09033203, -0.34375   ,  0.2890625 ,  0.07861328, -0.10595703,\n",
       "        -0.04394531,  0.40234375,  0.0456543 , -0.21191406,  0.08496094,\n",
       "        -0.08300781, -0.07910156, -0.04785156,  0.08447266,  0.01098633,\n",
       "        -0.18359375, -0.5546875 ,  0.04296875,  0.14453125,  0.30273438,\n",
       "        -0.33789062,  0.51171875,  0.171875  , -0.11474609, -0.05004883,\n",
       "         0.01879883,  0.28125   , -0.25      , -0.43554688, -0.1640625 ,\n",
       "        -0.1953125 ,  0.2421875 ,  0.09277344,  0.00772095,  0.11523438,\n",
       "        -0.4921875 , -0.15429688, -0.29492188, -0.02270508,  0.07080078,\n",
       "         0.07861328,  0.15820312, -0.00137329, -0.17089844, -0.22949219,\n",
       "        -0.11376953, -0.11767578, -0.10498047,  0.08105469, -0.38476562,\n",
       "         0.02807617,  0.04882812, -0.30078125, -0.33007812, -0.36523438,\n",
       "        -0.59375   , -0.31835938,  0.44140625,  0.32421875, -0.25390625,\n",
       "        -0.10595703, -0.578125  , -0.1328125 ,  0.19335938, -0.30859375,\n",
       "        -0.1171875 ,  0.05834961,  0.02075195,  0.24902344, -0.24414062,\n",
       "        -0.390625  , -0.20996094,  0.09472656,  0.15234375,  0.35546875,\n",
       "        -0.14453125,  0.10058594, -0.32421875, -0.25976562,  0.32421875,\n",
       "         0.05981445, -0.04736328, -0.12988281, -0.296875  ,  0.04394531,\n",
       "        -0.29882812,  0.12792969,  0.12988281, -0.04150391, -0.296875  ,\n",
       "         0.09375   , -0.1484375 , -0.09863281,  0.05078125, -0.22363281,\n",
       "        -0.23144531, -0.39257812, -0.00190735, -0.10742188,  0.12255859,\n",
       "        -0.12695312, -0.16308594,  0.04150391, -0.18359375, -0.09765625,\n",
       "         0.18554688, -0.05151367, -0.19921875,  0.25390625,  0.09423828,\n",
       "         0.01330566, -0.13769531, -0.21386719, -0.10888672,  0.10449219,\n",
       "        -0.23535156, -0.1328125 ,  0.12207031, -0.08740234,  0.11474609,\n",
       "        -0.04418945,  0.38085938, -0.13574219,  0.06494141, -0.08691406,\n",
       "        -0.02453613, -0.03686523,  0.16796875, -0.32421875, -0.05395508,\n",
       "        -0.38476562, -0.06982422, -0.07861328, -0.00527954, -0.15234375,\n",
       "        -0.06445312, -0.22167969, -0.03295898,  0.18066406, -0.07958984,\n",
       "        -0.02941895, -0.2109375 ,  0.3671875 , -0.28320312, -0.36523438,\n",
       "         0.2734375 , -0.0039978 ,  0.21484375,  0.03295898,  0.12597656,\n",
       "         0.14550781, -0.2265625 ,  0.12988281, -0.13085938, -0.21875   ,\n",
       "        -0.10693359,  0.19726562,  0.49804688,  0.16699219, -0.08447266,\n",
       "         0.10742188,  0.17480469, -0.05615234,  0.11669922, -0.22167969,\n",
       "        -0.11865234,  0.24023438, -0.28710938,  0.04077148, -0.03540039,\n",
       "        -0.18164062,  0.02832031,  0.0625    , -0.09912109,  0.21289062,\n",
       "        -0.06347656, -0.00314331,  0.18457031, -0.09570312,  0.15625   ,\n",
       "        -0.07128906,  0.21582031, -0.08398438,  0.33203125,  0.0378418 ,\n",
       "         0.00221252, -0.00643921,  0.02050781, -0.12353516,  0.09472656,\n",
       "         0.07080078, -0.07324219,  0.21777344, -0.26367188,  0.17480469,\n",
       "         0.28710938, -0.31640625,  0.16113281, -0.07470703, -0.04052734,\n",
       "        -0.18164062,  0.26757812, -0.08886719,  0.38476562,  0.11621094,\n",
       "        -0.16503906,  0.3046875 , -0.04980469, -0.12597656,  0.12109375,\n",
       "         0.20898438,  0.125     ,  0.15332031,  0.00341797, -0.12890625,\n",
       "        -0.08007812,  0.34570312,  0.38476562,  0.22167969,  0.04736328,\n",
       "         0.09667969,  0.26367188,  0.10351562, -0.10742188,  0.17089844,\n",
       "         0.2890625 ,  0.09521484, -0.06640625, -0.06884766, -0.25585938,\n",
       "         0.14550781,  0.16308594, -0.0625    , -0.00656128,  0.05737305,\n",
       "        -0.13476562, -0.35351562,  0.04394531, -0.03979492,  0.0168457 ,\n",
       "        -0.06103516,  0.21289062, -0.16894531, -0.140625  ,  0.12597656,\n",
       "        -0.05786133, -0.29296875, -0.140625  ,  0.13769531, -0.3203125 ,\n",
       "        -0.04174805,  0.3046875 , -0.30664062,  0.28515625, -0.12890625,\n",
       "        -0.265625  ,  0.06079102,  0.17578125, -0.44921875,  0.3828125 ,\n",
       "         0.03466797, -0.16210938, -0.10644531,  0.25976562,  0.7109375 ,\n",
       "         0.03222656, -0.01080322, -0.00254822, -0.22949219, -0.03442383],\n",
       "       dtype=float32),\n",
       " array([ 2.60009766e-02, -1.89208984e-03,  1.85546875e-01, -5.17578125e-02,\n",
       "         5.12695312e-03, -1.09863281e-01, -8.17871094e-03, -8.83789062e-02,\n",
       "         9.66796875e-02,  4.83398438e-02,  1.10473633e-02, -3.63281250e-01,\n",
       "         8.20312500e-02, -2.12402344e-02,  1.58203125e-01,  4.41894531e-02,\n",
       "        -1.17797852e-02,  2.12890625e-01, -5.73730469e-02,  5.66406250e-02,\n",
       "        -1.07421875e-01,  1.85546875e-01,  7.71484375e-02,  1.44958496e-04,\n",
       "         1.52343750e-01, -6.54296875e-02, -1.52343750e-01,  2.25585938e-01,\n",
       "         8.10546875e-02,  8.88671875e-02,  7.32421875e-02, -1.03515625e-01,\n",
       "        -6.68945312e-02,  1.76757812e-01,  2.12890625e-01,  1.40625000e-01,\n",
       "        -3.41796875e-02,  1.78222656e-02,  5.95703125e-02,  2.86102295e-04,\n",
       "         5.88378906e-02,  9.27734375e-03,  1.66992188e-01, -2.70080566e-03,\n",
       "         1.15722656e-01,  1.04492188e-01,  5.37109375e-02,  1.85546875e-02,\n",
       "         1.06445312e-01,  5.05371094e-02, -1.64794922e-02, -1.27929688e-01,\n",
       "         2.16796875e-01,  5.15136719e-02,  4.78515625e-02,  1.52343750e-01,\n",
       "         1.71875000e-01,  7.86132812e-02, -5.88378906e-02, -4.29687500e-02,\n",
       "        -7.27539062e-02,  1.81640625e-01, -8.05664062e-02, -1.54296875e-01,\n",
       "        -1.16699219e-01,  8.44726562e-02, -6.17675781e-02, -4.51660156e-02,\n",
       "         9.21630859e-03,  1.33789062e-01,  1.92871094e-02,  6.44531250e-02,\n",
       "         1.08886719e-01,  1.58203125e-01, -2.35595703e-02,  1.23535156e-01,\n",
       "         1.69921875e-01,  3.49121094e-02,  1.29882812e-01,  2.65625000e-01,\n",
       "         1.93359375e-01, -8.83789062e-02,  8.49609375e-02, -2.96630859e-02,\n",
       "         5.76171875e-02,  2.51464844e-02, -1.01562500e-01,  1.99218750e-01,\n",
       "         1.04492188e-01, -2.42919922e-02,  2.01416016e-02, -3.51562500e-02,\n",
       "         6.64062500e-02, -6.20117188e-02,  2.90527344e-02, -9.81445312e-02,\n",
       "        -1.81640625e-01,  2.14843750e-01, -5.76171875e-02, -4.51660156e-02,\n",
       "         4.49218750e-02, -1.95312500e-02, -2.08984375e-01,  1.19628906e-01,\n",
       "        -9.03320312e-02,  5.07812500e-02,  9.03320312e-03, -9.76562500e-02,\n",
       "        -7.86132812e-02, -1.36718750e-01, -1.13769531e-01, -5.64575195e-03,\n",
       "        -4.07714844e-02, -2.05993652e-03, -5.66406250e-02,  3.64685059e-03,\n",
       "         8.30078125e-02, -7.08007812e-02,  2.63671875e-01,  1.24511719e-01,\n",
       "        -1.61132812e-02,  9.13085938e-02, -2.39257812e-01, -1.04980469e-02,\n",
       "        -6.78710938e-02,  1.40625000e-01,  2.34375000e-01, -6.39648438e-02,\n",
       "         1.95312500e-01,  5.02929688e-02, -1.25000000e-01,  2.06298828e-02,\n",
       "        -1.19140625e-01, -1.17187500e-01, -9.01222229e-05,  3.68652344e-02,\n",
       "         1.46484375e-01,  2.47802734e-02, -1.49414062e-01,  3.03649902e-03,\n",
       "        -3.10058594e-02,  1.06933594e-01,  2.55859375e-01, -6.00585938e-02,\n",
       "        -2.07031250e-01,  1.58203125e-01, -2.15820312e-01, -1.84570312e-01,\n",
       "        -1.72851562e-01,  7.99560547e-03, -3.03955078e-02,  9.81445312e-02,\n",
       "         4.66918945e-03,  2.57812500e-01,  1.06933594e-01,  1.26953125e-01,\n",
       "         6.34765625e-02, -1.30859375e-01,  6.54296875e-02, -9.91210938e-02,\n",
       "         5.90820312e-02, -3.71093750e-02,  1.01074219e-01,  1.53320312e-01,\n",
       "        -1.53320312e-01, -7.56835938e-02,  5.85937500e-02, -5.05371094e-02,\n",
       "         2.08007812e-01,  4.85839844e-02, -9.42382812e-02, -9.71679688e-02,\n",
       "        -1.23046875e-01, -1.97265625e-01, -1.76757812e-01, -1.11328125e-01,\n",
       "         1.11328125e-01, -5.88378906e-02,  2.27539062e-01,  4.00390625e-02,\n",
       "         1.24511719e-01,  1.47460938e-01,  1.81884766e-02,  4.05273438e-02,\n",
       "         1.69921875e-01,  1.13769531e-01, -2.24609375e-02,  6.73828125e-02,\n",
       "         8.59375000e-02,  6.73828125e-02,  2.06298828e-02,  4.78515625e-02,\n",
       "         1.84326172e-02,  2.05078125e-01, -4.68750000e-02,  2.00195312e-01,\n",
       "        -1.56250000e-02, -1.40625000e-01,  1.09863281e-02, -1.73828125e-01,\n",
       "         4.85839844e-02, -1.58203125e-01, -1.04492188e-01,  3.63769531e-02,\n",
       "         3.01513672e-02,  1.27929688e-01, -1.14257812e-01,  1.41601562e-01,\n",
       "         2.34375000e-01, -8.98437500e-02, -1.02996826e-03, -1.50390625e-01,\n",
       "         1.79687500e-01,  1.35742188e-01, -2.08007812e-01, -1.27563477e-02,\n",
       "         1.75781250e-01, -1.39648438e-01, -2.03125000e-01, -3.00292969e-02,\n",
       "        -2.78320312e-02, -6.50024414e-03,  1.26953125e-01, -1.49414062e-01,\n",
       "         1.46484375e-01, -8.42285156e-03,  1.12304688e-01,  1.66015625e-01,\n",
       "        -1.57470703e-02,  1.23046875e-01,  7.22656250e-02, -4.37011719e-02,\n",
       "        -7.56835938e-02, -9.03320312e-02,  1.01562500e-01, -1.44531250e-01,\n",
       "        -4.00390625e-02, -1.26953125e-02,  2.66113281e-02, -7.81250000e-02,\n",
       "         3.56445312e-02,  3.49121094e-02,  1.79687500e-01, -1.38671875e-01,\n",
       "         2.80761719e-02, -2.86865234e-02,  6.78710938e-02,  7.03125000e-02,\n",
       "         9.57031250e-02,  5.00488281e-02, -2.20947266e-02, -3.00781250e-01,\n",
       "         1.14257812e-01,  7.51953125e-02,  1.26342773e-02,  1.32812500e-01,\n",
       "         2.52685547e-02,  3.63769531e-02, -2.81982422e-02, -1.36718750e-01,\n",
       "         1.79687500e-01, -9.27734375e-02,  8.49609375e-02,  1.32812500e-01,\n",
       "         3.97949219e-02,  4.29687500e-01, -1.87988281e-02, -1.47460938e-01,\n",
       "         6.10351562e-02,  9.03320312e-02,  8.69140625e-02, -6.88476562e-02,\n",
       "         1.10839844e-01,  9.81445312e-02,  1.50390625e-01,  1.61132812e-01,\n",
       "        -8.05664062e-02, -1.74804688e-01, -3.32031250e-02, -1.28906250e-01,\n",
       "         1.22558594e-01, -1.44653320e-02, -1.63085938e-01, -3.58886719e-02,\n",
       "         2.78320312e-02, -6.34765625e-02, -7.91015625e-02, -1.14746094e-01,\n",
       "         1.84326172e-02,  2.91748047e-02, -3.00781250e-01, -4.58984375e-02,\n",
       "        -1.74804688e-01,  2.33398438e-01,  2.25830078e-02,  1.10351562e-01,\n",
       "        -1.03515625e-01, -1.21582031e-01,  2.21679688e-01, -2.19726562e-02],\n",
       "       dtype=float32),\n",
       " array([ 2.25585938e-01,  9.86328125e-02, -2.91748047e-02,  1.42578125e-01,\n",
       "        -1.35742188e-01,  2.15820312e-01, -6.88476562e-02, -4.78515625e-02,\n",
       "         1.83593750e-01,  3.00781250e-01, -7.27539062e-02, -7.47070312e-02,\n",
       "        -6.07910156e-02, -1.60156250e-01,  2.62451172e-02,  2.45117188e-01,\n",
       "         1.25976562e-01,  1.74804688e-01,  4.27246094e-02, -1.04980469e-01,\n",
       "        -5.46875000e-02,  2.63671875e-01,  7.61718750e-02, -1.38671875e-01,\n",
       "         2.13867188e-01,  1.08398438e-01,  1.34277344e-02, -1.45874023e-02,\n",
       "        -7.08007812e-02, -5.29785156e-02, -1.04492188e-01,  3.34472656e-02,\n",
       "         2.55859375e-01,  5.76782227e-03,  1.66015625e-01,  1.71875000e-01,\n",
       "         2.30468750e-01,  4.32128906e-02, -6.49414062e-02,  3.51562500e-01,\n",
       "         3.37890625e-01, -1.13281250e-01,  3.26171875e-01, -4.62890625e-01,\n",
       "        -2.46582031e-02, -6.98242188e-02,  4.88281250e-02, -1.11816406e-01,\n",
       "        -1.87988281e-02, -1.60156250e-01,  1.03759766e-02,  2.31445312e-01,\n",
       "        -4.32128906e-02,  6.39648438e-02, -7.08007812e-02, -9.17968750e-02,\n",
       "        -1.03149414e-02, -2.15820312e-01,  2.29492188e-01, -6.34765625e-02,\n",
       "        -6.88476562e-02,  2.29492188e-01, -2.61718750e-01, -2.92968750e-01,\n",
       "        -2.08740234e-02, -1.33789062e-01,  1.05590820e-02,  1.15234375e-01,\n",
       "        -2.08984375e-01,  5.82885742e-03,  1.32812500e-01, -1.57226562e-01,\n",
       "        -9.27734375e-02,  6.05468750e-02, -2.14843750e-01,  2.08740234e-02,\n",
       "         1.85546875e-02,  1.88476562e-01,  5.85937500e-02,  1.02539062e-01,\n",
       "        -2.26562500e-01, -4.90722656e-02, -2.61718750e-01, -1.32446289e-02,\n",
       "        -8.88671875e-02, -8.15429688e-02,  4.02450562e-04,  3.45703125e-01,\n",
       "        -4.00390625e-02,  8.64257812e-02, -7.08007812e-02,  8.69140625e-02,\n",
       "        -1.25976562e-01,  8.66699219e-03, -1.39648438e-01,  1.73339844e-02,\n",
       "         3.27148438e-02,  2.67578125e-01,  2.03125000e-01, -6.93359375e-02,\n",
       "        -3.95507812e-02,  1.50390625e-01,  3.05175781e-02, -2.04101562e-01,\n",
       "         1.20117188e-01, -1.00585938e-01, -2.62451172e-02, -1.20117188e-01,\n",
       "        -1.23046875e-01, -1.54296875e-01, -5.59082031e-02,  3.32031250e-02,\n",
       "         1.05468750e-01, -2.34375000e-02,  3.10546875e-01, -1.64062500e-01,\n",
       "         7.76367188e-02,  1.25732422e-02,  2.22656250e-01,  8.83789062e-02,\n",
       "        -4.02343750e-01, -6.98242188e-02,  2.06054688e-01, -7.47070312e-02,\n",
       "        -3.37890625e-01, -1.91406250e-01, -1.17675781e-01, -4.85839844e-02,\n",
       "         2.25585938e-01,  2.67578125e-01, -1.53320312e-01, -7.76367188e-02,\n",
       "        -2.94921875e-01,  3.04687500e-01, -1.73339844e-02, -6.68945312e-02,\n",
       "         2.57568359e-02, -8.20312500e-02, -1.66015625e-01, -1.23046875e-01,\n",
       "         3.83300781e-02,  2.94921875e-01,  1.13281250e-01,  1.96289062e-01,\n",
       "         1.31835938e-02, -2.02148438e-01, -1.89453125e-01, -1.54296875e-01,\n",
       "        -2.06054688e-01, -7.95898438e-02,  1.82617188e-01,  1.14746094e-01,\n",
       "        -2.25830078e-02,  1.77734375e-01, -1.84326172e-02, -9.03320312e-02,\n",
       "        -1.75781250e-01, -2.04101562e-01, -1.46484375e-02, -2.31933594e-02,\n",
       "        -6.29882812e-02,  2.94921875e-01,  1.15722656e-01,  1.92871094e-02,\n",
       "         1.88476562e-01, -1.05468750e-01, -7.32421875e-02, -2.29492188e-01,\n",
       "         2.16796875e-01, -7.71484375e-02, -1.34765625e-01,  8.15429688e-02,\n",
       "        -1.86523438e-01,  1.28906250e-01, -2.06054688e-01,  7.56835938e-02,\n",
       "         1.62109375e-01, -1.72851562e-01,  3.37890625e-01, -5.76171875e-02,\n",
       "         3.68652344e-02, -1.64062500e-01,  2.14843750e-01,  1.68945312e-01,\n",
       "        -8.44726562e-02,  5.56640625e-02, -2.33398438e-01,  7.04956055e-03,\n",
       "        -5.02929688e-02, -6.78710938e-02, -1.19628906e-01,  1.18164062e-01,\n",
       "         5.95703125e-02, -3.66210938e-02, -1.57226562e-01,  5.29785156e-02,\n",
       "         3.05175781e-02, -1.72851562e-01, -1.93359375e-01,  4.88281250e-02,\n",
       "         1.45874023e-02,  1.04003906e-01, -1.21093750e-01, -3.80859375e-02,\n",
       "         1.10839844e-01,  5.98144531e-02, -2.01171875e-01,  6.68945312e-02,\n",
       "        -1.17675781e-01,  9.17968750e-02,  6.73828125e-02, -4.63867188e-02,\n",
       "        -7.78198242e-03, -1.05957031e-01, -9.37500000e-02,  5.58471680e-03,\n",
       "         2.65625000e-01,  2.36816406e-02,  8.34960938e-02, -1.67968750e-01,\n",
       "        -2.08984375e-01,  1.17187500e-01,  8.69140625e-02,  3.00292969e-02,\n",
       "         2.53906250e-01, -1.19140625e-01,  1.01074219e-01, -3.75976562e-02,\n",
       "        -1.40625000e-01, -1.20239258e-02,  8.20312500e-02, -7.93457031e-03,\n",
       "         9.71679688e-02,  1.53320312e-01, -2.00195312e-02,  1.12792969e-01,\n",
       "        -8.30078125e-02,  9.47265625e-02,  2.13867188e-01, -2.45361328e-02,\n",
       "         1.99218750e-01,  1.04980469e-01,  7.37304688e-02, -2.65625000e-01,\n",
       "        -3.06640625e-01,  7.99560547e-03,  1.87500000e-01, -7.47070312e-02,\n",
       "        -2.71484375e-01, -6.29882812e-02, -5.78613281e-02,  2.48046875e-01,\n",
       "         6.10351562e-02,  2.94921875e-01,  1.34765625e-01, -3.39843750e-01,\n",
       "         1.46484375e-01,  3.88183594e-02,  9.47265625e-02, -2.65625000e-01,\n",
       "        -2.20703125e-01,  3.58886719e-02,  3.35937500e-01,  4.17480469e-02,\n",
       "        -1.28906250e-01, -3.29589844e-02, -4.22363281e-02, -1.49414062e-01,\n",
       "        -1.02050781e-01,  6.68334961e-03, -7.47070312e-02,  1.92382812e-01,\n",
       "         2.36328125e-01, -2.80761719e-02, -2.00195312e-02, -9.37500000e-02,\n",
       "         1.63085938e-01,  4.24804688e-02,  1.58203125e-01, -8.23974609e-03,\n",
       "         8.05664062e-02, -2.61718750e-01, -5.90820312e-02, -5.43212891e-03,\n",
       "        -1.83593750e-01, -1.83868408e-03, -2.27050781e-02, -5.22460938e-02,\n",
       "        -3.23486328e-03,  2.53906250e-02,  1.07421875e-02,  1.52343750e-01,\n",
       "        -1.31835938e-01,  1.24023438e-01, -2.04101562e-01,  1.81884766e-02,\n",
       "         6.68945312e-02, -2.06054688e-01, -4.15039062e-02,  1.03027344e-01],\n",
       "       dtype=float32),\n",
       " array([-4.76074219e-02,  8.15429688e-02,  4.56542969e-02,  9.17968750e-02,\n",
       "        -1.47094727e-02,  1.11328125e-01,  6.54296875e-02, -9.66796875e-02,\n",
       "         1.38671875e-01,  1.43554688e-01, -7.86132812e-02, -1.63085938e-01,\n",
       "        -9.17968750e-02, -7.12890625e-02, -8.05664062e-02,  8.83789062e-02,\n",
       "         2.17773438e-01,  9.96093750e-02,  1.19018555e-02, -1.35742188e-01,\n",
       "        -5.78613281e-02,  9.03320312e-03,  1.75781250e-01, -1.17187500e-02,\n",
       "         4.90722656e-02, -1.05468750e-01, -1.53320312e-01,  6.17675781e-02,\n",
       "         8.64257812e-02,  2.25830078e-02,  1.59740448e-05,  6.39648438e-02,\n",
       "         2.33154297e-02, -1.45874023e-02,  1.51367188e-02,  5.29785156e-02,\n",
       "        -1.34277344e-02,  7.99560547e-03,  2.63671875e-02,  2.99072266e-02,\n",
       "         1.61132812e-01,  5.68847656e-02,  1.18164062e-01, -3.12500000e-02,\n",
       "        -7.59887695e-03,  6.64062500e-02, -1.08032227e-02, -6.53076172e-03,\n",
       "         1.13281250e-01,  9.22851562e-02,  4.29687500e-02, -6.10351562e-03,\n",
       "         2.80761719e-02, -8.78906250e-02,  3.46679688e-02,  8.83789062e-02,\n",
       "         8.36181641e-03,  1.30004883e-02,  3.71093750e-02, -5.12695312e-02,\n",
       "        -8.60595703e-03,  4.78515625e-02, -1.29882812e-01, -1.61132812e-01,\n",
       "        -8.10546875e-02, -9.70458984e-03,  5.12695312e-02,  9.61914062e-02,\n",
       "        -7.12890625e-02,  5.63964844e-02, -7.87353516e-03,  1.38671875e-01,\n",
       "        -2.52685547e-02,  7.22656250e-02, -1.61132812e-01, -2.91748047e-02,\n",
       "         1.05468750e-01,  2.27050781e-02,  6.29882812e-02,  4.18090820e-03,\n",
       "         1.28173828e-02,  4.07714844e-02,  3.66210938e-02,  6.88476562e-02,\n",
       "        -8.20312500e-02, -1.16210938e-01, -9.91210938e-02,  1.65039062e-01,\n",
       "        -1.34765625e-01, -5.63964844e-02,  2.73437500e-02,  4.46777344e-02,\n",
       "        -1.51977539e-02, -9.47265625e-02,  4.00390625e-02, -9.52148438e-02,\n",
       "        -6.15234375e-02,  1.67236328e-02, -1.62109375e-01,  4.61425781e-02,\n",
       "        -7.61718750e-02, -3.19824219e-02,  1.04980469e-01,  1.12304688e-02,\n",
       "         4.61425781e-02, -9.08203125e-02, -5.17578125e-02, -1.05468750e-01,\n",
       "         6.29882812e-02, -6.49414062e-02,  2.24609375e-02,  6.12792969e-02,\n",
       "         1.55029297e-02,  3.29589844e-02,  6.98242188e-02, -2.16064453e-02,\n",
       "         9.46044922e-03,  5.56640625e-02,  2.31933594e-02,  1.25000000e-01,\n",
       "        -1.96289062e-01,  1.25976562e-01, -1.55639648e-02,  8.88671875e-02,\n",
       "        -9.08203125e-02, -6.46972656e-03,  2.02178955e-04, -7.17773438e-02,\n",
       "        -6.54296875e-02, -8.10546875e-02,  3.63769531e-02, -1.57226562e-01,\n",
       "         1.57470703e-02, -6.22558594e-02, -5.78613281e-02, -1.39648438e-01,\n",
       "        -7.42187500e-02, -1.09252930e-02, -4.66308594e-02, -5.12695312e-02,\n",
       "        -9.99450684e-04, -7.17773438e-02,  3.36914062e-02, -1.63574219e-02,\n",
       "         4.58984375e-02,  5.27343750e-02, -1.04492188e-01, -1.41601562e-01,\n",
       "        -2.09960938e-01,  1.16210938e-01, -2.44140625e-02,  6.20117188e-02,\n",
       "        -2.25830078e-02,  2.69775391e-02, -1.14135742e-02, -4.24804688e-02,\n",
       "        -2.02941895e-03, -5.56640625e-02, -4.41894531e-02,  4.10156250e-02,\n",
       "         9.13085938e-02,  8.25195312e-02,  8.69140625e-02,  7.95898438e-02,\n",
       "         2.91748047e-02, -9.03320312e-02, -7.22656250e-02,  1.03515625e-01,\n",
       "        -2.96630859e-02, -6.44531250e-02, -1.75781250e-01,  2.66113281e-02,\n",
       "        -6.64062500e-02, -1.42211914e-02, -6.54296875e-02,  3.97949219e-02,\n",
       "         3.05175781e-03, -1.20605469e-01,  1.96533203e-02, -7.42187500e-02,\n",
       "        -5.00488281e-02, -9.96093750e-02,  4.58984375e-02,  1.65039062e-01,\n",
       "         2.16674805e-03, -3.75976562e-02, -7.61718750e-02,  2.73437500e-02,\n",
       "         1.87988281e-02,  6.89697266e-03,  1.68457031e-02, -9.22851562e-02,\n",
       "        -1.38549805e-02, -5.02929688e-02, -9.71679688e-02, -3.06396484e-02,\n",
       "        -5.39550781e-02, -3.08837891e-02, -7.76367188e-02, -1.95312500e-01,\n",
       "         6.15234375e-02, -1.04980469e-01, -1.80664062e-02,  4.54101562e-02,\n",
       "         6.73828125e-02, -8.64257812e-02, -9.86328125e-02, -2.84423828e-02,\n",
       "         2.70996094e-02, -2.88085938e-02, -1.84326172e-02,  6.64062500e-02,\n",
       "        -3.41796875e-02,  9.86328125e-02, -1.47460938e-01,  1.87988281e-02,\n",
       "         1.36718750e-01, -1.23291016e-02, -5.88378906e-02,  1.29394531e-02,\n",
       "         8.93554688e-02,  7.22656250e-02,  7.03125000e-02, -6.29882812e-02,\n",
       "         1.54296875e-01, -4.58984375e-02,  1.11816406e-01, -4.85839844e-02,\n",
       "         9.27734375e-02,  5.12695312e-02,  3.24707031e-02, -3.29589844e-02,\n",
       "        -2.41699219e-02,  6.10351562e-03,  1.00585938e-01,  2.86865234e-03,\n",
       "        -1.07421875e-01, -4.85839844e-02,  1.20605469e-01, -1.86920166e-03,\n",
       "         8.54492188e-02, -4.12597656e-02,  3.02734375e-02, -5.61523438e-02,\n",
       "         4.85839844e-02, -3.22265625e-02,  2.27050781e-02, -1.85546875e-02,\n",
       "         1.37939453e-02,  7.42187500e-02,  8.88671875e-02,  4.66308594e-02,\n",
       "         1.27929688e-01,  8.00781250e-02,  1.09375000e-01, -1.51367188e-02,\n",
       "         6.39648438e-02,  1.07910156e-01, -7.91015625e-02, -4.05273438e-02,\n",
       "        -5.46875000e-02,  4.02832031e-02, -1.39648438e-01,  9.71679688e-02,\n",
       "        -2.58789062e-02,  1.03515625e-01, -2.89306641e-02, -1.43432617e-02,\n",
       "         4.45556641e-03, -1.48315430e-02,  1.64062500e-01,  1.86767578e-02,\n",
       "         1.75781250e-01, -1.51977539e-02, -5.22460938e-02, -9.42382812e-02,\n",
       "         7.71484375e-02, -2.02148438e-01, -5.78613281e-02, -2.47802734e-02,\n",
       "        -5.21850586e-03, -2.91748047e-02,  1.08886719e-01,  7.27539062e-02,\n",
       "         8.54492188e-02, -8.88671875e-02, -8.77380371e-05, -1.40625000e-01,\n",
       "        -6.34765625e-02,  1.07910156e-01, -1.14746094e-01,  4.15039062e-02,\n",
       "        -4.19921875e-02,  9.22851562e-02, -7.13348389e-04,  7.51953125e-02,\n",
       "         4.93164062e-02, -5.56640625e-02,  1.04980469e-01, -1.08398438e-01],\n",
       "       dtype=float32),\n",
       " array([ 0.08007812,  0.10498047,  0.04980469,  0.0534668 , -0.06738281,\n",
       "        -0.12060547,  0.03515625, -0.11865234,  0.04394531,  0.03015137,\n",
       "        -0.05688477, -0.07617188,  0.01287842,  0.04980469, -0.08496094,\n",
       "        -0.06347656,  0.00628662, -0.04321289,  0.02026367,  0.01330566,\n",
       "        -0.01953125,  0.09277344, -0.171875  , -0.00131989,  0.06542969,\n",
       "         0.05834961, -0.08251953,  0.0859375 , -0.00318909,  0.05859375,\n",
       "        -0.03491211, -0.0123291 , -0.0480957 , -0.00302124,  0.05639648,\n",
       "         0.01495361, -0.07226562, -0.05224609,  0.09667969,  0.04296875,\n",
       "        -0.03540039, -0.07324219,  0.03271484, -0.06176758,  0.00787354,\n",
       "         0.0035553 , -0.00878906,  0.0390625 ,  0.03833008,  0.04443359,\n",
       "         0.06982422,  0.01263428, -0.00445557, -0.03320312, -0.04272461,\n",
       "         0.09765625, -0.02160645, -0.0378418 ,  0.01190186, -0.01391602,\n",
       "        -0.11328125,  0.09326172, -0.03930664, -0.11621094,  0.02331543,\n",
       "        -0.01599121,  0.02636719,  0.10742188, -0.00466919,  0.09619141,\n",
       "         0.0279541 , -0.05395508,  0.08544922, -0.03686523, -0.02026367,\n",
       "        -0.08544922,  0.125     ,  0.14453125,  0.0267334 ,  0.15039062,\n",
       "         0.05273438, -0.18652344,  0.08154297, -0.01062012, -0.03735352,\n",
       "        -0.07324219, -0.07519531,  0.03613281, -0.13183594,  0.00616455,\n",
       "         0.05078125,  0.04516602,  0.0100708 , -0.15039062, -0.06005859,\n",
       "         0.05761719, -0.00692749,  0.01586914, -0.0213623 ,  0.10351562,\n",
       "        -0.00029182, -0.046875  , -0.01635742, -0.07861328, -0.06933594,\n",
       "         0.01635742, -0.03149414, -0.01373291, -0.03662109, -0.08886719,\n",
       "        -0.0480957 , -0.01318359, -0.07177734,  0.00588989, -0.04614258,\n",
       "         0.03979492,  0.10058594, -0.04931641,  0.07568359,  0.03881836,\n",
       "        -0.16699219, -0.09619141, -0.10107422,  0.02905273, -0.05786133,\n",
       "        -0.01928711, -0.04296875, -0.08398438, -0.01989746,  0.05151367,\n",
       "         0.00848389, -0.03613281, -0.14941406, -0.01855469, -0.03637695,\n",
       "        -0.07666016, -0.03955078, -0.06152344, -0.02001953,  0.04150391,\n",
       "         0.03686523, -0.07226562,  0.00592041, -0.06298828,  0.00738525,\n",
       "        -0.01586914,  0.01611328, -0.01452637,  0.00772095,  0.10107422,\n",
       "        -0.00558472,  0.01428223, -0.07617188,  0.05639648, -0.01293945,\n",
       "         0.03063965, -0.02490234, -0.09863281,  0.0324707 , -0.02807617,\n",
       "        -0.08105469,  0.02062988,  0.01611328, -0.04199219, -0.03491211,\n",
       "        -0.03759766,  0.05493164,  0.01373291,  0.02685547, -0.05859375,\n",
       "        -0.07177734, -0.12011719, -0.02282715, -0.1640625 , -0.00361633,\n",
       "        -0.05981445,  0.07080078, -0.07714844,  0.05175781, -0.04296875,\n",
       "        -0.04833984,  0.0300293 , -0.06591797, -0.03173828, -0.04882812,\n",
       "        -0.03491211,  0.05883789, -0.01464844,  0.18066406,  0.05688477,\n",
       "         0.05249023,  0.05786133,  0.11669922,  0.05200195, -0.0534668 ,\n",
       "         0.01867676, -0.015625  ,  0.00576782, -0.07324219, -0.11621094,\n",
       "         0.04052734,  0.0625    , -0.04321289,  0.01055908,  0.02172852,\n",
       "         0.04248047,  0.03271484,  0.04418945,  0.05761719,  0.02612305,\n",
       "        -0.01831055, -0.02697754, -0.00674438,  0.00509644, -0.11621094,\n",
       "         0.00364685,  0.05761719, -0.05957031, -0.08837891,  0.0135498 ,\n",
       "         0.04541016, -0.04638672, -0.0177002 , -0.0625    ,  0.03442383,\n",
       "        -0.02416992,  0.03088379,  0.09570312,  0.07958984,  0.03930664,\n",
       "         0.0279541 , -0.0859375 ,  0.08105469,  0.06640625, -0.00041962,\n",
       "        -0.06933594,  0.03588867, -0.03417969,  0.04492188, -0.00772095,\n",
       "        -0.00741577, -0.04760742,  0.01397705, -0.09960938,  0.0246582 ,\n",
       "        -0.09960938,  0.11474609,  0.03173828,  0.02209473,  0.07226562,\n",
       "         0.03686523,  0.02563477,  0.01367188, -0.02734375,  0.00592041,\n",
       "        -0.06738281,  0.05053711, -0.02832031, -0.04516602, -0.01733398,\n",
       "         0.02111816,  0.03515625, -0.04296875,  0.06640625,  0.12207031,\n",
       "         0.12353516,  0.0039978 ,  0.04516602, -0.01855469,  0.04833984,\n",
       "         0.04516602,  0.08691406,  0.02941895,  0.03759766,  0.03442383,\n",
       "        -0.07373047, -0.0402832 , -0.14648438, -0.02441406, -0.01953125,\n",
       "         0.0065918 , -0.0018158 , -0.01092529,  0.09326172,  0.06542969,\n",
       "         0.01843262, -0.09326172, -0.01574707, -0.07128906, -0.08935547,\n",
       "        -0.07128906, -0.03015137, -0.01300049,  0.01635742, -0.01831055,\n",
       "         0.01483154,  0.00500488,  0.00366211,  0.04760742, -0.06884766],\n",
       "       dtype=float32),\n",
       " array([-1.48437500e-01, -2.07031250e-01, -2.13867188e-01,  2.63671875e-01,\n",
       "        -2.46582031e-02,  2.81250000e-01, -2.55126953e-02, -9.13085938e-02,\n",
       "         2.60009766e-02,  2.08984375e-01,  7.32421875e-02, -6.29882812e-02,\n",
       "         1.64062500e-01, -4.14062500e-01,  3.12500000e-02,  3.14453125e-01,\n",
       "        -1.11328125e-01,  1.69677734e-02,  3.08593750e-01, -2.65625000e-01,\n",
       "         1.54296875e-01, -6.25000000e-02,  9.86328125e-02, -1.88476562e-01,\n",
       "         1.74804688e-01, -1.25976562e-01,  2.01416016e-02,  2.47070312e-01,\n",
       "         3.24218750e-01,  1.97265625e-01, -2.36816406e-02, -2.81250000e-01,\n",
       "        -5.51757812e-02,  2.77099609e-02, -2.85644531e-02, -1.67968750e-01,\n",
       "         6.40625000e-01,  2.98828125e-01, -5.95703125e-02,  2.16796875e-01,\n",
       "        -2.04101562e-01, -4.88281250e-01,  3.06640625e-01, -1.99218750e-01,\n",
       "         3.14453125e-01, -1.66992188e-01, -4.60937500e-01,  1.59912109e-02,\n",
       "         2.45117188e-01,  3.30078125e-01, -1.58203125e-01, -1.76757812e-01,\n",
       "         1.07910156e-01, -1.92382812e-01, -2.11914062e-01, -1.71875000e-01,\n",
       "         1.05957031e-01,  8.25195312e-02, -2.75390625e-01, -1.13281250e-01,\n",
       "        -6.59179688e-02,  3.76953125e-01, -1.88476562e-01, -3.12500000e-02,\n",
       "         1.19140625e-01, -8.69140625e-02,  1.23046875e-01, -2.71484375e-01,\n",
       "         3.35937500e-01,  1.01928711e-02,  4.10156250e-01,  2.03857422e-02,\n",
       "        -7.86132812e-02,  1.43554688e-01, -3.88671875e-01,  3.02734375e-01,\n",
       "        -1.99218750e-01,  2.32421875e-01, -4.05273438e-02, -8.30078125e-02,\n",
       "         1.02539062e-01, -1.45263672e-02, -1.66015625e-01, -1.30859375e-01,\n",
       "        -2.91015625e-01,  3.94531250e-01, -1.44531250e-01,  4.19921875e-01,\n",
       "         2.71484375e-01, -1.76757812e-01, -4.56542969e-02, -3.12500000e-01,\n",
       "        -4.94140625e-01,  1.01562500e-01, -8.88671875e-02, -8.64257812e-02,\n",
       "         1.71875000e-01, -1.38549805e-02, -1.42578125e-01, -7.03125000e-02,\n",
       "        -3.10546875e-01, -2.94921875e-01,  1.82617188e-01, -7.91015625e-02,\n",
       "         6.37817383e-03, -2.31445312e-01, -4.93164062e-02, -1.70898438e-01,\n",
       "         1.47460938e-01, -9.61914062e-02, -5.58471680e-03, -9.52148438e-02,\n",
       "         1.78710938e-01, -1.21582031e-01, -1.50390625e-01, -5.29785156e-02,\n",
       "         6.88476562e-02, -2.55126953e-02,  2.57812500e-01,  1.47705078e-02,\n",
       "         2.09960938e-01,  1.94091797e-02, -9.96093750e-02, -1.02539062e-01,\n",
       "         1.89453125e-01,  2.67578125e-01,  9.81445312e-02, -6.12792969e-02,\n",
       "         1.13281250e-01,  4.68750000e-02, -1.43554688e-01, -2.27539062e-01,\n",
       "        -1.15234375e-01,  2.57812500e-01, -1.47460938e-01,  3.24218750e-01,\n",
       "         3.96728516e-04, -3.12500000e-01,  7.51953125e-02,  1.09375000e-01,\n",
       "         1.75781250e-02, -1.00585938e-01,  2.72216797e-02, -2.12402344e-02,\n",
       "        -2.59765625e-01,  3.04687500e-01, -5.00000000e-01,  1.93359375e-01,\n",
       "        -2.45117188e-01,  2.64892578e-02,  3.00781250e-01,  1.60156250e-01,\n",
       "         1.66015625e-01, -2.46093750e-01, -8.98437500e-02,  4.05273438e-02,\n",
       "        -8.64257812e-02,  1.19140625e-01, -2.50244141e-02,  3.36914062e-02,\n",
       "        -5.85937500e-02,  1.08398438e-01,  2.39257812e-01,  2.94921875e-01,\n",
       "         7.87353516e-03, -7.65991211e-03, -7.12890625e-02, -1.34765625e-01,\n",
       "         1.10839844e-01, -4.76074219e-02,  4.51660156e-02,  7.08007812e-03,\n",
       "         3.45703125e-01,  9.91210938e-02, -1.00585938e-01, -4.78515625e-02,\n",
       "         2.57812500e-01,  2.07031250e-01,  1.54296875e-01, -1.39770508e-02,\n",
       "         3.27148438e-02, -2.63671875e-01,  1.37695312e-01, -3.33984375e-01,\n",
       "        -1.21582031e-01,  1.05957031e-01, -1.29882812e-01,  3.47656250e-01,\n",
       "        -2.77343750e-01, -1.60156250e-01, -1.45507812e-01,  3.67187500e-01,\n",
       "         3.16406250e-01,  3.33984375e-01,  6.54296875e-02,  2.00195312e-01,\n",
       "         1.18408203e-02, -1.15234375e-01,  6.22558594e-02,  9.39941406e-03,\n",
       "        -1.67968750e-01,  2.48046875e-01,  1.42578125e-01, -1.67236328e-02,\n",
       "        -6.28662109e-03, -3.26171875e-01, -3.12500000e-01,  1.23535156e-01,\n",
       "        -1.02233887e-03, -1.01562500e-01, -4.85839844e-02, -2.61718750e-01,\n",
       "        -1.46484375e-02,  3.93676758e-03,  5.56640625e-02,  1.70898438e-01,\n",
       "        -1.12792969e-01,  1.66992188e-01, -2.96875000e-01,  2.23632812e-01,\n",
       "         1.65039062e-01,  2.13867188e-01,  2.24609375e-01,  1.34277344e-02,\n",
       "         1.60156250e-01, -1.14257812e-01,  8.93554688e-02, -2.21679688e-01,\n",
       "        -1.36718750e-01, -2.22656250e-01,  2.85156250e-01, -1.77734375e-01,\n",
       "        -3.04687500e-01,  6.15234375e-02,  2.04101562e-01, -2.91015625e-01,\n",
       "         1.12304688e-02,  1.17187500e-02, -2.50000000e-01,  3.30078125e-01,\n",
       "         1.82617188e-01,  6.17675781e-02, -1.31835938e-01, -2.75390625e-01,\n",
       "         1.36718750e-01,  1.04980469e-01,  1.04492188e-01,  9.17968750e-02,\n",
       "        -1.25976562e-01,  7.22656250e-02,  6.00585938e-02,  3.65234375e-01,\n",
       "         1.91406250e-01, -2.11914062e-01, -3.39843750e-01, -3.20312500e-01,\n",
       "        -1.61132812e-02, -1.22558594e-01, -2.73437500e-01,  1.03149414e-02,\n",
       "         8.85009766e-03, -1.14746094e-02, -1.95312500e-01, -4.24804688e-02,\n",
       "        -1.25000000e-01, -1.54296875e-01, -3.41796875e-01, -5.81054688e-02,\n",
       "        -4.19921875e-02, -1.06933594e-01,  5.81054688e-02,  1.76757812e-01,\n",
       "        -3.92578125e-01,  3.35937500e-01,  5.54199219e-02,  2.15820312e-01,\n",
       "        -2.45117188e-01, -1.16210938e-01, -7.37304688e-02, -2.77343750e-01,\n",
       "         2.69531250e-01, -2.51953125e-01,  6.73828125e-02,  4.55078125e-01,\n",
       "        -2.67578125e-01, -8.05664062e-02, -3.24218750e-01, -1.46484375e-01,\n",
       "        -1.04492188e-01,  5.03906250e-01,  1.61132812e-01,  1.12304688e-01,\n",
       "        -3.35937500e-01, -1.03149414e-02,  1.34765625e-01,  2.53906250e-01,\n",
       "         2.05078125e-01, -2.24609375e-02,  2.30468750e-01, -8.30078125e-02],\n",
       "       dtype=float32),\n",
       " array([ 2.60009766e-02, -1.89208984e-03,  1.85546875e-01, -5.17578125e-02,\n",
       "         5.12695312e-03, -1.09863281e-01, -8.17871094e-03, -8.83789062e-02,\n",
       "         9.66796875e-02,  4.83398438e-02,  1.10473633e-02, -3.63281250e-01,\n",
       "         8.20312500e-02, -2.12402344e-02,  1.58203125e-01,  4.41894531e-02,\n",
       "        -1.17797852e-02,  2.12890625e-01, -5.73730469e-02,  5.66406250e-02,\n",
       "        -1.07421875e-01,  1.85546875e-01,  7.71484375e-02,  1.44958496e-04,\n",
       "         1.52343750e-01, -6.54296875e-02, -1.52343750e-01,  2.25585938e-01,\n",
       "         8.10546875e-02,  8.88671875e-02,  7.32421875e-02, -1.03515625e-01,\n",
       "        -6.68945312e-02,  1.76757812e-01,  2.12890625e-01,  1.40625000e-01,\n",
       "        -3.41796875e-02,  1.78222656e-02,  5.95703125e-02,  2.86102295e-04,\n",
       "         5.88378906e-02,  9.27734375e-03,  1.66992188e-01, -2.70080566e-03,\n",
       "         1.15722656e-01,  1.04492188e-01,  5.37109375e-02,  1.85546875e-02,\n",
       "         1.06445312e-01,  5.05371094e-02, -1.64794922e-02, -1.27929688e-01,\n",
       "         2.16796875e-01,  5.15136719e-02,  4.78515625e-02,  1.52343750e-01,\n",
       "         1.71875000e-01,  7.86132812e-02, -5.88378906e-02, -4.29687500e-02,\n",
       "        -7.27539062e-02,  1.81640625e-01, -8.05664062e-02, -1.54296875e-01,\n",
       "        -1.16699219e-01,  8.44726562e-02, -6.17675781e-02, -4.51660156e-02,\n",
       "         9.21630859e-03,  1.33789062e-01,  1.92871094e-02,  6.44531250e-02,\n",
       "         1.08886719e-01,  1.58203125e-01, -2.35595703e-02,  1.23535156e-01,\n",
       "         1.69921875e-01,  3.49121094e-02,  1.29882812e-01,  2.65625000e-01,\n",
       "         1.93359375e-01, -8.83789062e-02,  8.49609375e-02, -2.96630859e-02,\n",
       "         5.76171875e-02,  2.51464844e-02, -1.01562500e-01,  1.99218750e-01,\n",
       "         1.04492188e-01, -2.42919922e-02,  2.01416016e-02, -3.51562500e-02,\n",
       "         6.64062500e-02, -6.20117188e-02,  2.90527344e-02, -9.81445312e-02,\n",
       "        -1.81640625e-01,  2.14843750e-01, -5.76171875e-02, -4.51660156e-02,\n",
       "         4.49218750e-02, -1.95312500e-02, -2.08984375e-01,  1.19628906e-01,\n",
       "        -9.03320312e-02,  5.07812500e-02,  9.03320312e-03, -9.76562500e-02,\n",
       "        -7.86132812e-02, -1.36718750e-01, -1.13769531e-01, -5.64575195e-03,\n",
       "        -4.07714844e-02, -2.05993652e-03, -5.66406250e-02,  3.64685059e-03,\n",
       "         8.30078125e-02, -7.08007812e-02,  2.63671875e-01,  1.24511719e-01,\n",
       "        -1.61132812e-02,  9.13085938e-02, -2.39257812e-01, -1.04980469e-02,\n",
       "        -6.78710938e-02,  1.40625000e-01,  2.34375000e-01, -6.39648438e-02,\n",
       "         1.95312500e-01,  5.02929688e-02, -1.25000000e-01,  2.06298828e-02,\n",
       "        -1.19140625e-01, -1.17187500e-01, -9.01222229e-05,  3.68652344e-02,\n",
       "         1.46484375e-01,  2.47802734e-02, -1.49414062e-01,  3.03649902e-03,\n",
       "        -3.10058594e-02,  1.06933594e-01,  2.55859375e-01, -6.00585938e-02,\n",
       "        -2.07031250e-01,  1.58203125e-01, -2.15820312e-01, -1.84570312e-01,\n",
       "        -1.72851562e-01,  7.99560547e-03, -3.03955078e-02,  9.81445312e-02,\n",
       "         4.66918945e-03,  2.57812500e-01,  1.06933594e-01,  1.26953125e-01,\n",
       "         6.34765625e-02, -1.30859375e-01,  6.54296875e-02, -9.91210938e-02,\n",
       "         5.90820312e-02, -3.71093750e-02,  1.01074219e-01,  1.53320312e-01,\n",
       "        -1.53320312e-01, -7.56835938e-02,  5.85937500e-02, -5.05371094e-02,\n",
       "         2.08007812e-01,  4.85839844e-02, -9.42382812e-02, -9.71679688e-02,\n",
       "        -1.23046875e-01, -1.97265625e-01, -1.76757812e-01, -1.11328125e-01,\n",
       "         1.11328125e-01, -5.88378906e-02,  2.27539062e-01,  4.00390625e-02,\n",
       "         1.24511719e-01,  1.47460938e-01,  1.81884766e-02,  4.05273438e-02,\n",
       "         1.69921875e-01,  1.13769531e-01, -2.24609375e-02,  6.73828125e-02,\n",
       "         8.59375000e-02,  6.73828125e-02,  2.06298828e-02,  4.78515625e-02,\n",
       "         1.84326172e-02,  2.05078125e-01, -4.68750000e-02,  2.00195312e-01,\n",
       "        -1.56250000e-02, -1.40625000e-01,  1.09863281e-02, -1.73828125e-01,\n",
       "         4.85839844e-02, -1.58203125e-01, -1.04492188e-01,  3.63769531e-02,\n",
       "         3.01513672e-02,  1.27929688e-01, -1.14257812e-01,  1.41601562e-01,\n",
       "         2.34375000e-01, -8.98437500e-02, -1.02996826e-03, -1.50390625e-01,\n",
       "         1.79687500e-01,  1.35742188e-01, -2.08007812e-01, -1.27563477e-02,\n",
       "         1.75781250e-01, -1.39648438e-01, -2.03125000e-01, -3.00292969e-02,\n",
       "        -2.78320312e-02, -6.50024414e-03,  1.26953125e-01, -1.49414062e-01,\n",
       "         1.46484375e-01, -8.42285156e-03,  1.12304688e-01,  1.66015625e-01,\n",
       "        -1.57470703e-02,  1.23046875e-01,  7.22656250e-02, -4.37011719e-02,\n",
       "        -7.56835938e-02, -9.03320312e-02,  1.01562500e-01, -1.44531250e-01,\n",
       "        -4.00390625e-02, -1.26953125e-02,  2.66113281e-02, -7.81250000e-02,\n",
       "         3.56445312e-02,  3.49121094e-02,  1.79687500e-01, -1.38671875e-01,\n",
       "         2.80761719e-02, -2.86865234e-02,  6.78710938e-02,  7.03125000e-02,\n",
       "         9.57031250e-02,  5.00488281e-02, -2.20947266e-02, -3.00781250e-01,\n",
       "         1.14257812e-01,  7.51953125e-02,  1.26342773e-02,  1.32812500e-01,\n",
       "         2.52685547e-02,  3.63769531e-02, -2.81982422e-02, -1.36718750e-01,\n",
       "         1.79687500e-01, -9.27734375e-02,  8.49609375e-02,  1.32812500e-01,\n",
       "         3.97949219e-02,  4.29687500e-01, -1.87988281e-02, -1.47460938e-01,\n",
       "         6.10351562e-02,  9.03320312e-02,  8.69140625e-02, -6.88476562e-02,\n",
       "         1.10839844e-01,  9.81445312e-02,  1.50390625e-01,  1.61132812e-01,\n",
       "        -8.05664062e-02, -1.74804688e-01, -3.32031250e-02, -1.28906250e-01,\n",
       "         1.22558594e-01, -1.44653320e-02, -1.63085938e-01, -3.58886719e-02,\n",
       "         2.78320312e-02, -6.34765625e-02, -7.91015625e-02, -1.14746094e-01,\n",
       "         1.84326172e-02,  2.91748047e-02, -3.00781250e-01, -4.58984375e-02,\n",
       "        -1.74804688e-01,  2.33398438e-01,  2.25830078e-02,  1.10351562e-01,\n",
       "        -1.03515625e-01, -1.21582031e-01,  2.21679688e-01, -2.19726562e-02],\n",
       "       dtype=float32),\n",
       " array([ 0.15820312,  0.10595703, -0.18945312,  0.38671875,  0.08349609,\n",
       "        -0.26757812,  0.08349609,  0.11328125, -0.10400391,  0.17871094,\n",
       "        -0.12353516, -0.22265625, -0.01806641, -0.25390625,  0.13183594,\n",
       "         0.0859375 ,  0.16113281,  0.11083984, -0.11083984, -0.0859375 ,\n",
       "         0.0267334 ,  0.34570312,  0.15136719, -0.00415039,  0.10498047,\n",
       "         0.04907227, -0.06982422,  0.08642578,  0.03198242, -0.02844238,\n",
       "        -0.15722656,  0.11865234,  0.36132812,  0.00173187,  0.05297852,\n",
       "        -0.234375  ,  0.11767578,  0.08642578, -0.01123047,  0.25976562,\n",
       "         0.28515625, -0.11669922,  0.38476562,  0.07275391,  0.01147461,\n",
       "         0.03466797,  0.18164062, -0.03955078,  0.04199219,  0.01013184,\n",
       "        -0.06054688,  0.09765625,  0.06689453,  0.14648438, -0.12011719,\n",
       "         0.08447266, -0.06152344,  0.06347656,  0.3046875 , -0.35546875,\n",
       "        -0.2890625 ,  0.19628906, -0.33203125, -0.07128906,  0.12792969,\n",
       "         0.09619141, -0.12158203, -0.08691406, -0.12890625,  0.27734375,\n",
       "         0.265625  ,  0.1796875 ,  0.12695312,  0.06298828, -0.34375   ,\n",
       "        -0.05908203,  0.0456543 ,  0.171875  ,  0.08935547,  0.14648438,\n",
       "        -0.04638672, -0.00842285, -0.0279541 ,  0.234375  , -0.07470703,\n",
       "        -0.13574219,  0.00378418,  0.19433594,  0.05664062, -0.05419922,\n",
       "         0.06176758,  0.14160156, -0.24121094,  0.02539062, -0.15917969,\n",
       "        -0.10595703,  0.11865234,  0.24707031, -0.13574219, -0.20410156,\n",
       "        -0.30078125,  0.07910156, -0.04394531,  0.02026367, -0.05786133,\n",
       "         0.2109375 ,  0.13574219,  0.08349609, -0.0098877 , -0.10546875,\n",
       "        -0.08105469,  0.03735352, -0.10351562, -0.10205078,  0.23925781,\n",
       "        -0.21875   ,  0.05151367,  0.06738281,  0.07617188,  0.04638672,\n",
       "         0.03198242, -0.07275391,  0.14550781,  0.04858398, -0.05664062,\n",
       "        -0.07470703, -0.0030365 , -0.09277344, -0.11083984, -0.03320312,\n",
       "        -0.15234375, -0.12207031,  0.09814453,  0.375     ,  0.00454712,\n",
       "        -0.10009766,  0.02734375,  0.30078125, -0.0390625 ,  0.30078125,\n",
       "        -0.04541016, -0.00424194,  0.13671875, -0.18945312, -0.21777344,\n",
       "         0.12695312, -0.02746582, -0.18164062,  0.08984375, -0.23339844,\n",
       "         0.203125  ,  0.2734375 , -0.26953125,  0.15332031, -0.20703125,\n",
       "        -0.01153564,  0.12451172,  0.05395508, -0.23535156, -0.01409912,\n",
       "        -0.09765625,  0.20800781,  0.19335938,  0.14746094,  0.28710938,\n",
       "        -0.23046875,  0.01965332, -0.09619141, -0.0703125 , -0.04174805,\n",
       "        -0.17578125,  0.0007019 ,  0.10546875,  0.10351562,  0.02478027,\n",
       "         0.35742188,  0.17382812, -0.09570312, -0.18359375,  0.23242188,\n",
       "        -0.14453125, -0.20410156, -0.01867676,  0.06640625, -0.2265625 ,\n",
       "        -0.00582886, -0.08642578,  0.02416992, -0.07324219, -0.29882812,\n",
       "        -0.15625   ,  0.07666016,  0.19628906, -0.20410156,  0.09863281,\n",
       "        -0.01672363, -0.18652344, -0.12353516, -0.16015625, -0.10058594,\n",
       "         0.21777344,  0.09375   , -0.10058594, -0.03637695,  0.15136719,\n",
       "        -0.02526855, -0.23730469,  0.03417969, -0.00604248,  0.15625   ,\n",
       "        -0.14257812,  0.18066406, -0.35351562,  0.25      ,  0.13085938,\n",
       "        -0.04296875,  0.17089844,  0.20507812,  0.00680542, -0.08251953,\n",
       "        -0.06738281,  0.22167969, -0.16308594, -0.16699219, -0.02087402,\n",
       "         0.11035156,  0.06054688, -0.04223633, -0.17285156,  0.05029297,\n",
       "        -0.19824219,  0.01495361,  0.06542969,  0.03271484,  0.14453125,\n",
       "        -0.08691406, -0.11035156, -0.1484375 ,  0.09667969,  0.22363281,\n",
       "         0.23535156,  0.08398438,  0.18164062, -0.10595703, -0.04296875,\n",
       "         0.11572266, -0.00153351,  0.0534668 , -0.1328125 , -0.33203125,\n",
       "        -0.08251953,  0.30664062,  0.22363281,  0.27929688,  0.09082031,\n",
       "        -0.18066406, -0.00613403, -0.09423828, -0.21289062,  0.01965332,\n",
       "        -0.08105469, -0.06689453, -0.31835938, -0.08447266,  0.13574219,\n",
       "         0.0625    ,  0.07080078, -0.14257812, -0.11279297,  0.01452637,\n",
       "        -0.06689453,  0.03881836,  0.19433594,  0.09521484,  0.11376953,\n",
       "        -0.12451172,  0.13769531, -0.18847656, -0.05224609,  0.15820312,\n",
       "         0.09863281, -0.04370117, -0.06054688,  0.21679688,  0.04077148,\n",
       "        -0.14648438, -0.18945312, -0.25195312, -0.16894531, -0.08642578,\n",
       "        -0.08544922,  0.18945312, -0.14648438,  0.13476562, -0.04077148,\n",
       "         0.03271484,  0.08935547, -0.26757812,  0.00836182, -0.21386719],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=[\"The\",\"Pizza\",\"was\",\"awful\",\"but\",\"the\",\"waitress\",\"was\",\"nice\"]\n",
    "wtext=[gmodel[w] for w in text]\n",
    "wtext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations\n",
    "\n",
    "- We have shown \"embeddings\" in the context of words as lanugage usually has a lot of them and a more direct encoding is infeasible. Embeddings do work in any of these situations in which a dimensionality reduction of otherwise discrete classes is desired.\n",
    "\n",
    "- We have also seen that embeddings can be learned to encode desired properties, such as similarity between individual elements. This can be learned by using Keras' \"merge\" layers, and in particular the dot product. Merge layers are a powerful method to create interesting new systems. For example, a \"concatenate\" layer can be used to merge networks with different kinds of input. For example, a house's price might be predicted from statistical data as well as images, see for example https://www.pyimagesearch.com/2019/02/04/keras-multiple-inputs-and-mixed-data/.\n",
    "\n",
    "- There are very few problems in NLP that can be solved based on a single word or a word tensor of a fixed length. Rather, we will require looking at the history of words to understand meaning, motivating the use of recurrent neural networks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
