{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_cond_to_data(fname_match, conditions_fnames):\n",
    "    \n",
    "    if \"s2\" in fname_match:\n",
    "        matcher = \"2\"\n",
    "    else:\n",
    "        matcher = \"1\"\n",
    "    \n",
    "    for fname in conditions_fnames:\n",
    "        if fname[0:4] == fname_match[0:4] and fname[-5] == matcher:\n",
    "            return fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So Tensorflow runs on GPU\n",
    "import tensorflow as tf\n",
    "\n",
    "# For running on GPU.\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Organization and Cleaning\n",
    "\n",
    "First, I want to enssure that all the file descriptions are paired with their data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "data_fpath = \"../data/fNIRS_Data/\"\n",
    "\n",
    "conditions_fnames = [fname for fname in os.listdir(data_fpath) if \"_conditions_\" in fname]\n",
    "deoxy_fnames = [fname for fname in os.listdir(data_fpath) if \"_Deoxy\" in fname]\n",
    "\n",
    "file_pairs = {}\n",
    "for fname in deoxy_fnames:\n",
    "    file_pairs[f\"{fname[0:4]}\"] = [fname, match_cond_to_data(fname, conditions_fnames)]\n",
    "    \n",
    "print(len(file_pairs))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the description files to index the data.\n",
    "\n",
    "In this step I will want to read through the \"conditions files\" to index and label the fNIRS data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "data_mats = []\n",
    "data_labels = []\n",
    "for k, val in file_pairs.items():\n",
    "    if val[1] != None:\n",
    "        cond_file = pd.read_csv(f\"{data_fpath}{val[1]}\")\n",
    "        data_file = pd.read_csv(f\"{data_fpath}{val[0]}\", header=34)\n",
    "        for x in range(1, 25):\n",
    "            data_mats.append(data_file[int(cond_file[f\"Task{str(x)}\"][0]):int(cond_file[f\"Task{str(x)}\"][0]) + int(cond_file[f\"Task{str(x)}\"][1])])\n",
    "            if cond_file[f\"Task{str(x)}\"][2] == \"cr\":\n",
    "                data_labels.append(0)\n",
    "            else:\n",
    "                data_labels.append(1)\n",
    "                \n",
    "print(data_labels)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean DataFrame and Convert to Array\n",
    "\n",
    "Next, we want to remove some variables from that data that are not useful to the modeling so we are just left with the the deoxy data. Then we will want to store in a way (a format) that is easier to input into the LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trevor/classes/s2020/deep_learning/venv/lib/python3.6/site-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "cols_to_drop = [\"Probe1(Deoxy)\", \"Mark\", \"Time\", \"BodyMovement\", \"RemovalMark\", \"PreScan\"]\n",
    "\n",
    "data_as_np = []\n",
    "for df in data_mats:\n",
    "    df.drop(cols_to_drop, axis=1, inplace=True)\n",
    "    df = df.reset_index()\n",
    "    if df.shape[0] != 250:\n",
    "        df = df[df.index <= 249]\n",
    "    data_as_np.append(df.values)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432\n",
      "432\n"
     ]
    }
   ],
   "source": [
    "# Sanity checking\n",
    "\n",
    "print(len(data_as_np))\n",
    "print(len(data_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some extra data cleaning for odd samples\n",
    "\n",
    "Some samples ended up being empty. Need to remove those samples as well as their labels from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "(250, 53)\n",
      "331\n",
      "331\n"
     ]
    }
   ],
   "source": [
    "for indx, elm in enumerate(data_as_np):\n",
    "    if elm.shape != (250, 53):\n",
    "        data_as_np = np.delete(data_as_np, indx)\n",
    "        del data_labels[indx]\n",
    "        \n",
    "# Sanity checking\n",
    "\n",
    "for elm in data_as_np:\n",
    "    print(elm.shape)\n",
    "    \n",
    "print(len(data_as_np))\n",
    "print(len(data_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing and Changing Input Shape of Sample\n",
    "\n",
    "Still unsure of what the best input shape for this model might be. I'm currently passing the entire sample, but it may be wiser to input chunks of ~5 seconds. Thus far, doing this has not helped much. Normalization has not helped much either."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.48363804 0.         ... 0.07120007 0.14512322 0.9089267 ]\n",
      " [0.00401606 0.49476386 0.01046718 ... 0.07009006 0.13565887 0.90397037]\n",
      " [0.00803213 0.50593395 0.02049871 ... 0.06896917 0.12564947 0.89889755]\n",
      " ...\n",
      " [0.99196787 0.04727778 1.         ... 0.25999646 1.         0.        ]\n",
      " [0.99598394 0.04727778 1.         ... 0.25999646 1.         0.        ]\n",
      " [1.         0.04727778 1.         ... 0.25999646 1.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "def organize_train_test_sets(data_as_np, data_labels):\n",
    "    \n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    \n",
    "    sample_factor = 1\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    data_labels = [[1,0] if elm == 0 else [0,1] for elm in data_labels]\n",
    "    \n",
    "    reshaped = []\n",
    "    for elm in data_as_np:\n",
    "        elm = elm.reshape(int(250 / sample_factor), 53 * sample_factor)\n",
    "        scaler = MinMaxScaler()\n",
    "        normalized = scaler.fit_transform(elm)\n",
    "        reshaped.append(normalized)\n",
    "\n",
    "    return train_test_split(reshaped, data_labels, shuffle=True, test_size=0.20)\n",
    "\n",
    "X_train, X_test, y_train, y_test = organize_train_test_sets(data_as_np, data_labels)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(X_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Model\n",
    "\n",
    "Currently, getting coint flip accuracy on the validation set. Though, it as actually learning the training set (finally). Was having an issue where I was getting coin flip accuracy on both the training and validation set. The model is certainly overfitting, but it does seem that the normalization helped the model to at least do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 264 samples, validate on 67 samples\n",
      "Epoch 1/20\n",
      "264/264 [==============================] - 2s 7ms/step - loss: 0.7317 - categorical_accuracy: 0.4773 - val_loss: 0.7076 - val_categorical_accuracy: 0.4328\n",
      "Epoch 2/20\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.6956 - categorical_accuracy: 0.5152 - val_loss: 0.7123 - val_categorical_accuracy: 0.4328\n",
      "Epoch 3/20\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.6866 - categorical_accuracy: 0.5909 - val_loss: 0.7133 - val_categorical_accuracy: 0.4328\n",
      "Epoch 4/20\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.6877 - categorical_accuracy: 0.5682 - val_loss: 0.7062 - val_categorical_accuracy: 0.4925\n",
      "Epoch 5/20\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.6696 - categorical_accuracy: 0.5795 - val_loss: 0.7095 - val_categorical_accuracy: 0.4925\n",
      "Epoch 6/20\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.6515 - categorical_accuracy: 0.6174 - val_loss: 0.7156 - val_categorical_accuracy: 0.4627\n",
      "Epoch 7/20\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.6498 - categorical_accuracy: 0.6477 - val_loss: 0.7526 - val_categorical_accuracy: 0.4478\n",
      "Epoch 8/20\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.6255 - categorical_accuracy: 0.6477 - val_loss: 0.7467 - val_categorical_accuracy: 0.4328\n",
      "Epoch 9/20\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.6037 - categorical_accuracy: 0.6970 - val_loss: 0.8502 - val_categorical_accuracy: 0.4925\n",
      "Epoch 10/20\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.6064 - categorical_accuracy: 0.6591 - val_loss: 0.8412 - val_categorical_accuracy: 0.4478\n",
      "Epoch 11/20\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.5661 - categorical_accuracy: 0.7273 - val_loss: 0.8396 - val_categorical_accuracy: 0.4328\n",
      "Epoch 12/20\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.5444 - categorical_accuracy: 0.7159 - val_loss: 0.7714 - val_categorical_accuracy: 0.5075\n",
      "Epoch 13/20\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.5346 - categorical_accuracy: 0.7500 - val_loss: 0.8409 - val_categorical_accuracy: 0.4030\n",
      "Epoch 14/20\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.4946 - categorical_accuracy: 0.7576 - val_loss: 0.8673 - val_categorical_accuracy: 0.4179\n",
      "Epoch 15/20\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.4543 - categorical_accuracy: 0.7917 - val_loss: 0.9561 - val_categorical_accuracy: 0.4030\n",
      "Epoch 16/20\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.4097 - categorical_accuracy: 0.8220 - val_loss: 0.9768 - val_categorical_accuracy: 0.4627\n",
      "Epoch 17/20\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.3694 - categorical_accuracy: 0.8485 - val_loss: 1.0738 - val_categorical_accuracy: 0.4179\n",
      "Epoch 18/20\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.4164 - categorical_accuracy: 0.8106 - val_loss: 0.9664 - val_categorical_accuracy: 0.3731\n",
      "Epoch 19/20\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.4134 - categorical_accuracy: 0.8030 - val_loss: 0.9731 - val_categorical_accuracy: 0.4179\n",
      "Epoch 20/20\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.3309 - categorical_accuracy: 0.8712 - val_loss: 1.1255 - val_categorical_accuracy: 0.4328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f0b9103cef0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "\n",
    "time_steps=250\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(time_steps, 53), activation=\"tanh\"))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(2, activation=\"softmax\"))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=16, verbose=1, validation_data=(X_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
