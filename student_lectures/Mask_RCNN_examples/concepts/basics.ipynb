{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask R-CNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instance Segmentation problem\n",
    "* You feed an image, it returns the object bounding boxes, classes and masks. More than just object detection.\n",
    "* Object detection (Fast/ Faster RCNN ) + Semantic Segmentation (FCN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Object detection\n",
    "* Sliding window\n",
    "    * brute force approach\n",
    "    *  slide windows from left and right, and from up to down to identify objects using classification\n",
    "    * varied sizes, and aspect ratios\n",
    "* Selective search\n",
    "    * start with each pixel as its own group\n",
    "    * combine two that are closest\n",
    "<img src=\"./selective-search.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ### State of the art of object detection -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- #### R-CNN -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Faster R-CNN\n",
    "\n",
    "<img src=\"./faster-rcnn.jpeg\">\n",
    "\n",
    "* uses a CNN feature extractor to extract image features\n",
    "* then uses a CNN region proposal network to create region of interests (RoIs)\n",
    "* then applying RoI pooling to warp them into fixed dimension\n",
    "* feed into fully connected layers to make classification and boundary box prediction\n",
    "\n",
    "<code>\n",
    "ROIs = region_proposal(feature_maps)\n",
    "for ROI in ROIs\n",
    "    patch = roi_pooling(feature_maps, ROI)\n",
    "    results = detector2(patch)\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What’s similar between Mask R-CNN and Faster R-CNN?\n",
    "* Both Mask R-CNN and Faster R-CNN have a branch for classification and bounding box regression.\n",
    "* Both use ResNet 101 architecture to extract features from image.\n",
    "* Both use Region Proposal Network(RPN) to generate Region of Interests(RoI).\n",
    "\n",
    "The Faster R-CNN builds all the ground work for feature extractions and ROI proposals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What's special about Mask RCNN?\n",
    "* add 2 more convolution layers to build the mask.\n",
    "* use ROI Align instead of ROI Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROI Align vs ROI Pool\n",
    "\n",
    "<img src=\"./roi-align.png\">\n",
    "\n",
    "* Mask R-CNN uses ROI Align which does not digitalize the boundary of the cells (top right) and make every target cell to have the same size (bottom right). \n",
    "* It also applies interpolation to calculate the feature map values within the cell better.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mask R-CNN\n",
    "<img src=\"./mask-rcnn.png\">\n",
    "\n",
    "* paper\n",
    "* Two stages\n",
    "\n",
    "<!--     * First: a light weight neural network called RPN scans all FPN top-bottom pathway (feature map) and proposes regions which may contain objects.\n",
    "    * Second: another neural network takes proposed regions by the first stage and assign them to several specific areas of a feature map level, scans these areas, and generates objects classes(multi-categorical classified), bounding boxes and masks.\n",
    "* backbone is a FPN (Feature Pyramid Networks) style deep neural net. -->\n",
    "\n",
    "<!-- * WHERE TO PUT THIS?\n",
    "    * Warped features are then fed into fully connected layers to make classification using softmax and boundary box prediction is further refined using the regression model\n",
    "    * Warped features are also fed into Mask classifier, which consists of two CNN’s to output a binary mask for each RoI. Mask Classifier allows the network to generate masks for every class without competition among classes. -->\n",
    "\n",
    "<!--     * consists of a bottom-up pathway, a top-bottom pathway and lateral connections.\n",
    "        * bottom-up: extracts features (can be any ConvNet, usually ResNet or VGG)\n",
    "        * top-bottom: generates freature pyramid map\n",
    "        * lateral connection: convolution and adding operations between two pathways.\n",
    "    * FPN outperformssingle ConvNets b/c it maintains strong sematically features at various resoultion scales.\n",
    "     -->\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IoU (Intersection over Union)\n",
    "<img src=\"./iou_equation.png\" width=\"200\" height=\"200\">\n",
    "\n",
    "* to measure the accuracy of an object detector on a particular dataset\n",
    "* predicted bounding box and the ground-truth bounding box (hand-labeled)\n",
    "* an Intersection over Union score > 0.5 is normally considered a “good” prediction\n",
    "<!--     * Item 2b -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if I have multiple bounding boxes with IoU greater than 0.5?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NMS (Non Maximum Suppression)\n",
    "<img src=\"./nms.png\" width=\"200\" height=\"200\">\n",
    "\n",
    "* It groups highly-overlapped boxes for the same class and selects the most confidence prediction only. \n",
    "* This avoids duplicates for the same object.\n",
    "* Per class operation\n",
    "\n",
    "<img src=\"./nms-2.png\">\n",
    "Classification with ROIs is shown in the dotted lines. Solid line is the refined bounding box.\n",
    "<!-- * a class of algorithms to select one entity (e.g. bounding boxes) out of many overlapping entities. In essence it is a form of clustering algorithm.\n",
    "* attempts have been made to use standard clustering algorithms such as k-means, Nearest Neighbor, DB Scan, etc. in object detection\n",
    "* is used along with some form of overlap measure (e.g. IOU). -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key improvements / achievement of Mask R-CNN\n",
    "* ROIAlign\n",
    "    * Pixel-to-pixel alignment\n",
    "    * for one object, it outputs multiple bounding boxes rather than a single definite one and warp them into a fixed dimension.\n",
    "* Parallel operations do not affect the speed\n",
    "* Reuse of feature map\n",
    "* elimintate competetion between different classes when generating the mask\n",
    "    * FCN uses softmax and multinomial cross entropy loss\n",
    "    * Mask R-CNN uses sigmoid and a binary loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terms: \n",
    "* Anchor boxes: \n",
    "     <img src=\"./anchor-boxes.png\">\n",
    "     \n",
    "    * to detect multiple objects, objects of different scales, and overlapping objects in an image. \n",
    "    * a set of predefined bounding boxes of a certain height and width.\n",
    "    * final object detection is done by removing anchor boxes that belong to the background class and the remaining ones are filtered by their confidence score.\n",
    "\n",
    "* RPN: \n",
    "    * uses a CNN to generate the multiple Region of Interest(RoI) using a lightweight binary classifier.\n",
    "    * uses 9 anchors boxes over the image. \n",
    "    * The classifier returns object/no-object scores. Non Max suppression is applied to Anchors with high objectness score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Comparing with YOLO \n",
    " -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ResNet -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
