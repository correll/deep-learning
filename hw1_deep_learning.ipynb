{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1. - Trevor Grant - Github: tjgran01\n",
    "\n",
    "For this proect I tried to be too fancy and predict a Pokemon's Type, based solely on the image of the pokemon. It did not work. How sad. I did, however, get tensorflow running on my GPU and learned some data cleaning stuff in the process, so that felt pretty cool. I also combined two datasets. I still failed though. Which, that's pretty much life.\n",
    "\n",
    "### Data:\n",
    "\n",
    "Data was gathered from two datasets on Kaggle.com. The links are below:\n",
    "\n",
    "imgs:https://www.kaggle.com/hannesrosenbusch/6036-labeled-pokemon-pictures\n",
    "\n",
    "labels: https://www.kaggle.com/abcsds/pokemon\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Keras Imports\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import SGD, RMSprop, Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running on the GPU\n",
    "\n",
    "I learned a lot about how to make the model run on the GPU, but was still having trouble when push came to shove. I was glad to see that I was note alone and found a somewhat helpful (in that it made the model run) thread on github.com \n",
    "\n",
    "https://github.com/tensorflow/tensorflow/issues/24496\n",
    "\n",
    "This is apparently an issue with the newer NVIDA card running on Ubuntu --- so if anyone ran into this issue the below code should fix the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So Tensorflow runs on GPU\n",
    "import tensorflow as tf\n",
    "\n",
    "# For running on GPU.\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Param Dictionary\n",
    "\n",
    "I put the parameters for the model into a dictionary because lose variables make me uncomfortable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_param_dict():\n",
    "\n",
    "    # From \"Deeplearning with Keras\"\n",
    "    EPOCHS = 50\n",
    "    BATCH_SIZE = 16\n",
    "    VERBOSE = 1\n",
    "    OPTIMIZER = Adam()\n",
    "    VALIDATION_SPLIT=0.15\n",
    "    IMG_ROWS, IMG_COLS = 100, 100 # input image dimensions\n",
    "    CLASSES = 4 # number of outputs = number of digits\n",
    "    INPUT_SHAPE = (IMG_ROWS, IMG_COLS, 3)\n",
    "\n",
    "    param_dict = {\"EPOCHS\": EPOCHS, \"BATCH_SIZE\": BATCH_SIZE,\n",
    "                  \"VERBOSE\": VERBOSE, \"OPTIMIZER\": Adam(),\n",
    "                  \"VALIDATION_SPLIT\": VALIDATION_SPLIT, \"IMG_ROWS\": IMG_ROWS,\n",
    "                  \"IMG_COLS\": IMG_COLS, \"CLASSES\": CLASSES,\n",
    "                  \"INPUT_SHAPE\": INPUT_SHAPE}\n",
    "\n",
    "    return param_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the data\n",
    "\n",
    "This probably should have been multiple functions, but oh well. This was the bulk of my work so I could better understand what format data needed to be in in order to be fed into the model. Reading the book, he often just pulls datasets from the keras API. I find that when I see that it is difficult for me to learn exactly **what** is going into the model, so being able to put together a dataset somewhat assuaged my concerns there.\n",
    "\n",
    "### Downsampling.\n",
    "\n",
    "Looking over the label distribution I had a major problem in that many of the Pokemon were of 'water' type (i.e. it was the majority class by a long shot with about 20% more samples than the next most common class). I added some functionality in here that would allow me to drop samples from types of pokemon I didn't want to classify. I thought that that might work --- but it didn't --- still a neat way to do it though!\n",
    "\n",
    "In total there were 18 different classes. When I ran the model on all of the classes it easily obtained a score of 97% accuracy ... on the validation set ... and ~18% on the test set. Boo. Downsampling to a binary classification problem helped with test accuracy somewhat, but not by much, but the validation set took a plunge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relabel_by_type():\n",
    "\n",
    "\n",
    "    # Adjust drop list to get rid of minority classes, etc.\n",
    "    drop_list = [\"drop_me\"]\n",
    "    drop_list = [\"drop_me\", 'Bug', 'Dark', 'Dragon', 'Electric', 'Fairy',\n",
    "                 'Fighting', 'Flying', 'Ghost', 'Ground', 'Normal', 'Psychic', 'Rock', 'Steel']\n",
    "\n",
    "    # Get Type Labels For All Images.\n",
    "\n",
    "    imgs = np.load(f\"{os.getcwd()}/../data/poke_image_data.npy\")\n",
    "    names_and_scores = pd.read_csv(f\"{os.getcwd()}/../data/names_and_strengths.csv\")\n",
    "    names_and_stats = pd.read_csv(f\"{os.getcwd()}/../data/Pokemon.csv\")\n",
    "\n",
    "    type_list = []\n",
    "    type_2_list = []\n",
    "    for name in names_and_scores[\"name\"].tolist():\n",
    "        if name in names_and_stats[\"Name\"].tolist():\n",
    "            type_list.append(names_and_stats.loc[names_and_stats[\"Name\"] == name, \"Type 1\"].iloc[0])\n",
    "            type_2_list.append(names_and_stats.loc[names_and_stats[\"Name\"] == name, \"Type 2\"].iloc[0])\n",
    "        else:\n",
    "            type_list.append(\"drop_me\")\n",
    "            type_2_list.append(\"drop_me\")\n",
    "\n",
    "\n",
    "    names_and_scores[\"Type 1\"] = type_list\n",
    "    names_and_scores[\"Type 2\"] = type_2_list\n",
    "\n",
    "    entries_to_drop = []\n",
    "    for i, row in (names_and_scores.iterrows()):\n",
    "        if row[\"Type 1\"] in drop_list or row[\"Type 2\"] in drop_list:\n",
    "            entries_to_drop.append(i)\n",
    "\n",
    "    poke_data = names_and_scores.drop(entries_to_drop, axis=0)\n",
    "    poke_imgs = []\n",
    "    for i, img in enumerate(imgs):\n",
    "        if i not in entries_to_drop:\n",
    "            poke_imgs.append(imgs[i])\n",
    "\n",
    "    poke_imgs = np.array(poke_imgs)\n",
    "\n",
    "    poke_data.to_csv(f\"{os.getcwd()}/../data/relabeled/poke_data.csv\")\n",
    "    np.save(f\"{os.getcwd()}/../data/relabeled/poke_imgs.npy\", poke_imgs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting\n",
    "\n",
    "It was important to be able to plot an image by pokemon name to ensure that my data cleaning didn't shuffle things around and mislabel things. That is all this function is for, really."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample_pokemon(pokename, imgs, df):\n",
    "    \"\"\"Ensures Re-Labeling Worked By Printing out A Pokemon img, given a name.\"\"\"\n",
    "\n",
    "    df = df[df[\"name\"] == pokename]\n",
    "    picked = random.choice(df.index.tolist())\n",
    "\n",
    "    imgplot = plt.imshow(imgs[picked])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding\n",
    "\n",
    "This is my poor-mans way of implementing one hot encoding. I know there are functions for this sort of thing, but based on the way the data was formatted this seemed to make the most sense as it preserved the labeling structure so that the indexes of the dataframe didn't come off from the indexes of the image (as they were sourced from different data sets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_labels(df):\n",
    "\n",
    "    types = [\"Grass\", \"Fire\", \"Ice\", \"Poison\"]\n",
    "\n",
    "    one_hot = pd.get_dummies(df['Type 1'])\n",
    "    df = df.join(one_hot)\n",
    "\n",
    "    df[\"one_hot\"] = df[types].values.tolist()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_train_test_sets(df, imgs):\n",
    "\n",
    "    imgs = imgs.astype(\"float32\")\n",
    "\n",
    "    labels = df[\"one_hot\"].tolist()\n",
    "    labels = np.array(labels)\n",
    "    labels = labels.astype(\"float32\")\n",
    "\n",
    "    return train_test_split(imgs, labels, shuffle=True, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(X_train, X_test, y_train, y_test, params):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(16, kernel_size=5, input_shape=params[\"INPUT_SHAPE\"]))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=5))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(20, 20)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add(Dense(params[\"CLASSES\"]))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    model.compile(loss=\"categorical_crossentropy\",\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=[\"accuracy\"])\n",
    "    model.summary()\n",
    "\n",
    "    history = model.fit(X_train, y_train,batch_size=params[\"BATCH_SIZE\"],\n",
    "                        epochs=params[\"EPOCHS\"], verbose=1,\n",
    "                        validation_split=params[\"VALIDATION_SPLIT\"])\n",
    "    score = model.evaluate(X_test, y_test, verbose=1)\n",
    "    print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    params = get_param_dict()\n",
    "\n",
    "    if not os.path.exists(f\"{os.getcwd()}/../data/relabeled/poke_data.csv\"):\n",
    "        relabel_by_type()\n",
    "\n",
    "    poke_imgs = np.load(f\"{os.getcwd()}/../data/relabeled/poke_imgs.npy\")\n",
    "    poke_data = pd.read_csv(f\"{os.getcwd()}/../data/relabeled/poke_data.csv\")\n",
    "\n",
    "    plot_sample_pokemon(\"Pichu\", poke_imgs, poke_data)\n",
    "\n",
    "    # Get one hot encoding for each type.\n",
    "    poke_data = one_hot_labels(poke_data)\n",
    "    # Split train and test sets\n",
    "    X_train, X_test, y_train, y_test = organize_train_test_sets(poke_data, poke_imgs)\n",
    "\n",
    "    model = make_model(X_train, X_test, y_train, y_test, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 96, 96, 16)        1216      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 96, 96, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 48, 48, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 44, 44, 32)        12832     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 44, 44, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 204       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 20,702\n",
      "Trainable params: 20,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 953 samples, validate on 169 samples\n",
      "Epoch 1/50\n",
      "953/953 [==============================] - 0s 338us/step - loss: 604.1720 - accuracy: 0.3043 - val_loss: 1687.2937 - val_accuracy: 0.6450\n",
      "Epoch 2/50\n",
      "953/953 [==============================] - 0s 229us/step - loss: 4937.0821 - accuracy: 0.3179 - val_loss: 6620.4014 - val_accuracy: 0.2012\n",
      "Epoch 3/50\n",
      "953/953 [==============================] - 0s 259us/step - loss: 17152.1087 - accuracy: 0.3305 - val_loss: 32019.4837 - val_accuracy: 0.1361\n",
      "Epoch 4/50\n",
      "953/953 [==============================] - 0s 265us/step - loss: 38918.8460 - accuracy: 0.3389 - val_loss: 54866.7839 - val_accuracy: 0.1953\n",
      "Epoch 5/50\n",
      "953/953 [==============================] - 0s 279us/step - loss: 83292.2151 - accuracy: 0.3190 - val_loss: 33969.9350 - val_accuracy: 0.5680\n",
      "Epoch 6/50\n",
      "953/953 [==============================] - 0s 284us/step - loss: 134252.9800 - accuracy: 0.3274 - val_loss: 75031.1246 - val_accuracy: 0.2071\n",
      "Epoch 7/50\n",
      "953/953 [==============================] - 0s 310us/step - loss: 211888.5708 - accuracy: 0.3253 - val_loss: 76964.6871 - val_accuracy: 0.1479\n",
      "Epoch 8/50\n",
      "953/953 [==============================] - 0s 346us/step - loss: 325070.7575 - accuracy: 0.3190 - val_loss: 589814.6021 - val_accuracy: 0.1953\n",
      "Epoch 9/50\n",
      "953/953 [==============================] - 0s 350us/step - loss: 494109.6244 - accuracy: 0.3075 - val_loss: 668988.4024 - val_accuracy: 0.6568\n",
      "Epoch 10/50\n",
      "953/953 [==============================] - 0s 359us/step - loss: 630367.0509 - accuracy: 0.3295 - val_loss: 515058.5592 - val_accuracy: 0.2071\n",
      "Epoch 11/50\n",
      "953/953 [==============================] - 0s 343us/step - loss: 776967.6728 - accuracy: 0.3421 - val_loss: 876504.3299 - val_accuracy: 0.6627\n",
      "Epoch 12/50\n",
      "953/953 [==============================] - 0s 340us/step - loss: 1205477.1380 - accuracy: 0.2970 - val_loss: 884255.2433 - val_accuracy: 0.6450\n",
      "Epoch 13/50\n",
      "953/953 [==============================] - 0s 363us/step - loss: 1507180.9612 - accuracy: 0.3075 - val_loss: 2242037.0178 - val_accuracy: 0.0355\n",
      "Epoch 14/50\n",
      "953/953 [==============================] - 0s 344us/step - loss: 1719337.5025 - accuracy: 0.3200 - val_loss: 3556077.2426 - val_accuracy: 0.6627\n",
      "Epoch 15/50\n",
      "953/953 [==============================] - 0s 384us/step - loss: 2129945.6548 - accuracy: 0.3358 - val_loss: 1041563.6479 - val_accuracy: 0.6568\n",
      "Epoch 16/50\n",
      "953/953 [==============================] - 0s 473us/step - loss: 2774741.9617 - accuracy: 0.3022 - val_loss: 1060156.5895 - val_accuracy: 0.1302\n",
      "Epoch 17/50\n",
      "953/953 [==============================] - 0s 417us/step - loss: 3028576.3033 - accuracy: 0.3305 - val_loss: 4388161.9024 - val_accuracy: 0.6627\n",
      "Epoch 18/50\n",
      "953/953 [==============================] - 0s 319us/step - loss: 3986584.1095 - accuracy: 0.3158 - val_loss: 4049590.5325 - val_accuracy: 0.0414\n",
      "Epoch 19/50\n",
      "953/953 [==============================] - 0s 287us/step - loss: 4344682.7789 - accuracy: 0.3536 - val_loss: 8411340.5207 - val_accuracy: 0.1953\n",
      "Epoch 20/50\n",
      "953/953 [==============================] - 0s 394us/step - loss: 5601163.9538 - accuracy: 0.3116 - val_loss: 7088594.5621 - val_accuracy: 0.0296\n",
      "Epoch 21/50\n",
      "953/953 [==============================] - 0s 468us/step - loss: 6659859.2109 - accuracy: 0.3127 - val_loss: 3637929.6450 - val_accuracy: 0.6568\n",
      "Epoch 22/50\n",
      "953/953 [==============================] - 0s 394us/step - loss: 7003865.5855 - accuracy: 0.3410 - val_loss: 7959189.9630 - val_accuracy: 0.0947\n",
      "Epoch 23/50\n",
      "953/953 [==============================] - 0s 368us/step - loss: 8479321.7177 - accuracy: 0.3295 - val_loss: 8310694.6243 - val_accuracy: 0.0296\n",
      "Epoch 24/50\n",
      "953/953 [==============================] - 0s 434us/step - loss: 9092879.3127 - accuracy: 0.3347 - val_loss: 10687144.1893 - val_accuracy: 0.1124\n",
      "Epoch 25/50\n",
      "953/953 [==============================] - 0s 307us/step - loss: 11425656.6128 - accuracy: 0.2991 - val_loss: 4949446.4201 - val_accuracy: 0.6450\n",
      "Epoch 26/50\n",
      "953/953 [==============================] - 0s 288us/step - loss: 12750973.7209 - accuracy: 0.3200 - val_loss: 10202024.1065 - val_accuracy: 0.6627\n",
      "Epoch 27/50\n",
      "953/953 [==============================] - 0s 298us/step - loss: 13598553.9864 - accuracy: 0.3358 - val_loss: 7453665.7041 - val_accuracy: 0.0828\n",
      "Epoch 28/50\n",
      "953/953 [==============================] - 0s 267us/step - loss: 16061291.7188 - accuracy: 0.3337 - val_loss: 13972782.9704 - val_accuracy: 0.1953\n",
      "Epoch 29/50\n",
      "953/953 [==============================] - 0s 253us/step - loss: 17477687.8757 - accuracy: 0.3263 - val_loss: 20466836.4024 - val_accuracy: 0.1124\n",
      "Epoch 30/50\n",
      "953/953 [==============================] - 0s 267us/step - loss: 19524311.4418 - accuracy: 0.3274 - val_loss: 34767893.2781 - val_accuracy: 0.1953\n",
      "Epoch 31/50\n",
      "953/953 [==============================] - 0s 293us/step - loss: 22228044.2896 - accuracy: 0.3127 - val_loss: 32981488.8521 - val_accuracy: 0.6627\n",
      "Epoch 32/50\n",
      "953/953 [==============================] - 0s 300us/step - loss: 23493696.4869 - accuracy: 0.3442 - val_loss: 27542976.3550 - val_accuracy: 0.6627\n",
      "Epoch 33/50\n",
      "953/953 [==============================] - 0s 278us/step - loss: 26416366.5395 - accuracy: 0.3358 - val_loss: 47369313.0178 - val_accuracy: 0.0296\n",
      "Epoch 34/50\n",
      "953/953 [==============================] - 0s 279us/step - loss: 30719184.4449 - accuracy: 0.3127 - val_loss: 42605961.8462 - val_accuracy: 0.6627\n",
      "Epoch 35/50\n",
      "953/953 [==============================] - 0s 280us/step - loss: 31827658.5771 - accuracy: 0.3463 - val_loss: 31872539.4556 - val_accuracy: 0.6627\n",
      "Epoch 36/50\n",
      "953/953 [==============================] - 0s 255us/step - loss: 37176263.0525 - accuracy: 0.3253 - val_loss: 19765563.0651 - val_accuracy: 0.1124\n",
      "Epoch 37/50\n",
      "953/953 [==============================] - 0s 245us/step - loss: 38280418.7240 - accuracy: 0.3200 - val_loss: 47311041.9882 - val_accuracy: 0.1953\n",
      "Epoch 38/50\n",
      "953/953 [==============================] - 0s 252us/step - loss: 42032530.9381 - accuracy: 0.3368 - val_loss: 15303468.0710 - val_accuracy: 0.1124\n",
      "Epoch 39/50\n",
      "953/953 [==============================] - 0s 252us/step - loss: 45544049.3767 - accuracy: 0.3358 - val_loss: 33213554.9349 - val_accuracy: 0.6627\n",
      "Epoch 40/50\n",
      "953/953 [==============================] - 0s 281us/step - loss: 49298852.1301 - accuracy: 0.3305 - val_loss: 75551822.6272 - val_accuracy: 0.1124\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "953/953 [==============================] - 0s 265us/step - loss: 54863983.7524 - accuracy: 0.3190 - val_loss: 74009133.6331 - val_accuracy: 0.1124\n",
      "Epoch 42/50\n",
      "953/953 [==============================] - 0s 269us/step - loss: 61506726.5477 - accuracy: 0.3347 - val_loss: 97546118.6746 - val_accuracy: 0.6627\n",
      "Epoch 43/50\n",
      "953/953 [==============================] - 0s 321us/step - loss: 59980414.2455 - accuracy: 0.3295 - val_loss: 41099288.0947 - val_accuracy: 0.2071\n",
      "Epoch 44/50\n",
      "953/953 [==============================] - 0s 324us/step - loss: 68090487.8153 - accuracy: 0.3326 - val_loss: 86051022.1538 - val_accuracy: 0.1953\n",
      "Epoch 45/50\n",
      "953/953 [==============================] - 0s 314us/step - loss: 69679170.6359 - accuracy: 0.3410 - val_loss: 59052904.3314 - val_accuracy: 0.1953\n",
      "Epoch 46/50\n",
      "953/953 [==============================] - 0s 308us/step - loss: 83368832.1280 - accuracy: 0.3169 - val_loss: 38022271.1953 - val_accuracy: 0.6272\n",
      "Epoch 47/50\n",
      "953/953 [==============================] - 0s 311us/step - loss: 80890103.1375 - accuracy: 0.3379 - val_loss: 46705161.2308 - val_accuracy: 0.1953\n",
      "Epoch 48/50\n",
      "953/953 [==============================] - 0s 321us/step - loss: 93506509.5068 - accuracy: 0.3106 - val_loss: 107530300.7337 - val_accuracy: 0.0296\n",
      "Epoch 49/50\n",
      "953/953 [==============================] - 0s 320us/step - loss: 91133898.2497 - accuracy: 0.3400 - val_loss: 96722750.1775 - val_accuracy: 0.5621\n",
      "Epoch 50/50\n",
      "953/953 [==============================] - 0s 323us/step - loss: 104461482.8374 - accuracy: 0.3316 - val_loss: 212378157.4911 - val_accuracy: 0.0296\n",
      "198/198 [==============================] - 0s 142us/step\n",
      "[218743983.67676768, 0.05050504952669144]\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
